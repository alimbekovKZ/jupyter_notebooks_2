{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # monitor \n",
    "# def get_memory_usage():\n",
    "#     return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "# def sizeof_fmt(num, suffix='B'):\n",
    "#     for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "#         if abs(num) < 1024.0:\n",
    "#             return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "#         num /= 1024.0\n",
    "#     return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file path if run on different machines\n",
    "# FilePath = \"/Users/yabindong/Program_Dataset/M5-Forcasting/m5-forecasting-accuracy/\"\n",
    "FilePath = \"MainData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to reduce the memory\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2 #bytes to MB\n",
    "    \n",
    "    # the for loop converts int16 --> int8, int32 --> int 16, etc\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[0:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    \n",
    "    if verbose:\n",
    "        print('Memory usage decreased from {:5.2f} Mb to {:5.2f} Mb ({:.1f}% reduction)'.format(start_mem, end_mem, 100*(start_mem-end_mem)/start_mem))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and reduce memory usage\n",
    "def ReadData(Path):\n",
    "    print(\"Reading files...\")\n",
    "    calendar = pd.read_csv(FilePath+'calendar.csv')\n",
    "    calendar = reduce_mem_usage(calendar)\n",
    "    print(\"calendar df has {} rows and {} columns\".format(calendar.shape[0], calendar.shape[1]))\n",
    "    \n",
    "    train = pd.read_csv(FilePath+'sales_train_validation.csv')\n",
    "    train = reduce_mem_usage(train)\n",
    "    print(\"train df has {} rows and {} columns\".format(train.shape[0], train.shape[1]))\n",
    "    \n",
    "    SellPrice = pd.read_csv(FilePath+'sell_prices.csv')\n",
    "    SellPrice = reduce_mem_usage(SellPrice)\n",
    "    print(\"train df has {} rows and {} columns\".format(SellPrice.shape[0], SellPrice.shape[1]))\n",
    "    \n",
    "    SampleSub = pd.read_csv(FilePath+'sample_submission.csv')\n",
    "    SampleSub = reduce_mem_usage(SampleSub)\n",
    "    print(\"train df has {} rows and {} columns\".format(SampleSub.shape[0], SampleSub.shape[1]))\n",
    "    \n",
    "    return calendar, train, SellPrice, SampleSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Memory usage decreased from  0.21 Mb to  0.12 Mb (41.9% reduction)\n",
      "calendar df has 1969 rows and 14 columns\n",
      "Memory usage decreased from 446.40 Mb to 95.00 Mb (78.7% reduction)\n",
      "train df has 30490 rows and 1919 columns\n",
      "Memory usage decreased from 208.77 Mb to 130.48 Mb (37.5% reduction)\n",
      "train df has 6841121 rows and 4 columns\n",
      "Memory usage decreased from 13.49 Mb to  2.09 Mb (84.5% reduction)\n",
      "train df has 60980 rows and 29 columns\n"
     ]
    }
   ],
   "source": [
    "df_calendar0, df_train0, df_SellPrice0, df_Sample_Submission = ReadData(FilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'sales'         # Our main target\n",
    "END_TRAIN = 1913         # Last day in train set\n",
    "MAIN_INDEX = ['id','d']  # We can identify item by these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of df_grid is (58327370, 8)\n"
     ]
    }
   ],
   "source": [
    "index_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "# unpivot a table from wide to long\n",
    "df_grid = pd.melt(df_train0, id_vars = index_columns, var_name = 'd', value_name = TARGET)\n",
    "print(\"the shape of df_grid is {}\".format(df_grid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**add test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of added test dataframe is (853720, 8)\n"
     ]
    }
   ],
   "source": [
    "add_grid = pd.DataFrame()\n",
    "for i in range(1,29):\n",
    "    temp_df = df_train0[index_columns].drop_duplicates()\n",
    "    temp_df['d'] = 'd_'+ str(END_TRAIN+i)\n",
    "    temp_df[TARGET] = np.nan\n",
    "    add_grid = pd.concat([add_grid,temp_df])\n",
    "print(\"The shape of added test dataframe is {}\".format(add_grid.shape)) # 30490*28=853720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of df_grid is (59181090, 8)\n"
     ]
    }
   ],
   "source": [
    "df_grid = pd.concat([df_grid,add_grid])\n",
    "df_grid = df_grid.reset_index(drop=True)\n",
    "print(\"The shape of df_grid is {}\".format(df_grid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove not used df\n",
    "# del temp_df, add_grid, df_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce memory usage by converting \"strings\" to categorical and it will not lose info\n",
    "for col in index_columns:\n",
    "    df_grid[col] = df_grid[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**price df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging by concat to not lose data\n",
    "def merge_by_concat(df1, df2, merge_on):\n",
    "    merged_gf = df1[merge_on]\n",
    "    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find absence for the item in the store, the first none 0 wm_yr_wk\n",
    "df_release = df_SellPrice0.groupby(['store_id','item_id'])['wm_yr_wk'].agg(['min']).reset_index()\n",
    "df_release.columns = ['store_id','item_id','release']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of df_grid is (59181090, 9)\n"
     ]
    }
   ],
   "source": [
    "# merge price and train\n",
    "df_grid = merge_by_concat(df_grid, df_release, ['store_id', 'item_id'])\n",
    "print(\"The shape of df_grid is {}\".format(df_grid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df_release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calendar df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid = merge_by_concat(df_grid, df_calendar0[['wm_yr_wk','d']], ['d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut off rows by release date\n",
    "df_grid = df_grid[df_grid['wm_yr_wk']>=df_grid['release']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid = df_grid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>release</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11101</td>\n",
       "      <td>11101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_009</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11101</td>\n",
       "      <td>11101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_010_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_010</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11101</td>\n",
       "      <td>11101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_012_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_012</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11101</td>\n",
       "      <td>11101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_015_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_015</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11101</td>\n",
       "      <td>11101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_009_CA_1_validation  HOBBIES_1_009  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_010_CA_1_validation  HOBBIES_1_010  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_012_CA_1_validation  HOBBIES_1_012  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_015_CA_1_validation  HOBBIES_1_015  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id    d  sales  release  wm_yr_wk  \n",
       "0       CA  d_1   12.0    11101     11101  \n",
       "1       CA  d_1    2.0    11101     11101  \n",
       "2       CA  d_1    0.0    11101     11101  \n",
       "3       CA  d_1    0.0    11101     11101  \n",
       "4       CA  d_1    4.0    11101     11101  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of grid_part_1: (46881677, 10)\n"
     ]
    }
   ],
   "source": [
    "# save part 1\n",
    "df_grid.to_pickle(FilePath+'grid_part_1.pkl')\n",
    "print(\"Size of grid_part_1: {}\".format(df_grid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max, min, mean, and std of the item in each store\n",
    "df_SellPrice0['price_max'] = df_SellPrice0.groupby(['store_id','item_id'])['sell_price'].transform('max')\n",
    "df_SellPrice0['price_min'] = df_SellPrice0.groupby(['store_id','item_id'])['sell_price'].transform('min')\n",
    "df_SellPrice0['price_std'] = df_SellPrice0.groupby(['store_id','item_id'])['sell_price'].transform('std')\n",
    "df_SellPrice0['price_mean'] = df_SellPrice0.groupby(['store_id','item_id'])['sell_price'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SellPrice0['price_norm'] = df_SellPrice0['sell_price']/df_SellPrice0['price_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many different sell prices for the same item\n",
    "df_SellPrice0['price_nunique'] = df_SellPrice0.groupby(['store_id','item_id'])['sell_price'].transform('nunique')\n",
    "# how many different items for the same price\n",
    "df_SellPrice0['item_nunique'] = df_SellPrice0.groupby(['store_id','sell_price'])['item_id'].transform('nunique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**price and calendar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but would like months and years as \"window\"\n",
    "calendar_prices = df_calendar0[['wm_yr_wk','month','year']]\n",
    "calendar_prices = calendar_prices.drop_duplicates(subset=['wm_yr_wk'])\n",
    "df_SellPrice0 = df_SellPrice0.merge(calendar_prices[['wm_yr_wk','month','year']], on=['wm_yr_wk'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del calendar_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the price \"momentum\": price over month average and year average\n",
    "# calculate the average sell_price of the month\n",
    "# df_SellPrice0.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\n",
    "df_SellPrice0['price_momentum_m'] = df_SellPrice0['sell_price']/df_SellPrice0.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\n",
    "df_SellPrice0['price_momentum_y'] = df_SellPrice0['sell_price']/df_SellPrice0.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n",
    "\n",
    "# Today's price over yesterday's price\n",
    "df_SellPrice0['price_momentum'] = df_SellPrice0['sell_price']/df_SellPrice0.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df_SellPrice0['month'], df_SellPrice0['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge and save part 2\n",
    "OriginalCol = list(df_grid)\n",
    "df_grid = df_grid.merge(df_SellPrice0, on=['store_id','item_id','wm_yr_wk'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage decreased from 2192.27 Mb to 1924.01 Mb (12.2% reduction)\n",
      "Size of grid_part_2: (46881677, 15)\n"
     ]
    }
   ],
   "source": [
    "KeepCol = [col for col in list(df_grid) if col not in OriginalCol]\n",
    "df_grid = df_grid[MAIN_INDEX+KeepCol]\n",
    "df_grid = reduce_mem_usage(df_grid)\n",
    "print('Size of grid_part_2: {}'.format(df_grid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid.to_pickle(FilePath+'grid_part_2.pkl')\n",
    "# print('Size of grid_part_2: {}'.format(df_grid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df_SellPrice0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the df_grid from part 1\n",
    "# some features from part 2 are not needed\n",
    "df_grid = pd.read_pickle(FilePath+'grid_part_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid = df_grid[MAIN_INDEX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calendar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "icols = ['date', 'd', 'event_name_1', 'event_type_1', 'event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid = df_grid.merge(df_calendar0[icols], on=['d'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "icols = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "for col in icols:\n",
    "    df_grid[col] = df_grid[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid['date'] = pd.to_datetime(df_grid['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features from date\n",
    "df_grid['tm_d'] = df_grid['date'].dt.day.astype(np.int8)\n",
    "df_grid['tm_w'] = df_grid['date'].dt.week.astype(np.int8)\n",
    "df_grid['tm_m'] = df_grid['date'].dt.month.astype(np.int8)\n",
    "# find our which year it is\n",
    "df_grid['tm_y'] = df_grid['date'].dt.year\n",
    "df_grid['tm_y'] = (df_grid['tm_y'] - df_grid['tm_y'].min()).astype(np.int8)\n",
    "# Monday=0, Sunday=6\n",
    "df_grid['tm_dw'] = df_grid['date'].dt.dayofweek.astype(np.int8)\n",
    "\n",
    "df_grid['tm_wm'] = df_grid['tm_d'].apply(lambda x: ceil(x/7)).astype(np.int8)\n",
    "df_grid['tm_w_end'] = (df_grid['tm_dw']>=5).astype(np.int8) # find weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove date\n",
    "# del df_grid['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of grid_part_3: (46881677, 17)\n"
     ]
    }
   ],
   "source": [
    "# Safe part 3\n",
    "df_grid.to_pickle(FilePath+'grid_part_3.pkl')\n",
    "print('Size of grid_part_3: {}'.format(df_grid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need calendar_df anymore\n",
    "# del df_calendar0\n",
    "# del df_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MainData/grid_part123.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-5896ecd02bc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbasic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFilePath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'grid_part123.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# 1) try standard library Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MainData/grid_part123.pkl'"
     ]
    }
   ],
   "source": [
    "basic = pd.read_pickle(FilePath+'grid_part123.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>release</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>price_std</th>\n",
       "      <th>price_mean</th>\n",
       "      <th>price_norm</th>\n",
       "      <th>price_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>price_momentum_m</th>\n",
       "      <th>price_momentum_y</th>\n",
       "      <th>price_momentum</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>tm_d</th>\n",
       "      <th>tm_w</th>\n",
       "      <th>tm_m</th>\n",
       "      <th>tm_y</th>\n",
       "      <th>tm_dw</th>\n",
       "      <th>tm_wm</th>\n",
       "      <th>tm_w_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11101</td>\n",
       "      <td>11101</td>\n",
       "      <td>0.459961</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>0.019791</td>\n",
       "      <td>0.476318</td>\n",
       "      <td>0.919922</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.949707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_009</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11101</td>\n",
       "      <td>11101</td>\n",
       "      <td>1.559570</td>\n",
       "      <td>1.769531</td>\n",
       "      <td>1.559570</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>1.764648</td>\n",
       "      <td>0.881348</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.885742</td>\n",
       "      <td>0.896484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_010_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_010</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11101</td>\n",
       "      <td>11101</td>\n",
       "      <td>3.169922</td>\n",
       "      <td>3.169922</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>2.982422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.064453</td>\n",
       "      <td>1.043945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_012_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_012</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11101</td>\n",
       "      <td>11101</td>\n",
       "      <td>5.980469</td>\n",
       "      <td>6.519531</td>\n",
       "      <td>5.980469</td>\n",
       "      <td>0.115906</td>\n",
       "      <td>6.468750</td>\n",
       "      <td>0.917480</td>\n",
       "      <td>3.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.922363</td>\n",
       "      <td>0.959473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_015_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_015</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11101</td>\n",
       "      <td>11101</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>0.720215</td>\n",
       "      <td>0.680176</td>\n",
       "      <td>0.011353</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.972168</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.990234</td>\n",
       "      <td>1.001953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_009_CA_1_validation  HOBBIES_1_009  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_010_CA_1_validation  HOBBIES_1_010  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_012_CA_1_validation  HOBBIES_1_012  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_015_CA_1_validation  HOBBIES_1_015  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d  sales  release  wm_yr_wk  sell_price  price_max  price_min  \\\n",
       "0       CA  1   12.0    11101     11101    0.459961   0.500000   0.419922   \n",
       "1       CA  1    2.0    11101     11101    1.559570   1.769531   1.559570   \n",
       "2       CA  1    0.0    11101     11101    3.169922   3.169922   2.970703   \n",
       "3       CA  1    0.0    11101     11101    5.980469   6.519531   5.980469   \n",
       "4       CA  1    4.0    11101     11101    0.700195   0.720215   0.680176   \n",
       "\n",
       "   price_std  price_mean  price_norm  price_nunique  item_nunique  \\\n",
       "0   0.019791    0.476318    0.919922            4.0            16   \n",
       "1   0.032715    1.764648    0.881348            2.0             9   \n",
       "2   0.046173    2.982422    1.000000            2.0            20   \n",
       "3   0.115906    6.468750    0.917480            3.0            71   \n",
       "4   0.011353    0.707031    0.972168            3.0            16   \n",
       "\n",
       "   price_momentum_m  price_momentum_y  price_momentum event_name_1  \\\n",
       "0          0.968750          0.949707             NaN          NaN   \n",
       "1          0.885742          0.896484             NaN          NaN   \n",
       "2          1.064453          1.043945             NaN          NaN   \n",
       "3          0.922363          0.959473             NaN          NaN   \n",
       "4          0.990234          1.001953             NaN          NaN   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2 snap_CA snap_TX snap_WI  tm_d  tm_w  \\\n",
       "0          NaN          NaN          NaN       0       0       0    29     4   \n",
       "1          NaN          NaN          NaN       0       0       0    29     4   \n",
       "2          NaN          NaN          NaN       0       0       0    29     4   \n",
       "3          NaN          NaN          NaN       0       0       0    29     4   \n",
       "4          NaN          NaN          NaN       0       0       0    29     4   \n",
       "\n",
       "   tm_m  tm_y  tm_dw  tm_wm  tm_w_end  \n",
       "0     1     0      5      5         1  \n",
       "1     1     0      5      5         1  \n",
       "2     1     0      5      5         1  \n",
       "3     1     0      5      5         1  \n",
       "4     1     0      5      5         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
