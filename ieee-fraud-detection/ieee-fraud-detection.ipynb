{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/neptune-ml/kaggle-ieee-fraud-detection/blob/master/notebooks/0.0-kaggle_kernel_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset has 590540 rows and 434 columns.\n",
      "Test dataset has 506691 rows and 433 columns.\n"
     ]
    }
   ],
   "source": [
    "raw_data_path = 'data/'\n",
    "nrows = 10000\n",
    "\n",
    "'''\n",
    "train_identity = pd.read_csv(f'{raw_data_path}train_identity.csv',nrows=nrows)\n",
    "train_transaction = pd.read_csv(f'{raw_data_path}train_transaction.csv',nrows=nrows)\n",
    "test_identity = pd.read_csv(f'{raw_data_path}test_identity.csv',nrows=nrows)\n",
    "test_transaction = pd.read_csv(f'{raw_data_path}test_transaction.csv',nrows=nrows)\n",
    "sub = pd.read_csv(f'{raw_data_path}sample_submission.csv',nrows=nrows)\n",
    "'''\n",
    "train_identity = pd.read_csv(f'{raw_data_path}train_identity.csv')\n",
    "train_transaction = pd.read_csv(f'{raw_data_path}train_transaction.csv')\n",
    "test_identity = pd.read_csv(f'{raw_data_path}test_identity.csv')\n",
    "test_transaction = pd.read_csv(f'{raw_data_path}test_transaction.csv')\n",
    "sub = pd.read_csv(f'{raw_data_path}sample_submission.csv')\n",
    "# let's combine the data and work with the whole dataset\n",
    "train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\n",
    "\n",
    "print(f'Train dataset has {train.shape[0]} rows and {train.shape[1]} columns.')\n",
    "print(f'Test dataset has {test.shape[0]} rows and {test.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TransactionAmt_to_mean_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "train['TransactionAmt_to_mean_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "train['TransactionAmt_to_std_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "train['TransactionAmt_to_std_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "test['TransactionAmt_to_mean_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "test['TransactionAmt_to_mean_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "test['TransactionAmt_to_std_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "test['TransactionAmt_to_std_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "train['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\n",
    "train['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\n",
    "train['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "test['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\n",
    "test['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\n",
    "test['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "train['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "\n",
    "train['dist1_to_mean_card1'] = train['dist1'] / train.groupby(['card1'])['dist1'].transform('mean')\n",
    "train['dist1_to_mean_card4'] = train['dist1'] / train.groupby(['card4'])['dist1'].transform('mean')\n",
    "train['dist1_to_std_card1'] = train['dist1'] / train.groupby(['card1'])['dist1'].transform('std')\n",
    "train['dist1_to_std_card4'] = train['dist1'] / train.groupby(['card4'])['dist1'].transform('std')\n",
    "\n",
    "test['dist1_to_mean_card1'] = test['dist1'] / test.groupby(['card1'])['dist1'].transform('mean')\n",
    "test['dist1_to_mean_card4'] = test['dist1'] / test.groupby(['card4'])['dist1'].transform('mean')\n",
    "test['dist1_to_std_card1'] = test['dist1'] / test.groupby(['card1'])['dist1'].transform('std')\n",
    "test['dist1_to_std_card4'] = test['dist1'] / test.groupby(['card4'])['dist1'].transform('std')\n",
    "\n",
    "\n",
    "train['D4_to_mean_card1'] = train['D4'] / train.groupby(['card1'])['D4'].transform('mean')\n",
    "train['D4_to_mean_card4'] = train['D4'] / train.groupby(['card4'])['D4'].transform('mean')\n",
    "train['D4_to_std_card1'] = train['D4'] / train.groupby(['card1'])['D4'].transform('std')\n",
    "train['D4_to_std_card4'] = train['D4'] / train.groupby(['card4'])['D4'].transform('std')\n",
    "\n",
    "test['D4_to_mean_card1'] = test['D4'] / test.groupby(['card1'])['D4'].transform('mean')\n",
    "test['D4_to_mean_card4'] = test['D4'] / test.groupby(['card4'])['D4'].transform('mean')\n",
    "test['D4_to_std_card1'] = test['D4'] / test.groupby(['card1'])['D4'].transform('std')\n",
    "test['D4_to_std_card4'] = test['D4'] / test.groupby(['card4'])['D4'].transform('std')\n",
    "\n",
    "train['card1_count'] = train.groupby(['card1'])['TransactionID'].transform('count')\n",
    "train['card2_count'] = train.groupby(['card2'])['TransactionID'].transform('count')\n",
    "train['card4_count'] = train.groupby(['card4'])['TransactionID'].transform('count')\n",
    "\n",
    "test['card1_count'] = test.groupby(['card1'])['TransactionID'].transform('count')\n",
    "test['card2_count'] = test.groupby(['card2'])['TransactionID'].transform('count')\n",
    "test['card4_count'] = test.groupby(['card4'])['TransactionID'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_null_cols = [col for col in train.columns if train[col].isnull().sum() / train.shape[0] > 0.9]\n",
    "many_null_cols_test = [col for col in test.columns if test[col].isnull().sum() / test.shape[0] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "big_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_value_cols = [col for col in train.columns if train[col].nunique() <= 1]\n",
    "one_value_cols_test = [col for col in test.columns if test[col].nunique() <= 1]\n",
    "one_value_cols == one_value_cols_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols+ one_value_cols_test))\n",
    "len(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop.remove('isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(cols_to_drop, axis=1)\n",
    "test = test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n",
    "            'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n",
    "            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
    "for col in cat_cols:\n",
    "    if col in train.columns:\n",
    "        train = train.drop([col], axis=1)\n",
    "        test = test.drop([col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data_path = '../output/features/'\n",
    "os.makedirs(features_data_path, exist_ok=True)\n",
    "\n",
    "train_features_path = f'{features_data_path}train_features_v0.csv'\n",
    "test_features_path = f'{features_data_path}test_features_v0.csv'\n",
    "\n",
    "train.to_csv(train_features_path, index=None)\n",
    "test.to_csv(test_features_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n",
    "y = train.sort_values('TransactionDT')['isFraud']\n",
    "X_test = test.sort_values('TransactionDT').drop(['TransactionDT', 'TransactionID'], axis=1)\n",
    "\n",
    "train = train[[\"TransactionDT\", 'TransactionID']]\n",
    "test = test[[\"TransactionDT\", 'TransactionID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "validation_params = {'seed':1234,\n",
    "                     'n_folds':5,\n",
    "                     'validation_schema': 'kfold'}\n",
    "\n",
    "folds = KFold(n_splits=validation_params['n_folds'], random_state=validation_params['seed'])\n",
    "'''\n",
    "validation_params = {'seed':1234,\n",
    "                     'n_folds':5,\n",
    "                     'validation_schema': 'kfold'}\n",
    "\n",
    "folds = TimeSeriesSplit(n_splits = validation_params['n_folds'])\n",
    "#folds = KFold(n_splits=validation_params['n_folds'], random_state=validation_params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_fold = 5\\nfolds = TimeSeriesSplit(n_splits=n_fold)\\nfolds = KFold(n_splits=5)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "n_fold = 5\n",
    "folds = TimeSeriesSplit(n_splits=n_fold)\n",
    "folds = KFold(n_splits=5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'num_leaves': 256,\n",
    "                  'min_child_samples': 79,\n",
    "                  'objective': 'binary',\n",
    "                  'max_depth': 15,\n",
    "                  'learning_rate': 0.02,\n",
    "                  \"boosting_type\": \"gbdt\",\n",
    "                  \"subsample_freq\": 3,\n",
    "                  \"subsample\": 0.9,\n",
    "                  \"bagging_seed\": 11,\n",
    "                  \"metric\": 'auc',\n",
    "                  \"verbosity\": -1,\n",
    "                  'reg_alpha': 0.3,\n",
    "                  'reg_lambda': 0.3,\n",
    "                  'colsample_bytree': 0.9\n",
    "                 }\n",
    "\n",
    "training_params = {'num_boosting_rounds':5000,\n",
    "                   'early_stopping_rounds':200\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={**model_params, **training_params,**validation_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(X, y, X_test, folds, model_params, training_params):\n",
    "    in_fold, out_of_fold, test_preds = np.zeros(len(X)), np.zeros(len(X)), np.zeros(len(X_test))\n",
    "    for fold_nr, (trn_idx, val_idx) in enumerate(folds.split(X.values, y.values)):\n",
    "        print(\"Fold {}\".format(fold_nr))\n",
    "\n",
    "        X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        trn_data = lgb.Dataset(X_train, y_train)\n",
    "        val_data = lgb.Dataset(X_valid, y_valid)\n",
    "        \n",
    "        # add live monitoring of lightgbm learning curves\n",
    "        #monitor = neptune_monitor(prefix='fold{}_'.format(fold_nr))\n",
    "        clf = lgb.train(model_params, trn_data, \n",
    "                        training_params['num_boosting_rounds'], \n",
    "                        valid_sets = [trn_data, val_data], \n",
    "                        early_stopping_rounds = training_params['early_stopping_rounds'])\n",
    "                        #,callbacks=[monitor])\n",
    "        in_fold[trn_idx] = clf.predict(X.iloc[trn_idx], num_iteration=clf.best_iteration)\n",
    "        out_of_fold[val_idx] = clf.predict(X.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        test_preds += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    return in_fold, out_of_fold, test_preds    \n",
    "\n",
    "def fmt_preds(y_pred):\n",
    "    return np.concatenate((1.0-y_pred.reshape(-1,1), y_pred.reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_data_path = '../output/predictions/'\n",
    "os.makedirs(predictions_data_path, exist_ok=True)\n",
    "\n",
    "train_predictions_path = f'{predictions_data_path}train_predictions_v0.csv'\n",
    "test_predictions_path = f'{predictions_data_path}test_predictions_v0.csv'\n",
    "submission_path = f'submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'submission.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[1]\ttraining's auc: 0.908197\tvalid_1's auc: 0.803298\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\ttraining's auc: 0.91967\tvalid_1's auc: 0.828875\n",
      "[3]\ttraining's auc: 0.922963\tvalid_1's auc: 0.842242\n",
      "[4]\ttraining's auc: 0.932331\tvalid_1's auc: 0.84701\n",
      "[5]\ttraining's auc: 0.933942\tvalid_1's auc: 0.850045\n",
      "[6]\ttraining's auc: 0.934785\tvalid_1's auc: 0.851804\n",
      "[7]\ttraining's auc: 0.935963\tvalid_1's auc: 0.85367\n",
      "[8]\ttraining's auc: 0.936603\tvalid_1's auc: 0.856992\n",
      "[9]\ttraining's auc: 0.937149\tvalid_1's auc: 0.857097\n",
      "[10]\ttraining's auc: 0.938239\tvalid_1's auc: 0.858476\n",
      "[11]\ttraining's auc: 0.938842\tvalid_1's auc: 0.859679\n",
      "[12]\ttraining's auc: 0.939998\tvalid_1's auc: 0.859967\n",
      "[13]\ttraining's auc: 0.940841\tvalid_1's auc: 0.861054\n",
      "[14]\ttraining's auc: 0.94091\tvalid_1's auc: 0.861653\n",
      "[15]\ttraining's auc: 0.941295\tvalid_1's auc: 0.862082\n",
      "[16]\ttraining's auc: 0.941973\tvalid_1's auc: 0.863249\n",
      "[17]\ttraining's auc: 0.942481\tvalid_1's auc: 0.863412\n",
      "[18]\ttraining's auc: 0.94308\tvalid_1's auc: 0.863226\n",
      "[19]\ttraining's auc: 0.943944\tvalid_1's auc: 0.864248\n",
      "[20]\ttraining's auc: 0.944663\tvalid_1's auc: 0.864297\n",
      "[21]\ttraining's auc: 0.944931\tvalid_1's auc: 0.864663\n",
      "[22]\ttraining's auc: 0.945736\tvalid_1's auc: 0.865777\n",
      "[23]\ttraining's auc: 0.946805\tvalid_1's auc: 0.866258\n",
      "[24]\ttraining's auc: 0.947463\tvalid_1's auc: 0.866645\n",
      "[25]\ttraining's auc: 0.948337\tvalid_1's auc: 0.866787\n",
      "[26]\ttraining's auc: 0.948815\tvalid_1's auc: 0.867138\n",
      "[27]\ttraining's auc: 0.949893\tvalid_1's auc: 0.868114\n",
      "[28]\ttraining's auc: 0.950656\tvalid_1's auc: 0.868668\n",
      "[29]\ttraining's auc: 0.951734\tvalid_1's auc: 0.869028\n",
      "[30]\ttraining's auc: 0.952279\tvalid_1's auc: 0.869514\n",
      "[31]\ttraining's auc: 0.952846\tvalid_1's auc: 0.869913\n",
      "[32]\ttraining's auc: 0.953403\tvalid_1's auc: 0.870268\n",
      "[33]\ttraining's auc: 0.9538\tvalid_1's auc: 0.870354\n",
      "[34]\ttraining's auc: 0.954275\tvalid_1's auc: 0.870423\n",
      "[35]\ttraining's auc: 0.955005\tvalid_1's auc: 0.870762\n",
      "[36]\ttraining's auc: 0.955316\tvalid_1's auc: 0.870698\n",
      "[37]\ttraining's auc: 0.955496\tvalid_1's auc: 0.870533\n",
      "[38]\ttraining's auc: 0.955864\tvalid_1's auc: 0.870376\n",
      "[39]\ttraining's auc: 0.956118\tvalid_1's auc: 0.870409\n",
      "[40]\ttraining's auc: 0.956584\tvalid_1's auc: 0.870738\n",
      "[41]\ttraining's auc: 0.957408\tvalid_1's auc: 0.87093\n",
      "[42]\ttraining's auc: 0.95808\tvalid_1's auc: 0.870939\n",
      "[43]\ttraining's auc: 0.9584\tvalid_1's auc: 0.871354\n",
      "[44]\ttraining's auc: 0.959299\tvalid_1's auc: 0.871677\n",
      "[45]\ttraining's auc: 0.959673\tvalid_1's auc: 0.871994\n",
      "[46]\ttraining's auc: 0.960194\tvalid_1's auc: 0.872159\n",
      "[47]\ttraining's auc: 0.960842\tvalid_1's auc: 0.872482\n",
      "[48]\ttraining's auc: 0.961424\tvalid_1's auc: 0.872732\n",
      "[49]\ttraining's auc: 0.961554\tvalid_1's auc: 0.87286\n",
      "[50]\ttraining's auc: 0.961807\tvalid_1's auc: 0.872965\n",
      "[51]\ttraining's auc: 0.962331\tvalid_1's auc: 0.873076\n",
      "[52]\ttraining's auc: 0.962687\tvalid_1's auc: 0.873066\n",
      "[53]\ttraining's auc: 0.962964\tvalid_1's auc: 0.873293\n",
      "[54]\ttraining's auc: 0.963075\tvalid_1's auc: 0.873461\n",
      "[55]\ttraining's auc: 0.963429\tvalid_1's auc: 0.873591\n",
      "[56]\ttraining's auc: 0.963966\tvalid_1's auc: 0.873593\n",
      "[57]\ttraining's auc: 0.964481\tvalid_1's auc: 0.87381\n",
      "[58]\ttraining's auc: 0.96513\tvalid_1's auc: 0.874238\n",
      "[59]\ttraining's auc: 0.96574\tvalid_1's auc: 0.874326\n",
      "[60]\ttraining's auc: 0.966181\tvalid_1's auc: 0.874594\n",
      "[61]\ttraining's auc: 0.966933\tvalid_1's auc: 0.874524\n",
      "[62]\ttraining's auc: 0.967543\tvalid_1's auc: 0.874571\n",
      "[63]\ttraining's auc: 0.968177\tvalid_1's auc: 0.874518\n",
      "[64]\ttraining's auc: 0.968589\tvalid_1's auc: 0.874932\n",
      "[65]\ttraining's auc: 0.969137\tvalid_1's auc: 0.875264\n",
      "[66]\ttraining's auc: 0.969722\tvalid_1's auc: 0.875322\n",
      "[67]\ttraining's auc: 0.970187\tvalid_1's auc: 0.875467\n",
      "[68]\ttraining's auc: 0.970795\tvalid_1's auc: 0.87561\n",
      "[69]\ttraining's auc: 0.971365\tvalid_1's auc: 0.875545\n",
      "[70]\ttraining's auc: 0.971936\tvalid_1's auc: 0.87547\n",
      "[71]\ttraining's auc: 0.972346\tvalid_1's auc: 0.875514\n",
      "[72]\ttraining's auc: 0.972569\tvalid_1's auc: 0.87544\n",
      "[73]\ttraining's auc: 0.973095\tvalid_1's auc: 0.875525\n",
      "[74]\ttraining's auc: 0.973395\tvalid_1's auc: 0.875634\n",
      "[75]\ttraining's auc: 0.973994\tvalid_1's auc: 0.875735\n",
      "[76]\ttraining's auc: 0.974527\tvalid_1's auc: 0.876097\n",
      "[77]\ttraining's auc: 0.975017\tvalid_1's auc: 0.87641\n",
      "[78]\ttraining's auc: 0.975481\tvalid_1's auc: 0.876444\n",
      "[79]\ttraining's auc: 0.975797\tvalid_1's auc: 0.876497\n",
      "[80]\ttraining's auc: 0.976321\tvalid_1's auc: 0.876497\n",
      "[81]\ttraining's auc: 0.976751\tvalid_1's auc: 0.876672\n",
      "[82]\ttraining's auc: 0.977106\tvalid_1's auc: 0.876644\n",
      "[83]\ttraining's auc: 0.977604\tvalid_1's auc: 0.876645\n",
      "[84]\ttraining's auc: 0.978013\tvalid_1's auc: 0.876701\n",
      "[85]\ttraining's auc: 0.978357\tvalid_1's auc: 0.876756\n",
      "[86]\ttraining's auc: 0.978743\tvalid_1's auc: 0.87671\n",
      "[87]\ttraining's auc: 0.979057\tvalid_1's auc: 0.876794\n",
      "[88]\ttraining's auc: 0.979564\tvalid_1's auc: 0.877186\n",
      "[89]\ttraining's auc: 0.980078\tvalid_1's auc: 0.877617\n",
      "[90]\ttraining's auc: 0.980604\tvalid_1's auc: 0.877882\n",
      "[91]\ttraining's auc: 0.981031\tvalid_1's auc: 0.878254\n",
      "[92]\ttraining's auc: 0.981519\tvalid_1's auc: 0.878627\n",
      "[93]\ttraining's auc: 0.981865\tvalid_1's auc: 0.878829\n",
      "[94]\ttraining's auc: 0.982129\tvalid_1's auc: 0.878978\n",
      "[95]\ttraining's auc: 0.982438\tvalid_1's auc: 0.879049\n",
      "[96]\ttraining's auc: 0.982764\tvalid_1's auc: 0.87928\n",
      "[97]\ttraining's auc: 0.983106\tvalid_1's auc: 0.879367\n",
      "[98]\ttraining's auc: 0.983401\tvalid_1's auc: 0.879515\n",
      "[99]\ttraining's auc: 0.983648\tvalid_1's auc: 0.879595\n",
      "[100]\ttraining's auc: 0.984045\tvalid_1's auc: 0.879936\n",
      "[101]\ttraining's auc: 0.984403\tvalid_1's auc: 0.880159\n",
      "[102]\ttraining's auc: 0.984748\tvalid_1's auc: 0.880356\n",
      "[103]\ttraining's auc: 0.985074\tvalid_1's auc: 0.880589\n",
      "[104]\ttraining's auc: 0.985376\tvalid_1's auc: 0.880785\n",
      "[105]\ttraining's auc: 0.985673\tvalid_1's auc: 0.880825\n",
      "[106]\ttraining's auc: 0.985949\tvalid_1's auc: 0.881083\n",
      "[107]\ttraining's auc: 0.986206\tvalid_1's auc: 0.881138\n",
      "[108]\ttraining's auc: 0.986455\tvalid_1's auc: 0.881291\n",
      "[109]\ttraining's auc: 0.986772\tvalid_1's auc: 0.881443\n",
      "[110]\ttraining's auc: 0.987097\tvalid_1's auc: 0.88146\n",
      "[111]\ttraining's auc: 0.987315\tvalid_1's auc: 0.88157\n",
      "[112]\ttraining's auc: 0.987576\tvalid_1's auc: 0.881887\n",
      "[113]\ttraining's auc: 0.987792\tvalid_1's auc: 0.88217\n",
      "[114]\ttraining's auc: 0.988033\tvalid_1's auc: 0.882347\n",
      "[115]\ttraining's auc: 0.988217\tvalid_1's auc: 0.882414\n",
      "[116]\ttraining's auc: 0.988478\tvalid_1's auc: 0.882595\n",
      "[117]\ttraining's auc: 0.988589\tvalid_1's auc: 0.882894\n",
      "[118]\ttraining's auc: 0.988789\tvalid_1's auc: 0.883074\n",
      "[119]\ttraining's auc: 0.988954\tvalid_1's auc: 0.883308\n",
      "[120]\ttraining's auc: 0.989133\tvalid_1's auc: 0.883378\n",
      "[121]\ttraining's auc: 0.989348\tvalid_1's auc: 0.883641\n",
      "[122]\ttraining's auc: 0.989545\tvalid_1's auc: 0.883788\n",
      "[123]\ttraining's auc: 0.98972\tvalid_1's auc: 0.883971\n",
      "[124]\ttraining's auc: 0.98983\tvalid_1's auc: 0.884129\n",
      "[125]\ttraining's auc: 0.989914\tvalid_1's auc: 0.884263\n",
      "[126]\ttraining's auc: 0.990033\tvalid_1's auc: 0.884369\n",
      "[127]\ttraining's auc: 0.990102\tvalid_1's auc: 0.884522\n",
      "[128]\ttraining's auc: 0.990173\tvalid_1's auc: 0.884695\n",
      "[129]\ttraining's auc: 0.990249\tvalid_1's auc: 0.884748\n",
      "[130]\ttraining's auc: 0.99036\tvalid_1's auc: 0.88502\n",
      "[131]\ttraining's auc: 0.990463\tvalid_1's auc: 0.885183\n",
      "[132]\ttraining's auc: 0.990559\tvalid_1's auc: 0.885399\n",
      "[133]\ttraining's auc: 0.990751\tvalid_1's auc: 0.885444\n",
      "[134]\ttraining's auc: 0.990949\tvalid_1's auc: 0.885539\n",
      "[135]\ttraining's auc: 0.991178\tvalid_1's auc: 0.885693\n",
      "[136]\ttraining's auc: 0.991273\tvalid_1's auc: 0.885803\n",
      "[137]\ttraining's auc: 0.99135\tvalid_1's auc: 0.88594\n",
      "[138]\ttraining's auc: 0.99142\tvalid_1's auc: 0.886048\n",
      "[139]\ttraining's auc: 0.991512\tvalid_1's auc: 0.886009\n",
      "[140]\ttraining's auc: 0.991557\tvalid_1's auc: 0.886077\n",
      "[141]\ttraining's auc: 0.991619\tvalid_1's auc: 0.8862\n",
      "[142]\ttraining's auc: 0.991742\tvalid_1's auc: 0.88635\n",
      "[143]\ttraining's auc: 0.991842\tvalid_1's auc: 0.886523\n",
      "[144]\ttraining's auc: 0.991949\tvalid_1's auc: 0.886541\n",
      "[145]\ttraining's auc: 0.992028\tvalid_1's auc: 0.886672\n",
      "[146]\ttraining's auc: 0.992066\tvalid_1's auc: 0.886708\n",
      "[147]\ttraining's auc: 0.99213\tvalid_1's auc: 0.886818\n",
      "[148]\ttraining's auc: 0.992206\tvalid_1's auc: 0.886902\n",
      "[149]\ttraining's auc: 0.992282\tvalid_1's auc: 0.886979\n",
      "[150]\ttraining's auc: 0.992351\tvalid_1's auc: 0.887017\n",
      "[151]\ttraining's auc: 0.992418\tvalid_1's auc: 0.887129\n",
      "[152]\ttraining's auc: 0.99247\tvalid_1's auc: 0.887216\n",
      "[153]\ttraining's auc: 0.992517\tvalid_1's auc: 0.887279\n",
      "[154]\ttraining's auc: 0.992552\tvalid_1's auc: 0.887372\n",
      "[155]\ttraining's auc: 0.992578\tvalid_1's auc: 0.887353\n",
      "[156]\ttraining's auc: 0.992627\tvalid_1's auc: 0.887418\n",
      "[157]\ttraining's auc: 0.992672\tvalid_1's auc: 0.887503\n",
      "[158]\ttraining's auc: 0.992747\tvalid_1's auc: 0.88749\n",
      "[159]\ttraining's auc: 0.992791\tvalid_1's auc: 0.887555\n",
      "[160]\ttraining's auc: 0.992865\tvalid_1's auc: 0.887569\n",
      "[161]\ttraining's auc: 0.992943\tvalid_1's auc: 0.887614\n",
      "[162]\ttraining's auc: 0.993023\tvalid_1's auc: 0.887722\n",
      "[163]\ttraining's auc: 0.993077\tvalid_1's auc: 0.887754\n",
      "[164]\ttraining's auc: 0.993124\tvalid_1's auc: 0.887817\n",
      "[165]\ttraining's auc: 0.993159\tvalid_1's auc: 0.887826\n",
      "[166]\ttraining's auc: 0.993233\tvalid_1's auc: 0.887947\n",
      "[167]\ttraining's auc: 0.993289\tvalid_1's auc: 0.888019\n",
      "[168]\ttraining's auc: 0.993315\tvalid_1's auc: 0.88806\n",
      "[169]\ttraining's auc: 0.993367\tvalid_1's auc: 0.888076\n",
      "[170]\ttraining's auc: 0.993453\tvalid_1's auc: 0.888137\n",
      "[171]\ttraining's auc: 0.993491\tvalid_1's auc: 0.888152\n",
      "[172]\ttraining's auc: 0.993518\tvalid_1's auc: 0.888215\n",
      "[173]\ttraining's auc: 0.993546\tvalid_1's auc: 0.88825\n",
      "[174]\ttraining's auc: 0.993567\tvalid_1's auc: 0.888194\n",
      "[175]\ttraining's auc: 0.993585\tvalid_1's auc: 0.888289\n",
      "[176]\ttraining's auc: 0.993619\tvalid_1's auc: 0.88837\n",
      "[177]\ttraining's auc: 0.993639\tvalid_1's auc: 0.888374\n",
      "[178]\ttraining's auc: 0.993677\tvalid_1's auc: 0.888387\n",
      "[179]\ttraining's auc: 0.99373\tvalid_1's auc: 0.888425\n",
      "[180]\ttraining's auc: 0.993766\tvalid_1's auc: 0.88845\n",
      "[181]\ttraining's auc: 0.993814\tvalid_1's auc: 0.888584\n",
      "[182]\ttraining's auc: 0.993839\tvalid_1's auc: 0.888636\n",
      "[183]\ttraining's auc: 0.993859\tvalid_1's auc: 0.888709\n",
      "[184]\ttraining's auc: 0.993899\tvalid_1's auc: 0.888751\n",
      "[185]\ttraining's auc: 0.993949\tvalid_1's auc: 0.888804\n",
      "[186]\ttraining's auc: 0.993981\tvalid_1's auc: 0.888855\n",
      "[187]\ttraining's auc: 0.994029\tvalid_1's auc: 0.888795\n",
      "[188]\ttraining's auc: 0.994091\tvalid_1's auc: 0.888733\n",
      "[189]\ttraining's auc: 0.994128\tvalid_1's auc: 0.888668\n",
      "[190]\ttraining's auc: 0.994161\tvalid_1's auc: 0.888676\n",
      "[191]\ttraining's auc: 0.994227\tvalid_1's auc: 0.888726\n",
      "[192]\ttraining's auc: 0.994293\tvalid_1's auc: 0.888753\n",
      "[193]\ttraining's auc: 0.99436\tvalid_1's auc: 0.888796\n",
      "[194]\ttraining's auc: 0.994422\tvalid_1's auc: 0.88884\n",
      "[195]\ttraining's auc: 0.994477\tvalid_1's auc: 0.888866\n",
      "[196]\ttraining's auc: 0.994567\tvalid_1's auc: 0.888916\n",
      "[197]\ttraining's auc: 0.994651\tvalid_1's auc: 0.889019\n",
      "[198]\ttraining's auc: 0.994708\tvalid_1's auc: 0.889013\n",
      "[199]\ttraining's auc: 0.994766\tvalid_1's auc: 0.889072\n",
      "[200]\ttraining's auc: 0.994778\tvalid_1's auc: 0.889059\n",
      "[201]\ttraining's auc: 0.994795\tvalid_1's auc: 0.889092\n",
      "[202]\ttraining's auc: 0.994862\tvalid_1's auc: 0.889068\n",
      "[203]\ttraining's auc: 0.994902\tvalid_1's auc: 0.88901\n",
      "[204]\ttraining's auc: 0.994938\tvalid_1's auc: 0.888963\n",
      "[205]\ttraining's auc: 0.994955\tvalid_1's auc: 0.888999\n",
      "[206]\ttraining's auc: 0.994982\tvalid_1's auc: 0.889004\n",
      "[207]\ttraining's auc: 0.995035\tvalid_1's auc: 0.889065\n",
      "[208]\ttraining's auc: 0.995063\tvalid_1's auc: 0.889093\n",
      "[209]\ttraining's auc: 0.995106\tvalid_1's auc: 0.889141\n",
      "[210]\ttraining's auc: 0.995132\tvalid_1's auc: 0.88924\n",
      "[211]\ttraining's auc: 0.995163\tvalid_1's auc: 0.889205\n",
      "[212]\ttraining's auc: 0.995182\tvalid_1's auc: 0.889185\n",
      "[213]\ttraining's auc: 0.995206\tvalid_1's auc: 0.889203\n",
      "[214]\ttraining's auc: 0.995255\tvalid_1's auc: 0.889225\n",
      "[215]\ttraining's auc: 0.995295\tvalid_1's auc: 0.889338\n",
      "[216]\ttraining's auc: 0.995342\tvalid_1's auc: 0.889491\n",
      "[217]\ttraining's auc: 0.995352\tvalid_1's auc: 0.889499\n",
      "[218]\ttraining's auc: 0.995392\tvalid_1's auc: 0.889519\n",
      "[219]\ttraining's auc: 0.995423\tvalid_1's auc: 0.889515\n",
      "[220]\ttraining's auc: 0.995428\tvalid_1's auc: 0.889513\n",
      "[221]\ttraining's auc: 0.995441\tvalid_1's auc: 0.889549\n",
      "[222]\ttraining's auc: 0.995446\tvalid_1's auc: 0.889513\n",
      "[223]\ttraining's auc: 0.995494\tvalid_1's auc: 0.889643\n",
      "[224]\ttraining's auc: 0.995534\tvalid_1's auc: 0.889697\n",
      "[225]\ttraining's auc: 0.995593\tvalid_1's auc: 0.889801\n",
      "[226]\ttraining's auc: 0.995652\tvalid_1's auc: 0.889772\n",
      "[227]\ttraining's auc: 0.99568\tvalid_1's auc: 0.889727\n",
      "[228]\ttraining's auc: 0.995701\tvalid_1's auc: 0.889763\n",
      "[229]\ttraining's auc: 0.995748\tvalid_1's auc: 0.88975\n",
      "[230]\ttraining's auc: 0.995783\tvalid_1's auc: 0.889797\n",
      "[231]\ttraining's auc: 0.995812\tvalid_1's auc: 0.889808\n",
      "[232]\ttraining's auc: 0.995848\tvalid_1's auc: 0.889813\n",
      "[233]\ttraining's auc: 0.995864\tvalid_1's auc: 0.889731\n",
      "[234]\ttraining's auc: 0.995892\tvalid_1's auc: 0.8897\n",
      "[235]\ttraining's auc: 0.995909\tvalid_1's auc: 0.889704\n",
      "[236]\ttraining's auc: 0.995916\tvalid_1's auc: 0.889688\n",
      "[237]\ttraining's auc: 0.995928\tvalid_1's auc: 0.889656\n",
      "[238]\ttraining's auc: 0.995945\tvalid_1's auc: 0.889672\n",
      "[239]\ttraining's auc: 0.99596\tvalid_1's auc: 0.889694\n",
      "[240]\ttraining's auc: 0.996011\tvalid_1's auc: 0.889619\n",
      "[241]\ttraining's auc: 0.996023\tvalid_1's auc: 0.889595\n",
      "[242]\ttraining's auc: 0.996028\tvalid_1's auc: 0.889608\n",
      "[243]\ttraining's auc: 0.996043\tvalid_1's auc: 0.889597\n",
      "[244]\ttraining's auc: 0.996051\tvalid_1's auc: 0.889594\n",
      "[245]\ttraining's auc: 0.996097\tvalid_1's auc: 0.889654\n",
      "[246]\ttraining's auc: 0.996116\tvalid_1's auc: 0.889653\n",
      "[247]\ttraining's auc: 0.996129\tvalid_1's auc: 0.889685\n",
      "[248]\ttraining's auc: 0.99615\tvalid_1's auc: 0.889709\n",
      "[249]\ttraining's auc: 0.996174\tvalid_1's auc: 0.88975\n",
      "[250]\ttraining's auc: 0.996209\tvalid_1's auc: 0.88985\n",
      "[251]\ttraining's auc: 0.996247\tvalid_1's auc: 0.889913\n",
      "[252]\ttraining's auc: 0.996277\tvalid_1's auc: 0.88992\n",
      "[253]\ttraining's auc: 0.996287\tvalid_1's auc: 0.889949\n",
      "[254]\ttraining's auc: 0.996305\tvalid_1's auc: 0.889943\n",
      "[255]\ttraining's auc: 0.996325\tvalid_1's auc: 0.889799\n",
      "[256]\ttraining's auc: 0.996346\tvalid_1's auc: 0.889827\n",
      "[257]\ttraining's auc: 0.996378\tvalid_1's auc: 0.889808\n",
      "[258]\ttraining's auc: 0.996387\tvalid_1's auc: 0.889828\n",
      "[259]\ttraining's auc: 0.9964\tvalid_1's auc: 0.889863\n",
      "[260]\ttraining's auc: 0.996417\tvalid_1's auc: 0.889866\n",
      "[261]\ttraining's auc: 0.99643\tvalid_1's auc: 0.889903\n",
      "[262]\ttraining's auc: 0.996459\tvalid_1's auc: 0.889939\n",
      "[263]\ttraining's auc: 0.996486\tvalid_1's auc: 0.88988\n",
      "[264]\ttraining's auc: 0.996499\tvalid_1's auc: 0.889853\n",
      "[265]\ttraining's auc: 0.996526\tvalid_1's auc: 0.889867\n",
      "[266]\ttraining's auc: 0.99656\tvalid_1's auc: 0.88987\n",
      "[267]\ttraining's auc: 0.996568\tvalid_1's auc: 0.889843\n",
      "[268]\ttraining's auc: 0.9966\tvalid_1's auc: 0.889991\n",
      "[269]\ttraining's auc: 0.996638\tvalid_1's auc: 0.890036\n",
      "[270]\ttraining's auc: 0.996665\tvalid_1's auc: 0.89005\n",
      "[271]\ttraining's auc: 0.996691\tvalid_1's auc: 0.890054\n",
      "[272]\ttraining's auc: 0.996724\tvalid_1's auc: 0.890034\n",
      "[273]\ttraining's auc: 0.996734\tvalid_1's auc: 0.890042\n",
      "[274]\ttraining's auc: 0.996779\tvalid_1's auc: 0.889997\n",
      "[275]\ttraining's auc: 0.996796\tvalid_1's auc: 0.890024\n",
      "[276]\ttraining's auc: 0.996819\tvalid_1's auc: 0.890051\n",
      "[277]\ttraining's auc: 0.996836\tvalid_1's auc: 0.890133\n",
      "[278]\ttraining's auc: 0.99687\tvalid_1's auc: 0.890089\n",
      "[279]\ttraining's auc: 0.996885\tvalid_1's auc: 0.890157\n",
      "[280]\ttraining's auc: 0.996902\tvalid_1's auc: 0.890237\n",
      "[281]\ttraining's auc: 0.996917\tvalid_1's auc: 0.890187\n",
      "[282]\ttraining's auc: 0.99695\tvalid_1's auc: 0.890138\n",
      "[283]\ttraining's auc: 0.997006\tvalid_1's auc: 0.890129\n",
      "[284]\ttraining's auc: 0.997035\tvalid_1's auc: 0.89018\n",
      "[285]\ttraining's auc: 0.997062\tvalid_1's auc: 0.89019\n",
      "[286]\ttraining's auc: 0.997109\tvalid_1's auc: 0.890204\n",
      "[287]\ttraining's auc: 0.997142\tvalid_1's auc: 0.89014\n",
      "[288]\ttraining's auc: 0.997159\tvalid_1's auc: 0.890072\n",
      "[289]\ttraining's auc: 0.99717\tvalid_1's auc: 0.890017\n",
      "[290]\ttraining's auc: 0.997175\tvalid_1's auc: 0.889971\n",
      "[291]\ttraining's auc: 0.997188\tvalid_1's auc: 0.889925\n",
      "[292]\ttraining's auc: 0.997208\tvalid_1's auc: 0.889885\n",
      "[293]\ttraining's auc: 0.997225\tvalid_1's auc: 0.889865\n",
      "[294]\ttraining's auc: 0.99724\tvalid_1's auc: 0.889805\n",
      "[295]\ttraining's auc: 0.997273\tvalid_1's auc: 0.889871\n",
      "[296]\ttraining's auc: 0.997293\tvalid_1's auc: 0.889903\n",
      "[297]\ttraining's auc: 0.997321\tvalid_1's auc: 0.889926\n",
      "[298]\ttraining's auc: 0.997366\tvalid_1's auc: 0.889993\n",
      "[299]\ttraining's auc: 0.997421\tvalid_1's auc: 0.890024\n",
      "[300]\ttraining's auc: 0.997439\tvalid_1's auc: 0.890016\n",
      "[301]\ttraining's auc: 0.997474\tvalid_1's auc: 0.890009\n",
      "[302]\ttraining's auc: 0.997506\tvalid_1's auc: 0.889939\n",
      "[303]\ttraining's auc: 0.997545\tvalid_1's auc: 0.889922\n",
      "[304]\ttraining's auc: 0.997553\tvalid_1's auc: 0.88995\n",
      "[305]\ttraining's auc: 0.997569\tvalid_1's auc: 0.889964\n",
      "[306]\ttraining's auc: 0.997576\tvalid_1's auc: 0.889927\n",
      "[307]\ttraining's auc: 0.997594\tvalid_1's auc: 0.88991\n",
      "[308]\ttraining's auc: 0.997602\tvalid_1's auc: 0.889886\n",
      "[309]\ttraining's auc: 0.997655\tvalid_1's auc: 0.889868\n",
      "[310]\ttraining's auc: 0.997675\tvalid_1's auc: 0.889887\n",
      "[311]\ttraining's auc: 0.997688\tvalid_1's auc: 0.889896\n",
      "[312]\ttraining's auc: 0.997695\tvalid_1's auc: 0.889909\n",
      "[313]\ttraining's auc: 0.997711\tvalid_1's auc: 0.889938\n",
      "[314]\ttraining's auc: 0.997729\tvalid_1's auc: 0.889968\n",
      "[315]\ttraining's auc: 0.997744\tvalid_1's auc: 0.89004\n",
      "[316]\ttraining's auc: 0.997775\tvalid_1's auc: 0.889896\n",
      "[317]\ttraining's auc: 0.997804\tvalid_1's auc: 0.889846\n",
      "[318]\ttraining's auc: 0.997831\tvalid_1's auc: 0.889694\n",
      "[319]\ttraining's auc: 0.997834\tvalid_1's auc: 0.889702\n",
      "[320]\ttraining's auc: 0.99784\tvalid_1's auc: 0.889644\n",
      "[321]\ttraining's auc: 0.997842\tvalid_1's auc: 0.889629\n",
      "[322]\ttraining's auc: 0.997861\tvalid_1's auc: 0.889591\n",
      "[323]\ttraining's auc: 0.997879\tvalid_1's auc: 0.889687\n",
      "[324]\ttraining's auc: 0.997886\tvalid_1's auc: 0.889643\n",
      "[325]\ttraining's auc: 0.997918\tvalid_1's auc: 0.889625\n",
      "[326]\ttraining's auc: 0.997959\tvalid_1's auc: 0.889634\n",
      "[327]\ttraining's auc: 0.997993\tvalid_1's auc: 0.889608\n",
      "[328]\ttraining's auc: 0.997999\tvalid_1's auc: 0.889587\n",
      "[329]\ttraining's auc: 0.998011\tvalid_1's auc: 0.889553\n",
      "[330]\ttraining's auc: 0.998024\tvalid_1's auc: 0.889485\n",
      "[331]\ttraining's auc: 0.998034\tvalid_1's auc: 0.889405\n",
      "[332]\ttraining's auc: 0.998039\tvalid_1's auc: 0.889361\n",
      "[333]\ttraining's auc: 0.998045\tvalid_1's auc: 0.889327\n",
      "[334]\ttraining's auc: 0.998051\tvalid_1's auc: 0.889313\n",
      "[335]\ttraining's auc: 0.998055\tvalid_1's auc: 0.889289\n",
      "[336]\ttraining's auc: 0.998069\tvalid_1's auc: 0.889269\n",
      "[337]\ttraining's auc: 0.998075\tvalid_1's auc: 0.889228\n",
      "[338]\ttraining's auc: 0.998088\tvalid_1's auc: 0.889148\n",
      "[339]\ttraining's auc: 0.998104\tvalid_1's auc: 0.88911\n",
      "[340]\ttraining's auc: 0.998118\tvalid_1's auc: 0.889042\n",
      "[341]\ttraining's auc: 0.998123\tvalid_1's auc: 0.889016\n",
      "[342]\ttraining's auc: 0.998137\tvalid_1's auc: 0.889005\n",
      "[343]\ttraining's auc: 0.99815\tvalid_1's auc: 0.889009\n",
      "[344]\ttraining's auc: 0.998155\tvalid_1's auc: 0.88899\n",
      "[345]\ttraining's auc: 0.998159\tvalid_1's auc: 0.888978\n",
      "[346]\ttraining's auc: 0.99816\tvalid_1's auc: 0.888975\n",
      "[347]\ttraining's auc: 0.998162\tvalid_1's auc: 0.888958\n",
      "[348]\ttraining's auc: 0.998164\tvalid_1's auc: 0.888945\n",
      "[349]\ttraining's auc: 0.998173\tvalid_1's auc: 0.888958\n",
      "[350]\ttraining's auc: 0.998208\tvalid_1's auc: 0.889009\n",
      "[351]\ttraining's auc: 0.998216\tvalid_1's auc: 0.889027\n",
      "[352]\ttraining's auc: 0.998235\tvalid_1's auc: 0.888983\n",
      "[353]\ttraining's auc: 0.998247\tvalid_1's auc: 0.888968\n",
      "[354]\ttraining's auc: 0.998274\tvalid_1's auc: 0.888963\n",
      "[355]\ttraining's auc: 0.998279\tvalid_1's auc: 0.888997\n",
      "[356]\ttraining's auc: 0.998288\tvalid_1's auc: 0.889036\n",
      "[357]\ttraining's auc: 0.99829\tvalid_1's auc: 0.889048\n",
      "[358]\ttraining's auc: 0.998309\tvalid_1's auc: 0.889032\n",
      "[359]\ttraining's auc: 0.998318\tvalid_1's auc: 0.888933\n",
      "[360]\ttraining's auc: 0.998331\tvalid_1's auc: 0.888905\n",
      "[361]\ttraining's auc: 0.998348\tvalid_1's auc: 0.888911\n",
      "[362]\ttraining's auc: 0.998356\tvalid_1's auc: 0.88891\n",
      "[363]\ttraining's auc: 0.998367\tvalid_1's auc: 0.888914\n",
      "[364]\ttraining's auc: 0.998396\tvalid_1's auc: 0.888932\n",
      "[365]\ttraining's auc: 0.99842\tvalid_1's auc: 0.8889\n",
      "[366]\ttraining's auc: 0.998435\tvalid_1's auc: 0.888959\n",
      "[367]\ttraining's auc: 0.998478\tvalid_1's auc: 0.888914\n",
      "[368]\ttraining's auc: 0.998516\tvalid_1's auc: 0.888852\n",
      "[369]\ttraining's auc: 0.998542\tvalid_1's auc: 0.888786\n",
      "[370]\ttraining's auc: 0.998552\tvalid_1's auc: 0.888796\n",
      "[371]\ttraining's auc: 0.998581\tvalid_1's auc: 0.888816\n",
      "[372]\ttraining's auc: 0.99859\tvalid_1's auc: 0.88882\n",
      "[373]\ttraining's auc: 0.99861\tvalid_1's auc: 0.888731\n",
      "[374]\ttraining's auc: 0.998625\tvalid_1's auc: 0.88871\n",
      "[375]\ttraining's auc: 0.998642\tvalid_1's auc: 0.888685\n",
      "[376]\ttraining's auc: 0.998658\tvalid_1's auc: 0.888699\n",
      "[377]\ttraining's auc: 0.998677\tvalid_1's auc: 0.888743\n",
      "[378]\ttraining's auc: 0.9987\tvalid_1's auc: 0.888744\n",
      "[379]\ttraining's auc: 0.998711\tvalid_1's auc: 0.888748\n",
      "[380]\ttraining's auc: 0.998722\tvalid_1's auc: 0.888665\n",
      "[381]\ttraining's auc: 0.998733\tvalid_1's auc: 0.888639\n",
      "[382]\ttraining's auc: 0.998752\tvalid_1's auc: 0.888664\n",
      "[383]\ttraining's auc: 0.998767\tvalid_1's auc: 0.888702\n",
      "[384]\ttraining's auc: 0.998774\tvalid_1's auc: 0.888768\n",
      "[385]\ttraining's auc: 0.998793\tvalid_1's auc: 0.888821\n",
      "[386]\ttraining's auc: 0.998809\tvalid_1's auc: 0.888942\n",
      "[387]\ttraining's auc: 0.998823\tvalid_1's auc: 0.88898\n",
      "[388]\ttraining's auc: 0.998825\tvalid_1's auc: 0.88891\n",
      "[389]\ttraining's auc: 0.998828\tvalid_1's auc: 0.888853\n",
      "[390]\ttraining's auc: 0.99883\tvalid_1's auc: 0.888787\n",
      "[391]\ttraining's auc: 0.998846\tvalid_1's auc: 0.888782\n",
      "[392]\ttraining's auc: 0.998867\tvalid_1's auc: 0.888788\n",
      "[393]\ttraining's auc: 0.998879\tvalid_1's auc: 0.88879\n",
      "[394]\ttraining's auc: 0.998886\tvalid_1's auc: 0.888774\n",
      "[395]\ttraining's auc: 0.998893\tvalid_1's auc: 0.88879\n",
      "[396]\ttraining's auc: 0.998911\tvalid_1's auc: 0.888758\n",
      "[397]\ttraining's auc: 0.998919\tvalid_1's auc: 0.888746\n",
      "[398]\ttraining's auc: 0.998929\tvalid_1's auc: 0.888749\n",
      "[399]\ttraining's auc: 0.998942\tvalid_1's auc: 0.888673\n",
      "[400]\ttraining's auc: 0.998947\tvalid_1's auc: 0.888636\n",
      "[401]\ttraining's auc: 0.998951\tvalid_1's auc: 0.888606\n",
      "[402]\ttraining's auc: 0.998957\tvalid_1's auc: 0.888569\n",
      "[403]\ttraining's auc: 0.998961\tvalid_1's auc: 0.888556\n",
      "[404]\ttraining's auc: 0.998978\tvalid_1's auc: 0.888663\n",
      "[405]\ttraining's auc: 0.998989\tvalid_1's auc: 0.888658\n",
      "[406]\ttraining's auc: 0.998996\tvalid_1's auc: 0.888698\n",
      "[407]\ttraining's auc: 0.999015\tvalid_1's auc: 0.888712\n",
      "[408]\ttraining's auc: 0.999021\tvalid_1's auc: 0.888651\n",
      "[409]\ttraining's auc: 0.999029\tvalid_1's auc: 0.888638\n",
      "[410]\ttraining's auc: 0.999038\tvalid_1's auc: 0.88875\n",
      "[411]\ttraining's auc: 0.999045\tvalid_1's auc: 0.888865\n",
      "[412]\ttraining's auc: 0.999048\tvalid_1's auc: 0.888841\n",
      "[413]\ttraining's auc: 0.999058\tvalid_1's auc: 0.888778\n",
      "[414]\ttraining's auc: 0.999061\tvalid_1's auc: 0.888705\n",
      "[415]\ttraining's auc: 0.999064\tvalid_1's auc: 0.888689\n",
      "[416]\ttraining's auc: 0.999072\tvalid_1's auc: 0.888676\n",
      "[417]\ttraining's auc: 0.99908\tvalid_1's auc: 0.88871\n",
      "[418]\ttraining's auc: 0.999083\tvalid_1's auc: 0.88867\n",
      "[419]\ttraining's auc: 0.999083\tvalid_1's auc: 0.888673\n",
      "[420]\ttraining's auc: 0.999084\tvalid_1's auc: 0.888617\n",
      "[421]\ttraining's auc: 0.999101\tvalid_1's auc: 0.888577\n",
      "[422]\ttraining's auc: 0.999119\tvalid_1's auc: 0.888556\n",
      "[423]\ttraining's auc: 0.999135\tvalid_1's auc: 0.888547\n",
      "[424]\ttraining's auc: 0.999146\tvalid_1's auc: 0.888544\n",
      "[425]\ttraining's auc: 0.999148\tvalid_1's auc: 0.888532\n",
      "[426]\ttraining's auc: 0.999155\tvalid_1's auc: 0.888549\n",
      "[427]\ttraining's auc: 0.999166\tvalid_1's auc: 0.888481\n",
      "[428]\ttraining's auc: 0.999168\tvalid_1's auc: 0.888434\n",
      "[429]\ttraining's auc: 0.99917\tvalid_1's auc: 0.88833\n",
      "[430]\ttraining's auc: 0.999178\tvalid_1's auc: 0.888234\n",
      "[431]\ttraining's auc: 0.999185\tvalid_1's auc: 0.88822\n",
      "[432]\ttraining's auc: 0.999194\tvalid_1's auc: 0.888173\n",
      "[433]\ttraining's auc: 0.999199\tvalid_1's auc: 0.888103\n",
      "[434]\ttraining's auc: 0.999206\tvalid_1's auc: 0.888048\n",
      "[435]\ttraining's auc: 0.999211\tvalid_1's auc: 0.887984\n",
      "[436]\ttraining's auc: 0.999224\tvalid_1's auc: 0.887992\n",
      "[437]\ttraining's auc: 0.99924\tvalid_1's auc: 0.887997\n",
      "[438]\ttraining's auc: 0.999249\tvalid_1's auc: 0.888006\n",
      "[439]\ttraining's auc: 0.999258\tvalid_1's auc: 0.887998\n",
      "[440]\ttraining's auc: 0.999268\tvalid_1's auc: 0.887984\n",
      "[441]\ttraining's auc: 0.999272\tvalid_1's auc: 0.88796\n",
      "[442]\ttraining's auc: 0.999283\tvalid_1's auc: 0.887995\n",
      "[443]\ttraining's auc: 0.999285\tvalid_1's auc: 0.887925\n",
      "[444]\ttraining's auc: 0.999296\tvalid_1's auc: 0.887995\n",
      "[445]\ttraining's auc: 0.999302\tvalid_1's auc: 0.887988\n",
      "[446]\ttraining's auc: 0.999306\tvalid_1's auc: 0.887978\n",
      "[447]\ttraining's auc: 0.999309\tvalid_1's auc: 0.887997\n",
      "[448]\ttraining's auc: 0.999315\tvalid_1's auc: 0.887984\n",
      "[449]\ttraining's auc: 0.999321\tvalid_1's auc: 0.887913\n",
      "[450]\ttraining's auc: 0.999329\tvalid_1's auc: 0.88788\n",
      "[451]\ttraining's auc: 0.999342\tvalid_1's auc: 0.887834\n",
      "[452]\ttraining's auc: 0.999357\tvalid_1's auc: 0.887842\n",
      "[453]\ttraining's auc: 0.999367\tvalid_1's auc: 0.887785\n",
      "[454]\ttraining's auc: 0.99937\tvalid_1's auc: 0.88776\n",
      "[455]\ttraining's auc: 0.999375\tvalid_1's auc: 0.887663\n",
      "[456]\ttraining's auc: 0.999377\tvalid_1's auc: 0.887616\n",
      "[457]\ttraining's auc: 0.99938\tvalid_1's auc: 0.887537\n",
      "[458]\ttraining's auc: 0.999383\tvalid_1's auc: 0.887541\n",
      "[459]\ttraining's auc: 0.99939\tvalid_1's auc: 0.887483\n",
      "[460]\ttraining's auc: 0.999399\tvalid_1's auc: 0.887481\n",
      "[461]\ttraining's auc: 0.999406\tvalid_1's auc: 0.887396\n",
      "[462]\ttraining's auc: 0.999414\tvalid_1's auc: 0.887343\n",
      "[463]\ttraining's auc: 0.99942\tvalid_1's auc: 0.887329\n",
      "[464]\ttraining's auc: 0.999426\tvalid_1's auc: 0.887319\n",
      "[465]\ttraining's auc: 0.99943\tvalid_1's auc: 0.88731\n",
      "[466]\ttraining's auc: 0.999439\tvalid_1's auc: 0.88732\n",
      "[467]\ttraining's auc: 0.999446\tvalid_1's auc: 0.887334\n",
      "[468]\ttraining's auc: 0.999452\tvalid_1's auc: 0.887315\n",
      "[469]\ttraining's auc: 0.999465\tvalid_1's auc: 0.887264\n",
      "[470]\ttraining's auc: 0.999475\tvalid_1's auc: 0.887154\n",
      "[471]\ttraining's auc: 0.999488\tvalid_1's auc: 0.887121\n",
      "[472]\ttraining's auc: 0.999491\tvalid_1's auc: 0.887084\n",
      "[473]\ttraining's auc: 0.999495\tvalid_1's auc: 0.887048\n",
      "[474]\ttraining's auc: 0.999497\tvalid_1's auc: 0.886974\n",
      "[475]\ttraining's auc: 0.999503\tvalid_1's auc: 0.886885\n",
      "[476]\ttraining's auc: 0.999509\tvalid_1's auc: 0.886836\n",
      "[477]\ttraining's auc: 0.999516\tvalid_1's auc: 0.886848\n",
      "[478]\ttraining's auc: 0.999517\tvalid_1's auc: 0.886839\n",
      "[479]\ttraining's auc: 0.999518\tvalid_1's auc: 0.886826\n",
      "[480]\ttraining's auc: 0.99952\tvalid_1's auc: 0.886829\n",
      "Early stopping, best iteration is:\n",
      "[280]\ttraining's auc: 0.996902\tvalid_1's auc: 0.890237\n",
      "Fold 1\n",
      "[1]\ttraining's auc: 0.888109\tvalid_1's auc: 0.828512\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\ttraining's auc: 0.897559\tvalid_1's auc: 0.850447\n",
      "[3]\ttraining's auc: 0.902777\tvalid_1's auc: 0.862447\n",
      "[4]\ttraining's auc: 0.907208\tvalid_1's auc: 0.867174\n",
      "[5]\ttraining's auc: 0.910436\tvalid_1's auc: 0.87237\n",
      "[6]\ttraining's auc: 0.9124\tvalid_1's auc: 0.874379\n",
      "[7]\ttraining's auc: 0.913975\tvalid_1's auc: 0.874039\n",
      "[8]\ttraining's auc: 0.915046\tvalid_1's auc: 0.875113\n",
      "[9]\ttraining's auc: 0.915567\tvalid_1's auc: 0.875204\n",
      "[10]\ttraining's auc: 0.916563\tvalid_1's auc: 0.876071\n",
      "[11]\ttraining's auc: 0.91692\tvalid_1's auc: 0.875322\n",
      "[12]\ttraining's auc: 0.917194\tvalid_1's auc: 0.877284\n",
      "[13]\ttraining's auc: 0.917469\tvalid_1's auc: 0.877877\n",
      "[14]\ttraining's auc: 0.917763\tvalid_1's auc: 0.878103\n",
      "[15]\ttraining's auc: 0.91801\tvalid_1's auc: 0.879315\n",
      "[16]\ttraining's auc: 0.919702\tvalid_1's auc: 0.879921\n",
      "[17]\ttraining's auc: 0.919959\tvalid_1's auc: 0.880067\n",
      "[18]\ttraining's auc: 0.920666\tvalid_1's auc: 0.880105\n",
      "[19]\ttraining's auc: 0.921074\tvalid_1's auc: 0.880414\n",
      "[20]\ttraining's auc: 0.921361\tvalid_1's auc: 0.880811\n",
      "[21]\ttraining's auc: 0.921562\tvalid_1's auc: 0.880849\n",
      "[22]\ttraining's auc: 0.922\tvalid_1's auc: 0.880809\n",
      "[23]\ttraining's auc: 0.92277\tvalid_1's auc: 0.880912\n",
      "[24]\ttraining's auc: 0.923262\tvalid_1's auc: 0.880792\n",
      "[25]\ttraining's auc: 0.92382\tvalid_1's auc: 0.881288\n",
      "[26]\ttraining's auc: 0.924492\tvalid_1's auc: 0.88199\n",
      "[27]\ttraining's auc: 0.925293\tvalid_1's auc: 0.882258\n",
      "[28]\ttraining's auc: 0.927072\tvalid_1's auc: 0.883021\n",
      "[29]\ttraining's auc: 0.928038\tvalid_1's auc: 0.883734\n",
      "[30]\ttraining's auc: 0.928635\tvalid_1's auc: 0.884398\n",
      "[31]\ttraining's auc: 0.929264\tvalid_1's auc: 0.884306\n",
      "[32]\ttraining's auc: 0.93117\tvalid_1's auc: 0.885355\n",
      "[33]\ttraining's auc: 0.931463\tvalid_1's auc: 0.885026\n",
      "[34]\ttraining's auc: 0.931634\tvalid_1's auc: 0.88504\n",
      "[35]\ttraining's auc: 0.932225\tvalid_1's auc: 0.885419\n",
      "[36]\ttraining's auc: 0.932617\tvalid_1's auc: 0.885888\n",
      "[37]\ttraining's auc: 0.933202\tvalid_1's auc: 0.886248\n",
      "[38]\ttraining's auc: 0.933581\tvalid_1's auc: 0.886313\n",
      "[39]\ttraining's auc: 0.93399\tvalid_1's auc: 0.886565\n",
      "[40]\ttraining's auc: 0.935085\tvalid_1's auc: 0.887136\n",
      "[41]\ttraining's auc: 0.936209\tvalid_1's auc: 0.887525\n",
      "[42]\ttraining's auc: 0.937283\tvalid_1's auc: 0.88806\n",
      "[43]\ttraining's auc: 0.937792\tvalid_1's auc: 0.888207\n",
      "[44]\ttraining's auc: 0.93844\tvalid_1's auc: 0.888573\n",
      "[45]\ttraining's auc: 0.9391\tvalid_1's auc: 0.88871\n",
      "[46]\ttraining's auc: 0.939423\tvalid_1's auc: 0.888795\n",
      "[47]\ttraining's auc: 0.939713\tvalid_1's auc: 0.888922\n",
      "[48]\ttraining's auc: 0.940006\tvalid_1's auc: 0.889058\n",
      "[49]\ttraining's auc: 0.940537\tvalid_1's auc: 0.889035\n",
      "[50]\ttraining's auc: 0.941115\tvalid_1's auc: 0.889168\n",
      "[51]\ttraining's auc: 0.941657\tvalid_1's auc: 0.889263\n",
      "[52]\ttraining's auc: 0.942261\tvalid_1's auc: 0.889312\n",
      "[53]\ttraining's auc: 0.942667\tvalid_1's auc: 0.889471\n",
      "[54]\ttraining's auc: 0.943376\tvalid_1's auc: 0.889511\n",
      "[55]\ttraining's auc: 0.944015\tvalid_1's auc: 0.889498\n",
      "[56]\ttraining's auc: 0.944748\tvalid_1's auc: 0.889937\n",
      "[57]\ttraining's auc: 0.9454\tvalid_1's auc: 0.890192\n",
      "[58]\ttraining's auc: 0.94631\tvalid_1's auc: 0.890111\n",
      "[59]\ttraining's auc: 0.947117\tvalid_1's auc: 0.890006\n",
      "[60]\ttraining's auc: 0.947816\tvalid_1's auc: 0.889915\n",
      "[61]\ttraining's auc: 0.9484\tvalid_1's auc: 0.889994\n",
      "[62]\ttraining's auc: 0.948854\tvalid_1's auc: 0.88973\n",
      "[63]\ttraining's auc: 0.949557\tvalid_1's auc: 0.889821\n",
      "[64]\ttraining's auc: 0.950242\tvalid_1's auc: 0.889874\n",
      "[65]\ttraining's auc: 0.950879\tvalid_1's auc: 0.89036\n",
      "[66]\ttraining's auc: 0.951522\tvalid_1's auc: 0.890751\n",
      "[67]\ttraining's auc: 0.952069\tvalid_1's auc: 0.891336\n",
      "[68]\ttraining's auc: 0.952585\tvalid_1's auc: 0.891541\n",
      "[69]\ttraining's auc: 0.953048\tvalid_1's auc: 0.891959\n",
      "[70]\ttraining's auc: 0.953519\tvalid_1's auc: 0.892412\n",
      "[71]\ttraining's auc: 0.954033\tvalid_1's auc: 0.892542\n",
      "[72]\ttraining's auc: 0.954526\tvalid_1's auc: 0.893321\n",
      "[73]\ttraining's auc: 0.955064\tvalid_1's auc: 0.89352\n",
      "[74]\ttraining's auc: 0.955454\tvalid_1's auc: 0.893794\n",
      "[75]\ttraining's auc: 0.955919\tvalid_1's auc: 0.893964\n",
      "[76]\ttraining's auc: 0.956413\tvalid_1's auc: 0.8942\n",
      "[77]\ttraining's auc: 0.956814\tvalid_1's auc: 0.894236\n",
      "[78]\ttraining's auc: 0.95733\tvalid_1's auc: 0.894291\n",
      "[79]\ttraining's auc: 0.957729\tvalid_1's auc: 0.894233\n",
      "[80]\ttraining's auc: 0.958231\tvalid_1's auc: 0.894237\n",
      "[81]\ttraining's auc: 0.958648\tvalid_1's auc: 0.894358\n",
      "[82]\ttraining's auc: 0.959196\tvalid_1's auc: 0.894762\n",
      "[83]\ttraining's auc: 0.959741\tvalid_1's auc: 0.895305\n",
      "[84]\ttraining's auc: 0.960331\tvalid_1's auc: 0.896103\n",
      "[85]\ttraining's auc: 0.961144\tvalid_1's auc: 0.896307\n",
      "[86]\ttraining's auc: 0.961761\tvalid_1's auc: 0.896564\n",
      "[87]\ttraining's auc: 0.962562\tvalid_1's auc: 0.897167\n",
      "[88]\ttraining's auc: 0.962991\tvalid_1's auc: 0.89741\n",
      "[89]\ttraining's auc: 0.963414\tvalid_1's auc: 0.897764\n",
      "[90]\ttraining's auc: 0.96374\tvalid_1's auc: 0.898004\n",
      "[91]\ttraining's auc: 0.964051\tvalid_1's auc: 0.89785\n",
      "[92]\ttraining's auc: 0.964451\tvalid_1's auc: 0.897823\n",
      "[93]\ttraining's auc: 0.964882\tvalid_1's auc: 0.897771\n",
      "[94]\ttraining's auc: 0.965238\tvalid_1's auc: 0.898003\n",
      "[95]\ttraining's auc: 0.965646\tvalid_1's auc: 0.89854\n",
      "[96]\ttraining's auc: 0.965988\tvalid_1's auc: 0.898834\n",
      "[97]\ttraining's auc: 0.96635\tvalid_1's auc: 0.899006\n",
      "[98]\ttraining's auc: 0.966742\tvalid_1's auc: 0.899224\n",
      "[99]\ttraining's auc: 0.967112\tvalid_1's auc: 0.899291\n",
      "[100]\ttraining's auc: 0.967405\tvalid_1's auc: 0.899521\n",
      "[101]\ttraining's auc: 0.967744\tvalid_1's auc: 0.899787\n",
      "[102]\ttraining's auc: 0.968126\tvalid_1's auc: 0.900105\n",
      "[103]\ttraining's auc: 0.968568\tvalid_1's auc: 0.900333\n",
      "[104]\ttraining's auc: 0.969009\tvalid_1's auc: 0.900424\n",
      "[105]\ttraining's auc: 0.969337\tvalid_1's auc: 0.900442\n",
      "[106]\ttraining's auc: 0.969728\tvalid_1's auc: 0.900633\n",
      "[107]\ttraining's auc: 0.970058\tvalid_1's auc: 0.900962\n",
      "[108]\ttraining's auc: 0.970396\tvalid_1's auc: 0.901219\n",
      "[109]\ttraining's auc: 0.97062\tvalid_1's auc: 0.901294\n",
      "[110]\ttraining's auc: 0.970862\tvalid_1's auc: 0.901311\n",
      "[111]\ttraining's auc: 0.971137\tvalid_1's auc: 0.901247\n",
      "[112]\ttraining's auc: 0.97154\tvalid_1's auc: 0.901644\n",
      "[113]\ttraining's auc: 0.971828\tvalid_1's auc: 0.901887\n",
      "[114]\ttraining's auc: 0.972068\tvalid_1's auc: 0.902052\n",
      "[115]\ttraining's auc: 0.972445\tvalid_1's auc: 0.902133\n",
      "[116]\ttraining's auc: 0.972837\tvalid_1's auc: 0.902451\n",
      "[117]\ttraining's auc: 0.973204\tvalid_1's auc: 0.902967\n",
      "[118]\ttraining's auc: 0.973452\tvalid_1's auc: 0.902994\n",
      "[119]\ttraining's auc: 0.973715\tvalid_1's auc: 0.903086\n",
      "[120]\ttraining's auc: 0.973941\tvalid_1's auc: 0.90322\n",
      "[121]\ttraining's auc: 0.974224\tvalid_1's auc: 0.903671\n",
      "[122]\ttraining's auc: 0.974486\tvalid_1's auc: 0.903978\n",
      "[123]\ttraining's auc: 0.974792\tvalid_1's auc: 0.904305\n",
      "[124]\ttraining's auc: 0.975032\tvalid_1's auc: 0.904296\n",
      "[125]\ttraining's auc: 0.975275\tvalid_1's auc: 0.904485\n",
      "[126]\ttraining's auc: 0.975475\tvalid_1's auc: 0.904572\n",
      "[127]\ttraining's auc: 0.975661\tvalid_1's auc: 0.904696\n",
      "[128]\ttraining's auc: 0.975865\tvalid_1's auc: 0.904774\n",
      "[129]\ttraining's auc: 0.97605\tvalid_1's auc: 0.904826\n",
      "[130]\ttraining's auc: 0.976294\tvalid_1's auc: 0.904949\n",
      "[131]\ttraining's auc: 0.976457\tvalid_1's auc: 0.90507\n",
      "[132]\ttraining's auc: 0.976682\tvalid_1's auc: 0.905079\n",
      "[133]\ttraining's auc: 0.976829\tvalid_1's auc: 0.905179\n",
      "[134]\ttraining's auc: 0.976938\tvalid_1's auc: 0.905295\n",
      "[135]\ttraining's auc: 0.977172\tvalid_1's auc: 0.905327\n",
      "[136]\ttraining's auc: 0.977362\tvalid_1's auc: 0.905453\n",
      "[137]\ttraining's auc: 0.977595\tvalid_1's auc: 0.90561\n",
      "[138]\ttraining's auc: 0.977819\tvalid_1's auc: 0.905796\n",
      "[139]\ttraining's auc: 0.978007\tvalid_1's auc: 0.906046\n",
      "[140]\ttraining's auc: 0.978187\tvalid_1's auc: 0.906174\n",
      "[141]\ttraining's auc: 0.978365\tvalid_1's auc: 0.906202\n",
      "[142]\ttraining's auc: 0.978599\tvalid_1's auc: 0.906369\n",
      "[143]\ttraining's auc: 0.978806\tvalid_1's auc: 0.906652\n",
      "[144]\ttraining's auc: 0.978919\tvalid_1's auc: 0.906736\n",
      "[145]\ttraining's auc: 0.979022\tvalid_1's auc: 0.906805\n",
      "[146]\ttraining's auc: 0.979076\tvalid_1's auc: 0.906849\n",
      "[147]\ttraining's auc: 0.979194\tvalid_1's auc: 0.90695\n",
      "[148]\ttraining's auc: 0.979365\tvalid_1's auc: 0.90701\n",
      "[149]\ttraining's auc: 0.979473\tvalid_1's auc: 0.907198\n",
      "[150]\ttraining's auc: 0.979565\tvalid_1's auc: 0.907316\n",
      "[151]\ttraining's auc: 0.979811\tvalid_1's auc: 0.907309\n",
      "[152]\ttraining's auc: 0.979988\tvalid_1's auc: 0.907468\n",
      "[153]\ttraining's auc: 0.980199\tvalid_1's auc: 0.907592\n",
      "[154]\ttraining's auc: 0.980339\tvalid_1's auc: 0.907612\n",
      "[155]\ttraining's auc: 0.980492\tvalid_1's auc: 0.907647\n",
      "[156]\ttraining's auc: 0.980624\tvalid_1's auc: 0.907615\n",
      "[157]\ttraining's auc: 0.980678\tvalid_1's auc: 0.907654\n",
      "[158]\ttraining's auc: 0.980771\tvalid_1's auc: 0.907721\n",
      "[159]\ttraining's auc: 0.980854\tvalid_1's auc: 0.90783\n",
      "[160]\ttraining's auc: 0.980982\tvalid_1's auc: 0.907935\n",
      "[161]\ttraining's auc: 0.981082\tvalid_1's auc: 0.908043\n",
      "[162]\ttraining's auc: 0.981173\tvalid_1's auc: 0.908077\n",
      "[163]\ttraining's auc: 0.981223\tvalid_1's auc: 0.908046\n",
      "[164]\ttraining's auc: 0.981328\tvalid_1's auc: 0.908095\n",
      "[165]\ttraining's auc: 0.981385\tvalid_1's auc: 0.908096\n",
      "[166]\ttraining's auc: 0.981521\tvalid_1's auc: 0.908303\n",
      "[167]\ttraining's auc: 0.981661\tvalid_1's auc: 0.908333\n",
      "[168]\ttraining's auc: 0.981844\tvalid_1's auc: 0.908407\n",
      "[169]\ttraining's auc: 0.981905\tvalid_1's auc: 0.908478\n",
      "[170]\ttraining's auc: 0.98197\tvalid_1's auc: 0.908479\n",
      "[171]\ttraining's auc: 0.982065\tvalid_1's auc: 0.908525\n",
      "[172]\ttraining's auc: 0.982183\tvalid_1's auc: 0.908458\n",
      "[173]\ttraining's auc: 0.982269\tvalid_1's auc: 0.908528\n",
      "[174]\ttraining's auc: 0.982444\tvalid_1's auc: 0.908628\n",
      "[175]\ttraining's auc: 0.982507\tvalid_1's auc: 0.908539\n",
      "[176]\ttraining's auc: 0.982568\tvalid_1's auc: 0.908427\n",
      "[177]\ttraining's auc: 0.982691\tvalid_1's auc: 0.908368\n",
      "[178]\ttraining's auc: 0.982765\tvalid_1's auc: 0.908367\n",
      "[179]\ttraining's auc: 0.98281\tvalid_1's auc: 0.908386\n",
      "[180]\ttraining's auc: 0.982917\tvalid_1's auc: 0.908397\n",
      "[181]\ttraining's auc: 0.982957\tvalid_1's auc: 0.908463\n",
      "[182]\ttraining's auc: 0.983088\tvalid_1's auc: 0.908634\n",
      "[183]\ttraining's auc: 0.98315\tvalid_1's auc: 0.908617\n",
      "[184]\ttraining's auc: 0.983353\tvalid_1's auc: 0.908788\n",
      "[185]\ttraining's auc: 0.983397\tvalid_1's auc: 0.908786\n",
      "[186]\ttraining's auc: 0.983498\tvalid_1's auc: 0.908701\n",
      "[187]\ttraining's auc: 0.98353\tvalid_1's auc: 0.908732\n",
      "[188]\ttraining's auc: 0.983567\tvalid_1's auc: 0.908803\n",
      "[189]\ttraining's auc: 0.9836\tvalid_1's auc: 0.908759\n",
      "[190]\ttraining's auc: 0.983709\tvalid_1's auc: 0.908691\n",
      "[191]\ttraining's auc: 0.983837\tvalid_1's auc: 0.90866\n",
      "[192]\ttraining's auc: 0.983932\tvalid_1's auc: 0.908635\n",
      "[193]\ttraining's auc: 0.983991\tvalid_1's auc: 0.90861\n",
      "[194]\ttraining's auc: 0.984122\tvalid_1's auc: 0.908629\n",
      "[195]\ttraining's auc: 0.984165\tvalid_1's auc: 0.908669\n",
      "[196]\ttraining's auc: 0.984231\tvalid_1's auc: 0.908728\n",
      "[197]\ttraining's auc: 0.984319\tvalid_1's auc: 0.908785\n",
      "[198]\ttraining's auc: 0.984379\tvalid_1's auc: 0.9088\n",
      "[199]\ttraining's auc: 0.984551\tvalid_1's auc: 0.909083\n",
      "[200]\ttraining's auc: 0.984567\tvalid_1's auc: 0.909091\n",
      "[201]\ttraining's auc: 0.984732\tvalid_1's auc: 0.909271\n",
      "[202]\ttraining's auc: 0.984838\tvalid_1's auc: 0.909413\n",
      "[203]\ttraining's auc: 0.984957\tvalid_1's auc: 0.909586\n",
      "[204]\ttraining's auc: 0.985053\tvalid_1's auc: 0.909686\n",
      "[205]\ttraining's auc: 0.985175\tvalid_1's auc: 0.909871\n",
      "[206]\ttraining's auc: 0.985294\tvalid_1's auc: 0.910014\n",
      "[207]\ttraining's auc: 0.985334\tvalid_1's auc: 0.909943\n",
      "[208]\ttraining's auc: 0.985375\tvalid_1's auc: 0.910003\n",
      "[209]\ttraining's auc: 0.985459\tvalid_1's auc: 0.910016\n",
      "[210]\ttraining's auc: 0.985544\tvalid_1's auc: 0.910002\n",
      "[211]\ttraining's auc: 0.985647\tvalid_1's auc: 0.910081\n",
      "[212]\ttraining's auc: 0.985786\tvalid_1's auc: 0.910134\n",
      "[213]\ttraining's auc: 0.985824\tvalid_1's auc: 0.910103\n",
      "[214]\ttraining's auc: 0.985924\tvalid_1's auc: 0.910081\n",
      "[215]\ttraining's auc: 0.985969\tvalid_1's auc: 0.910094\n",
      "[216]\ttraining's auc: 0.98605\tvalid_1's auc: 0.910085\n",
      "[217]\ttraining's auc: 0.986086\tvalid_1's auc: 0.910119\n",
      "[218]\ttraining's auc: 0.986129\tvalid_1's auc: 0.910141\n",
      "[219]\ttraining's auc: 0.986159\tvalid_1's auc: 0.910151\n",
      "[220]\ttraining's auc: 0.986258\tvalid_1's auc: 0.910176\n",
      "[221]\ttraining's auc: 0.986279\tvalid_1's auc: 0.910171\n",
      "[222]\ttraining's auc: 0.986302\tvalid_1's auc: 0.910171\n",
      "[223]\ttraining's auc: 0.986447\tvalid_1's auc: 0.910191\n",
      "[224]\ttraining's auc: 0.986569\tvalid_1's auc: 0.910193\n",
      "[225]\ttraining's auc: 0.986687\tvalid_1's auc: 0.910158\n",
      "[226]\ttraining's auc: 0.98684\tvalid_1's auc: 0.910183\n",
      "[227]\ttraining's auc: 0.986989\tvalid_1's auc: 0.910223\n",
      "[228]\ttraining's auc: 0.987049\tvalid_1's auc: 0.910206\n",
      "[229]\ttraining's auc: 0.987111\tvalid_1's auc: 0.910312\n",
      "[230]\ttraining's auc: 0.987139\tvalid_1's auc: 0.910292\n",
      "[231]\ttraining's auc: 0.987173\tvalid_1's auc: 0.910296\n",
      "[232]\ttraining's auc: 0.987201\tvalid_1's auc: 0.91034\n",
      "[233]\ttraining's auc: 0.987309\tvalid_1's auc: 0.910343\n",
      "[234]\ttraining's auc: 0.987323\tvalid_1's auc: 0.910366\n",
      "[235]\ttraining's auc: 0.987353\tvalid_1's auc: 0.91034\n",
      "[236]\ttraining's auc: 0.987385\tvalid_1's auc: 0.910317\n",
      "[237]\ttraining's auc: 0.987445\tvalid_1's auc: 0.91029\n",
      "[238]\ttraining's auc: 0.987575\tvalid_1's auc: 0.910325\n",
      "[239]\ttraining's auc: 0.987644\tvalid_1's auc: 0.910248\n",
      "[240]\ttraining's auc: 0.987661\tvalid_1's auc: 0.910181\n",
      "[241]\ttraining's auc: 0.98774\tvalid_1's auc: 0.910278\n",
      "[242]\ttraining's auc: 0.987783\tvalid_1's auc: 0.910299\n",
      "[243]\ttraining's auc: 0.987853\tvalid_1's auc: 0.910282\n",
      "[244]\ttraining's auc: 0.987867\tvalid_1's auc: 0.910252\n",
      "[245]\ttraining's auc: 0.987905\tvalid_1's auc: 0.910157\n",
      "[246]\ttraining's auc: 0.987932\tvalid_1's auc: 0.910149\n",
      "[247]\ttraining's auc: 0.987951\tvalid_1's auc: 0.910095\n",
      "[248]\ttraining's auc: 0.987959\tvalid_1's auc: 0.910044\n",
      "[249]\ttraining's auc: 0.987985\tvalid_1's auc: 0.909998\n",
      "[250]\ttraining's auc: 0.988112\tvalid_1's auc: 0.909964\n",
      "[251]\ttraining's auc: 0.988202\tvalid_1's auc: 0.909916\n",
      "[252]\ttraining's auc: 0.988311\tvalid_1's auc: 0.909922\n",
      "[253]\ttraining's auc: 0.988335\tvalid_1's auc: 0.909849\n",
      "[254]\ttraining's auc: 0.988367\tvalid_1's auc: 0.909846\n",
      "[255]\ttraining's auc: 0.98839\tvalid_1's auc: 0.909891\n",
      "[256]\ttraining's auc: 0.988512\tvalid_1's auc: 0.909878\n",
      "[257]\ttraining's auc: 0.988612\tvalid_1's auc: 0.909918\n",
      "[258]\ttraining's auc: 0.988701\tvalid_1's auc: 0.909859\n",
      "[259]\ttraining's auc: 0.988741\tvalid_1's auc: 0.909841\n",
      "[260]\ttraining's auc: 0.988774\tvalid_1's auc: 0.90987\n",
      "[261]\ttraining's auc: 0.988875\tvalid_1's auc: 0.909987\n",
      "[262]\ttraining's auc: 0.988892\tvalid_1's auc: 0.909935\n",
      "[263]\ttraining's auc: 0.988919\tvalid_1's auc: 0.909861\n",
      "[264]\ttraining's auc: 0.988946\tvalid_1's auc: 0.909818\n",
      "[265]\ttraining's auc: 0.988983\tvalid_1's auc: 0.909883\n",
      "[266]\ttraining's auc: 0.989016\tvalid_1's auc: 0.909918\n",
      "[267]\ttraining's auc: 0.989055\tvalid_1's auc: 0.909965\n",
      "[268]\ttraining's auc: 0.989067\tvalid_1's auc: 0.909961\n",
      "[269]\ttraining's auc: 0.989094\tvalid_1's auc: 0.910041\n",
      "[270]\ttraining's auc: 0.989124\tvalid_1's auc: 0.910057\n",
      "[271]\ttraining's auc: 0.989138\tvalid_1's auc: 0.91004\n",
      "[272]\ttraining's auc: 0.989191\tvalid_1's auc: 0.910037\n",
      "[273]\ttraining's auc: 0.989258\tvalid_1's auc: 0.910051\n",
      "[274]\ttraining's auc: 0.989388\tvalid_1's auc: 0.91009\n",
      "[275]\ttraining's auc: 0.989418\tvalid_1's auc: 0.910082\n",
      "[276]\ttraining's auc: 0.989444\tvalid_1's auc: 0.910024\n",
      "[277]\ttraining's auc: 0.989487\tvalid_1's auc: 0.910066\n",
      "[278]\ttraining's auc: 0.989534\tvalid_1's auc: 0.910132\n",
      "[279]\ttraining's auc: 0.989587\tvalid_1's auc: 0.910109\n",
      "[280]\ttraining's auc: 0.98963\tvalid_1's auc: 0.910113\n",
      "[281]\ttraining's auc: 0.98965\tvalid_1's auc: 0.910082\n",
      "[282]\ttraining's auc: 0.98967\tvalid_1's auc: 0.910051\n",
      "[283]\ttraining's auc: 0.989744\tvalid_1's auc: 0.910093\n",
      "[284]\ttraining's auc: 0.989802\tvalid_1's auc: 0.910091\n",
      "[285]\ttraining's auc: 0.989834\tvalid_1's auc: 0.910069\n",
      "[286]\ttraining's auc: 0.989852\tvalid_1's auc: 0.910044\n",
      "[287]\ttraining's auc: 0.989878\tvalid_1's auc: 0.909958\n",
      "[288]\ttraining's auc: 0.989885\tvalid_1's auc: 0.909921\n",
      "[289]\ttraining's auc: 0.989892\tvalid_1's auc: 0.909921\n",
      "[290]\ttraining's auc: 0.989926\tvalid_1's auc: 0.909954\n",
      "[291]\ttraining's auc: 0.989996\tvalid_1's auc: 0.91007\n",
      "[292]\ttraining's auc: 0.990062\tvalid_1's auc: 0.91008\n",
      "[293]\ttraining's auc: 0.990112\tvalid_1's auc: 0.910002\n",
      "[294]\ttraining's auc: 0.990173\tvalid_1's auc: 0.909886\n",
      "[295]\ttraining's auc: 0.990278\tvalid_1's auc: 0.909891\n",
      "[296]\ttraining's auc: 0.990309\tvalid_1's auc: 0.909835\n",
      "[297]\ttraining's auc: 0.990393\tvalid_1's auc: 0.909842\n",
      "[298]\ttraining's auc: 0.990413\tvalid_1's auc: 0.909833\n",
      "[299]\ttraining's auc: 0.990444\tvalid_1's auc: 0.90977\n",
      "[300]\ttraining's auc: 0.990465\tvalid_1's auc: 0.909764\n",
      "[301]\ttraining's auc: 0.990482\tvalid_1's auc: 0.909717\n",
      "[302]\ttraining's auc: 0.990502\tvalid_1's auc: 0.909724\n",
      "[303]\ttraining's auc: 0.990557\tvalid_1's auc: 0.909737\n",
      "[304]\ttraining's auc: 0.990673\tvalid_1's auc: 0.909813\n",
      "[305]\ttraining's auc: 0.99073\tvalid_1's auc: 0.909881\n",
      "[306]\ttraining's auc: 0.990763\tvalid_1's auc: 0.909889\n",
      "[307]\ttraining's auc: 0.990816\tvalid_1's auc: 0.90987\n",
      "[308]\ttraining's auc: 0.990848\tvalid_1's auc: 0.909884\n",
      "[309]\ttraining's auc: 0.990892\tvalid_1's auc: 0.909835\n",
      "[310]\ttraining's auc: 0.990925\tvalid_1's auc: 0.909807\n",
      "[311]\ttraining's auc: 0.990957\tvalid_1's auc: 0.909792\n",
      "[312]\ttraining's auc: 0.990991\tvalid_1's auc: 0.909745\n",
      "[313]\ttraining's auc: 0.991054\tvalid_1's auc: 0.909733\n",
      "[314]\ttraining's auc: 0.991113\tvalid_1's auc: 0.909719\n",
      "[315]\ttraining's auc: 0.991152\tvalid_1's auc: 0.909665\n",
      "[316]\ttraining's auc: 0.991198\tvalid_1's auc: 0.90973\n",
      "[317]\ttraining's auc: 0.991243\tvalid_1's auc: 0.909751\n",
      "[318]\ttraining's auc: 0.991288\tvalid_1's auc: 0.909731\n",
      "[319]\ttraining's auc: 0.99134\tvalid_1's auc: 0.909763\n",
      "[320]\ttraining's auc: 0.991374\tvalid_1's auc: 0.909818\n",
      "[321]\ttraining's auc: 0.991401\tvalid_1's auc: 0.909771\n",
      "[322]\ttraining's auc: 0.991436\tvalid_1's auc: 0.909744\n",
      "[323]\ttraining's auc: 0.991466\tvalid_1's auc: 0.909725\n",
      "[324]\ttraining's auc: 0.99148\tvalid_1's auc: 0.9097\n",
      "[325]\ttraining's auc: 0.99151\tvalid_1's auc: 0.909732\n",
      "[326]\ttraining's auc: 0.991532\tvalid_1's auc: 0.909738\n",
      "[327]\ttraining's auc: 0.991553\tvalid_1's auc: 0.909746\n",
      "[328]\ttraining's auc: 0.991567\tvalid_1's auc: 0.909721\n",
      "[329]\ttraining's auc: 0.991587\tvalid_1's auc: 0.909669\n",
      "[330]\ttraining's auc: 0.9916\tvalid_1's auc: 0.909678\n",
      "[331]\ttraining's auc: 0.991656\tvalid_1's auc: 0.90961\n",
      "[332]\ttraining's auc: 0.991706\tvalid_1's auc: 0.909481\n",
      "[333]\ttraining's auc: 0.991771\tvalid_1's auc: 0.909387\n",
      "[334]\ttraining's auc: 0.991779\tvalid_1's auc: 0.909293\n",
      "[335]\ttraining's auc: 0.991851\tvalid_1's auc: 0.909353\n",
      "[336]\ttraining's auc: 0.991899\tvalid_1's auc: 0.909401\n",
      "[337]\ttraining's auc: 0.991928\tvalid_1's auc: 0.909368\n",
      "[338]\ttraining's auc: 0.991974\tvalid_1's auc: 0.90931\n",
      "[339]\ttraining's auc: 0.992055\tvalid_1's auc: 0.909286\n",
      "[340]\ttraining's auc: 0.992101\tvalid_1's auc: 0.90927\n",
      "[341]\ttraining's auc: 0.992134\tvalid_1's auc: 0.909251\n",
      "[342]\ttraining's auc: 0.992157\tvalid_1's auc: 0.909223\n",
      "[343]\ttraining's auc: 0.992219\tvalid_1's auc: 0.909252\n",
      "[344]\ttraining's auc: 0.992256\tvalid_1's auc: 0.909267\n",
      "[345]\ttraining's auc: 0.992292\tvalid_1's auc: 0.90924\n",
      "[346]\ttraining's auc: 0.992366\tvalid_1's auc: 0.909237\n",
      "[347]\ttraining's auc: 0.992401\tvalid_1's auc: 0.909242\n",
      "[348]\ttraining's auc: 0.992474\tvalid_1's auc: 0.909213\n",
      "[349]\ttraining's auc: 0.992478\tvalid_1's auc: 0.90919\n",
      "[350]\ttraining's auc: 0.992481\tvalid_1's auc: 0.909176\n",
      "[351]\ttraining's auc: 0.992484\tvalid_1's auc: 0.909199\n",
      "[352]\ttraining's auc: 0.992553\tvalid_1's auc: 0.909347\n",
      "[353]\ttraining's auc: 0.992591\tvalid_1's auc: 0.909398\n",
      "[354]\ttraining's auc: 0.992636\tvalid_1's auc: 0.909375\n",
      "[355]\ttraining's auc: 0.992654\tvalid_1's auc: 0.909349\n",
      "[356]\ttraining's auc: 0.992665\tvalid_1's auc: 0.909311\n",
      "[357]\ttraining's auc: 0.99267\tvalid_1's auc: 0.909317\n",
      "[358]\ttraining's auc: 0.992689\tvalid_1's auc: 0.909274\n",
      "[359]\ttraining's auc: 0.992702\tvalid_1's auc: 0.909245\n",
      "[360]\ttraining's auc: 0.992718\tvalid_1's auc: 0.909205\n",
      "[361]\ttraining's auc: 0.992775\tvalid_1's auc: 0.909082\n",
      "[362]\ttraining's auc: 0.992822\tvalid_1's auc: 0.909095\n",
      "[363]\ttraining's auc: 0.992875\tvalid_1's auc: 0.909\n",
      "[364]\ttraining's auc: 0.992944\tvalid_1's auc: 0.909058\n",
      "[365]\ttraining's auc: 0.992999\tvalid_1's auc: 0.909116\n",
      "[366]\ttraining's auc: 0.993016\tvalid_1's auc: 0.909158\n",
      "[367]\ttraining's auc: 0.993059\tvalid_1's auc: 0.909193\n",
      "[368]\ttraining's auc: 0.993108\tvalid_1's auc: 0.909168\n",
      "[369]\ttraining's auc: 0.993142\tvalid_1's auc: 0.909191\n",
      "[370]\ttraining's auc: 0.993151\tvalid_1's auc: 0.909168\n",
      "[371]\ttraining's auc: 0.993164\tvalid_1's auc: 0.909179\n",
      "[372]\ttraining's auc: 0.993176\tvalid_1's auc: 0.909144\n",
      "[373]\ttraining's auc: 0.993192\tvalid_1's auc: 0.909138\n",
      "[374]\ttraining's auc: 0.99323\tvalid_1's auc: 0.909196\n",
      "[375]\ttraining's auc: 0.993269\tvalid_1's auc: 0.909201\n",
      "[376]\ttraining's auc: 0.993296\tvalid_1's auc: 0.909154\n",
      "[377]\ttraining's auc: 0.993326\tvalid_1's auc: 0.909106\n",
      "[378]\ttraining's auc: 0.993361\tvalid_1's auc: 0.909055\n",
      "[379]\ttraining's auc: 0.993372\tvalid_1's auc: 0.909092\n",
      "[380]\ttraining's auc: 0.99338\tvalid_1's auc: 0.909091\n",
      "[381]\ttraining's auc: 0.993386\tvalid_1's auc: 0.909125\n",
      "[382]\ttraining's auc: 0.993401\tvalid_1's auc: 0.909152\n",
      "[383]\ttraining's auc: 0.993409\tvalid_1's auc: 0.909162\n",
      "[384]\ttraining's auc: 0.99342\tvalid_1's auc: 0.909182\n",
      "[385]\ttraining's auc: 0.993439\tvalid_1's auc: 0.9092\n",
      "[386]\ttraining's auc: 0.993451\tvalid_1's auc: 0.909166\n",
      "[387]\ttraining's auc: 0.993462\tvalid_1's auc: 0.909115\n",
      "[388]\ttraining's auc: 0.993472\tvalid_1's auc: 0.909043\n",
      "[389]\ttraining's auc: 0.99348\tvalid_1's auc: 0.908991\n",
      "[390]\ttraining's auc: 0.993488\tvalid_1's auc: 0.908931\n",
      "[391]\ttraining's auc: 0.993497\tvalid_1's auc: 0.908928\n",
      "[392]\ttraining's auc: 0.993509\tvalid_1's auc: 0.908939\n",
      "[393]\ttraining's auc: 0.993516\tvalid_1's auc: 0.908914\n",
      "[394]\ttraining's auc: 0.993534\tvalid_1's auc: 0.908914\n",
      "[395]\ttraining's auc: 0.993591\tvalid_1's auc: 0.908893\n",
      "[396]\ttraining's auc: 0.993613\tvalid_1's auc: 0.908912\n",
      "[397]\ttraining's auc: 0.993668\tvalid_1's auc: 0.908864\n",
      "[398]\ttraining's auc: 0.993735\tvalid_1's auc: 0.908918\n",
      "[399]\ttraining's auc: 0.993796\tvalid_1's auc: 0.908927\n",
      "[400]\ttraining's auc: 0.993855\tvalid_1's auc: 0.90893\n",
      "[401]\ttraining's auc: 0.993923\tvalid_1's auc: 0.909011\n",
      "[402]\ttraining's auc: 0.993995\tvalid_1's auc: 0.909094\n",
      "[403]\ttraining's auc: 0.994069\tvalid_1's auc: 0.90902\n",
      "[404]\ttraining's auc: 0.994099\tvalid_1's auc: 0.908989\n",
      "[405]\ttraining's auc: 0.994124\tvalid_1's auc: 0.908928\n",
      "[406]\ttraining's auc: 0.994201\tvalid_1's auc: 0.909001\n",
      "[407]\ttraining's auc: 0.994277\tvalid_1's auc: 0.909048\n",
      "[408]\ttraining's auc: 0.994341\tvalid_1's auc: 0.90907\n",
      "[409]\ttraining's auc: 0.994352\tvalid_1's auc: 0.909051\n",
      "[410]\ttraining's auc: 0.994366\tvalid_1's auc: 0.909051\n",
      "[411]\ttraining's auc: 0.994377\tvalid_1's auc: 0.909048\n",
      "[412]\ttraining's auc: 0.99443\tvalid_1's auc: 0.90909\n",
      "[413]\ttraining's auc: 0.994464\tvalid_1's auc: 0.909014\n",
      "[414]\ttraining's auc: 0.994487\tvalid_1's auc: 0.908972\n",
      "[415]\ttraining's auc: 0.994526\tvalid_1's auc: 0.908923\n",
      "[416]\ttraining's auc: 0.994552\tvalid_1's auc: 0.908992\n",
      "[417]\ttraining's auc: 0.994577\tvalid_1's auc: 0.908909\n",
      "[418]\ttraining's auc: 0.994593\tvalid_1's auc: 0.908881\n",
      "[419]\ttraining's auc: 0.994602\tvalid_1's auc: 0.908828\n",
      "[420]\ttraining's auc: 0.994612\tvalid_1's auc: 0.908758\n",
      "[421]\ttraining's auc: 0.994635\tvalid_1's auc: 0.9087\n",
      "[422]\ttraining's auc: 0.994656\tvalid_1's auc: 0.908659\n",
      "[423]\ttraining's auc: 0.994674\tvalid_1's auc: 0.908631\n",
      "[424]\ttraining's auc: 0.994708\tvalid_1's auc: 0.908558\n",
      "[425]\ttraining's auc: 0.994728\tvalid_1's auc: 0.908568\n",
      "[426]\ttraining's auc: 0.994748\tvalid_1's auc: 0.908508\n",
      "[427]\ttraining's auc: 0.99476\tvalid_1's auc: 0.908399\n",
      "[428]\ttraining's auc: 0.994797\tvalid_1's auc: 0.908357\n",
      "[429]\ttraining's auc: 0.99481\tvalid_1's auc: 0.908262\n",
      "[430]\ttraining's auc: 0.994822\tvalid_1's auc: 0.908307\n",
      "[431]\ttraining's auc: 0.994845\tvalid_1's auc: 0.908315\n",
      "[432]\ttraining's auc: 0.994849\tvalid_1's auc: 0.908349\n",
      "[433]\ttraining's auc: 0.994862\tvalid_1's auc: 0.908294\n",
      "[434]\ttraining's auc: 0.994874\tvalid_1's auc: 0.908215\n",
      "Early stopping, best iteration is:\n",
      "[234]\ttraining's auc: 0.987323\tvalid_1's auc: 0.910366\n",
      "Fold 2\n",
      "[1]\ttraining's auc: 0.890447\tvalid_1's auc: 0.824981\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\ttraining's auc: 0.898657\tvalid_1's auc: 0.848152\n",
      "[3]\ttraining's auc: 0.901246\tvalid_1's auc: 0.856539\n",
      "[4]\ttraining's auc: 0.903565\tvalid_1's auc: 0.858266\n",
      "[5]\ttraining's auc: 0.90468\tvalid_1's auc: 0.859755\n",
      "[6]\ttraining's auc: 0.905953\tvalid_1's auc: 0.86379\n",
      "[7]\ttraining's auc: 0.908045\tvalid_1's auc: 0.864706\n",
      "[8]\ttraining's auc: 0.907628\tvalid_1's auc: 0.864459\n",
      "[9]\ttraining's auc: 0.90814\tvalid_1's auc: 0.86488\n",
      "[10]\ttraining's auc: 0.909296\tvalid_1's auc: 0.86528\n",
      "[11]\ttraining's auc: 0.909621\tvalid_1's auc: 0.865336\n",
      "[12]\ttraining's auc: 0.909936\tvalid_1's auc: 0.865973\n",
      "[13]\ttraining's auc: 0.910386\tvalid_1's auc: 0.866376\n",
      "[14]\ttraining's auc: 0.911911\tvalid_1's auc: 0.867368\n",
      "[15]\ttraining's auc: 0.912265\tvalid_1's auc: 0.867572\n",
      "[16]\ttraining's auc: 0.912801\tvalid_1's auc: 0.867694\n",
      "[17]\ttraining's auc: 0.913009\tvalid_1's auc: 0.868004\n",
      "[18]\ttraining's auc: 0.913109\tvalid_1's auc: 0.86819\n",
      "[19]\ttraining's auc: 0.9139\tvalid_1's auc: 0.868365\n",
      "[20]\ttraining's auc: 0.91447\tvalid_1's auc: 0.868261\n",
      "[21]\ttraining's auc: 0.91476\tvalid_1's auc: 0.868442\n",
      "[22]\ttraining's auc: 0.914817\tvalid_1's auc: 0.869048\n",
      "[23]\ttraining's auc: 0.914951\tvalid_1's auc: 0.869155\n",
      "[24]\ttraining's auc: 0.915342\tvalid_1's auc: 0.869246\n",
      "[25]\ttraining's auc: 0.916213\tvalid_1's auc: 0.869012\n",
      "[26]\ttraining's auc: 0.916677\tvalid_1's auc: 0.86934\n",
      "[27]\ttraining's auc: 0.917056\tvalid_1's auc: 0.869454\n",
      "[28]\ttraining's auc: 0.919812\tvalid_1's auc: 0.870046\n",
      "[29]\ttraining's auc: 0.919984\tvalid_1's auc: 0.870516\n",
      "[30]\ttraining's auc: 0.920197\tvalid_1's auc: 0.87094\n",
      "[31]\ttraining's auc: 0.920404\tvalid_1's auc: 0.870901\n",
      "[32]\ttraining's auc: 0.920642\tvalid_1's auc: 0.87113\n",
      "[33]\ttraining's auc: 0.921272\tvalid_1's auc: 0.871611\n",
      "[34]\ttraining's auc: 0.921762\tvalid_1's auc: 0.871729\n",
      "[35]\ttraining's auc: 0.921974\tvalid_1's auc: 0.871902\n",
      "[36]\ttraining's auc: 0.922252\tvalid_1's auc: 0.872097\n",
      "[37]\ttraining's auc: 0.922506\tvalid_1's auc: 0.872307\n",
      "[38]\ttraining's auc: 0.923329\tvalid_1's auc: 0.872847\n",
      "[39]\ttraining's auc: 0.923653\tvalid_1's auc: 0.873165\n",
      "[40]\ttraining's auc: 0.924074\tvalid_1's auc: 0.873723\n",
      "[41]\ttraining's auc: 0.924457\tvalid_1's auc: 0.8741\n",
      "[42]\ttraining's auc: 0.924944\tvalid_1's auc: 0.87445\n",
      "[43]\ttraining's auc: 0.925365\tvalid_1's auc: 0.874821\n",
      "[44]\ttraining's auc: 0.925664\tvalid_1's auc: 0.875058\n",
      "[45]\ttraining's auc: 0.926967\tvalid_1's auc: 0.875582\n",
      "[46]\ttraining's auc: 0.927254\tvalid_1's auc: 0.875659\n",
      "[47]\ttraining's auc: 0.928153\tvalid_1's auc: 0.876459\n",
      "[48]\ttraining's auc: 0.928956\tvalid_1's auc: 0.877492\n",
      "[49]\ttraining's auc: 0.929688\tvalid_1's auc: 0.878003\n",
      "[50]\ttraining's auc: 0.930098\tvalid_1's auc: 0.878106\n",
      "[51]\ttraining's auc: 0.930554\tvalid_1's auc: 0.878294\n",
      "[52]\ttraining's auc: 0.931467\tvalid_1's auc: 0.878992\n",
      "[53]\ttraining's auc: 0.931967\tvalid_1's auc: 0.879378\n",
      "[54]\ttraining's auc: 0.932622\tvalid_1's auc: 0.87996\n",
      "[55]\ttraining's auc: 0.933293\tvalid_1's auc: 0.880579\n",
      "[56]\ttraining's auc: 0.933791\tvalid_1's auc: 0.88091\n",
      "[57]\ttraining's auc: 0.934266\tvalid_1's auc: 0.881283\n",
      "[58]\ttraining's auc: 0.934602\tvalid_1's auc: 0.881471\n",
      "[59]\ttraining's auc: 0.934935\tvalid_1's auc: 0.881641\n",
      "[60]\ttraining's auc: 0.9353\tvalid_1's auc: 0.881801\n",
      "[61]\ttraining's auc: 0.935799\tvalid_1's auc: 0.882142\n",
      "[62]\ttraining's auc: 0.936076\tvalid_1's auc: 0.882402\n",
      "[63]\ttraining's auc: 0.936707\tvalid_1's auc: 0.882933\n",
      "[64]\ttraining's auc: 0.937535\tvalid_1's auc: 0.88343\n",
      "[65]\ttraining's auc: 0.937943\tvalid_1's auc: 0.883499\n",
      "[66]\ttraining's auc: 0.938239\tvalid_1's auc: 0.883411\n",
      "[67]\ttraining's auc: 0.938597\tvalid_1's auc: 0.883612\n",
      "[68]\ttraining's auc: 0.939188\tvalid_1's auc: 0.883903\n",
      "[69]\ttraining's auc: 0.939604\tvalid_1's auc: 0.884069\n",
      "[70]\ttraining's auc: 0.940277\tvalid_1's auc: 0.884768\n",
      "[71]\ttraining's auc: 0.940902\tvalid_1's auc: 0.885223\n",
      "[72]\ttraining's auc: 0.941468\tvalid_1's auc: 0.88591\n",
      "[73]\ttraining's auc: 0.942092\tvalid_1's auc: 0.886446\n",
      "[74]\ttraining's auc: 0.942854\tvalid_1's auc: 0.886869\n",
      "[75]\ttraining's auc: 0.943375\tvalid_1's auc: 0.887097\n",
      "[76]\ttraining's auc: 0.943864\tvalid_1's auc: 0.887275\n",
      "[77]\ttraining's auc: 0.94439\tvalid_1's auc: 0.887571\n",
      "[78]\ttraining's auc: 0.944801\tvalid_1's auc: 0.887908\n",
      "[79]\ttraining's auc: 0.945373\tvalid_1's auc: 0.88811\n",
      "[80]\ttraining's auc: 0.945868\tvalid_1's auc: 0.88818\n",
      "[81]\ttraining's auc: 0.946401\tvalid_1's auc: 0.88835\n",
      "[82]\ttraining's auc: 0.946682\tvalid_1's auc: 0.888474\n",
      "[83]\ttraining's auc: 0.947002\tvalid_1's auc: 0.888576\n",
      "[84]\ttraining's auc: 0.947378\tvalid_1's auc: 0.888588\n",
      "[85]\ttraining's auc: 0.947749\tvalid_1's auc: 0.888756\n",
      "[86]\ttraining's auc: 0.948169\tvalid_1's auc: 0.888856\n",
      "[87]\ttraining's auc: 0.948521\tvalid_1's auc: 0.888993\n",
      "[88]\ttraining's auc: 0.948964\tvalid_1's auc: 0.889187\n",
      "[89]\ttraining's auc: 0.949252\tvalid_1's auc: 0.889407\n",
      "[90]\ttraining's auc: 0.949656\tvalid_1's auc: 0.889662\n",
      "[91]\ttraining's auc: 0.950035\tvalid_1's auc: 0.88976\n",
      "[92]\ttraining's auc: 0.950438\tvalid_1's auc: 0.889951\n",
      "[93]\ttraining's auc: 0.95071\tvalid_1's auc: 0.889903\n",
      "[94]\ttraining's auc: 0.951314\tvalid_1's auc: 0.889965\n",
      "[95]\ttraining's auc: 0.951658\tvalid_1's auc: 0.890184\n",
      "[96]\ttraining's auc: 0.952068\tvalid_1's auc: 0.890197\n",
      "[97]\ttraining's auc: 0.95239\tvalid_1's auc: 0.890356\n",
      "[98]\ttraining's auc: 0.953023\tvalid_1's auc: 0.890525\n",
      "[99]\ttraining's auc: 0.953321\tvalid_1's auc: 0.89057\n",
      "[100]\ttraining's auc: 0.953657\tvalid_1's auc: 0.890584\n",
      "[101]\ttraining's auc: 0.953994\tvalid_1's auc: 0.890594\n",
      "[102]\ttraining's auc: 0.954412\tvalid_1's auc: 0.890769\n",
      "[103]\ttraining's auc: 0.954681\tvalid_1's auc: 0.890996\n",
      "[104]\ttraining's auc: 0.955064\tvalid_1's auc: 0.891201\n",
      "[105]\ttraining's auc: 0.955431\tvalid_1's auc: 0.891403\n",
      "[106]\ttraining's auc: 0.956071\tvalid_1's auc: 0.891545\n",
      "[107]\ttraining's auc: 0.95655\tvalid_1's auc: 0.891799\n",
      "[108]\ttraining's auc: 0.957072\tvalid_1's auc: 0.892016\n",
      "[109]\ttraining's auc: 0.957463\tvalid_1's auc: 0.891993\n",
      "[110]\ttraining's auc: 0.957899\tvalid_1's auc: 0.892168\n",
      "[111]\ttraining's auc: 0.95835\tvalid_1's auc: 0.892327\n",
      "[112]\ttraining's auc: 0.958609\tvalid_1's auc: 0.892501\n",
      "[113]\ttraining's auc: 0.958967\tvalid_1's auc: 0.892731\n",
      "[114]\ttraining's auc: 0.959293\tvalid_1's auc: 0.892702\n",
      "[115]\ttraining's auc: 0.959641\tvalid_1's auc: 0.892778\n",
      "[116]\ttraining's auc: 0.960156\tvalid_1's auc: 0.893191\n",
      "[117]\ttraining's auc: 0.960529\tvalid_1's auc: 0.89327\n",
      "[118]\ttraining's auc: 0.96094\tvalid_1's auc: 0.893575\n",
      "[119]\ttraining's auc: 0.961368\tvalid_1's auc: 0.893743\n",
      "[120]\ttraining's auc: 0.961654\tvalid_1's auc: 0.894049\n",
      "[121]\ttraining's auc: 0.962112\tvalid_1's auc: 0.894408\n",
      "[122]\ttraining's auc: 0.962489\tvalid_1's auc: 0.89455\n",
      "[123]\ttraining's auc: 0.96278\tvalid_1's auc: 0.894606\n",
      "[124]\ttraining's auc: 0.963227\tvalid_1's auc: 0.894807\n",
      "[125]\ttraining's auc: 0.963547\tvalid_1's auc: 0.894935\n",
      "[126]\ttraining's auc: 0.963846\tvalid_1's auc: 0.895086\n",
      "[127]\ttraining's auc: 0.964305\tvalid_1's auc: 0.895323\n",
      "[128]\ttraining's auc: 0.964595\tvalid_1's auc: 0.895368\n",
      "[129]\ttraining's auc: 0.964874\tvalid_1's auc: 0.895413\n",
      "[130]\ttraining's auc: 0.965201\tvalid_1's auc: 0.895555\n",
      "[131]\ttraining's auc: 0.965571\tvalid_1's auc: 0.89569\n",
      "[132]\ttraining's auc: 0.965914\tvalid_1's auc: 0.895826\n",
      "[133]\ttraining's auc: 0.966221\tvalid_1's auc: 0.896027\n",
      "[134]\ttraining's auc: 0.966563\tvalid_1's auc: 0.896165\n",
      "[135]\ttraining's auc: 0.966935\tvalid_1's auc: 0.896429\n",
      "[136]\ttraining's auc: 0.967239\tvalid_1's auc: 0.896735\n",
      "[137]\ttraining's auc: 0.967525\tvalid_1's auc: 0.896924\n",
      "[138]\ttraining's auc: 0.967805\tvalid_1's auc: 0.897169\n",
      "[139]\ttraining's auc: 0.968143\tvalid_1's auc: 0.897183\n",
      "[140]\ttraining's auc: 0.968429\tvalid_1's auc: 0.897272\n",
      "[141]\ttraining's auc: 0.968697\tvalid_1's auc: 0.89734\n",
      "[142]\ttraining's auc: 0.968965\tvalid_1's auc: 0.897441\n",
      "[143]\ttraining's auc: 0.96924\tvalid_1's auc: 0.897528\n",
      "[144]\ttraining's auc: 0.96956\tvalid_1's auc: 0.897628\n",
      "[145]\ttraining's auc: 0.969733\tvalid_1's auc: 0.897584\n",
      "[146]\ttraining's auc: 0.969971\tvalid_1's auc: 0.897762\n",
      "[147]\ttraining's auc: 0.970173\tvalid_1's auc: 0.897773\n",
      "[148]\ttraining's auc: 0.970405\tvalid_1's auc: 0.897945\n",
      "[149]\ttraining's auc: 0.970627\tvalid_1's auc: 0.897964\n",
      "[150]\ttraining's auc: 0.970843\tvalid_1's auc: 0.897979\n",
      "[151]\ttraining's auc: 0.971063\tvalid_1's auc: 0.898064\n",
      "[152]\ttraining's auc: 0.971259\tvalid_1's auc: 0.898206\n",
      "[153]\ttraining's auc: 0.971456\tvalid_1's auc: 0.898269\n",
      "[154]\ttraining's auc: 0.971573\tvalid_1's auc: 0.898336\n",
      "[155]\ttraining's auc: 0.97179\tvalid_1's auc: 0.898359\n",
      "[156]\ttraining's auc: 0.971909\tvalid_1's auc: 0.898491\n",
      "[157]\ttraining's auc: 0.97207\tvalid_1's auc: 0.898522\n",
      "[158]\ttraining's auc: 0.972267\tvalid_1's auc: 0.898576\n",
      "[159]\ttraining's auc: 0.972453\tvalid_1's auc: 0.898671\n",
      "[160]\ttraining's auc: 0.972679\tvalid_1's auc: 0.898719\n",
      "[161]\ttraining's auc: 0.972852\tvalid_1's auc: 0.898758\n",
      "[162]\ttraining's auc: 0.97306\tvalid_1's auc: 0.898814\n",
      "[163]\ttraining's auc: 0.9733\tvalid_1's auc: 0.898967\n",
      "[164]\ttraining's auc: 0.973412\tvalid_1's auc: 0.89897\n",
      "[165]\ttraining's auc: 0.973592\tvalid_1's auc: 0.899042\n",
      "[166]\ttraining's auc: 0.97373\tvalid_1's auc: 0.899086\n",
      "[167]\ttraining's auc: 0.973934\tvalid_1's auc: 0.899143\n",
      "[168]\ttraining's auc: 0.974071\tvalid_1's auc: 0.899251\n",
      "[169]\ttraining's auc: 0.974202\tvalid_1's auc: 0.899227\n",
      "[170]\ttraining's auc: 0.974361\tvalid_1's auc: 0.899256\n",
      "[171]\ttraining's auc: 0.974504\tvalid_1's auc: 0.899265\n",
      "[172]\ttraining's auc: 0.974702\tvalid_1's auc: 0.899221\n",
      "[173]\ttraining's auc: 0.974904\tvalid_1's auc: 0.899289\n",
      "[174]\ttraining's auc: 0.975123\tvalid_1's auc: 0.899375\n",
      "[175]\ttraining's auc: 0.975218\tvalid_1's auc: 0.899417\n",
      "[176]\ttraining's auc: 0.975295\tvalid_1's auc: 0.899486\n",
      "[177]\ttraining's auc: 0.975514\tvalid_1's auc: 0.899523\n",
      "[178]\ttraining's auc: 0.975696\tvalid_1's auc: 0.899603\n",
      "[179]\ttraining's auc: 0.975852\tvalid_1's auc: 0.899726\n",
      "[180]\ttraining's auc: 0.976022\tvalid_1's auc: 0.899789\n",
      "[181]\ttraining's auc: 0.97621\tvalid_1's auc: 0.899842\n",
      "[182]\ttraining's auc: 0.976392\tvalid_1's auc: 0.899985\n",
      "[183]\ttraining's auc: 0.976552\tvalid_1's auc: 0.900088\n",
      "[184]\ttraining's auc: 0.976659\tvalid_1's auc: 0.900142\n",
      "[185]\ttraining's auc: 0.976754\tvalid_1's auc: 0.900185\n",
      "[186]\ttraining's auc: 0.97683\tvalid_1's auc: 0.900294\n",
      "[187]\ttraining's auc: 0.976919\tvalid_1's auc: 0.90031\n",
      "[188]\ttraining's auc: 0.977096\tvalid_1's auc: 0.90044\n",
      "[189]\ttraining's auc: 0.977293\tvalid_1's auc: 0.90048\n",
      "[190]\ttraining's auc: 0.977401\tvalid_1's auc: 0.900497\n",
      "[191]\ttraining's auc: 0.977464\tvalid_1's auc: 0.900515\n",
      "[192]\ttraining's auc: 0.977626\tvalid_1's auc: 0.900635\n",
      "[193]\ttraining's auc: 0.977804\tvalid_1's auc: 0.900758\n",
      "[194]\ttraining's auc: 0.977954\tvalid_1's auc: 0.900855\n",
      "[195]\ttraining's auc: 0.978093\tvalid_1's auc: 0.90089\n",
      "[196]\ttraining's auc: 0.978291\tvalid_1's auc: 0.900988\n",
      "[197]\ttraining's auc: 0.978444\tvalid_1's auc: 0.901071\n",
      "[198]\ttraining's auc: 0.978607\tvalid_1's auc: 0.901161\n",
      "[199]\ttraining's auc: 0.978701\tvalid_1's auc: 0.901269\n",
      "[200]\ttraining's auc: 0.978735\tvalid_1's auc: 0.901364\n",
      "[201]\ttraining's auc: 0.978823\tvalid_1's auc: 0.901447\n",
      "[202]\ttraining's auc: 0.978872\tvalid_1's auc: 0.901418\n",
      "[203]\ttraining's auc: 0.978941\tvalid_1's auc: 0.901457\n",
      "[204]\ttraining's auc: 0.979047\tvalid_1's auc: 0.901446\n",
      "[205]\ttraining's auc: 0.979164\tvalid_1's auc: 0.901514\n",
      "[206]\ttraining's auc: 0.979219\tvalid_1's auc: 0.901562\n",
      "[207]\ttraining's auc: 0.979375\tvalid_1's auc: 0.901708\n",
      "[208]\ttraining's auc: 0.979439\tvalid_1's auc: 0.901773\n",
      "[209]\ttraining's auc: 0.979496\tvalid_1's auc: 0.90186\n",
      "[210]\ttraining's auc: 0.979581\tvalid_1's auc: 0.901871\n",
      "[211]\ttraining's auc: 0.979711\tvalid_1's auc: 0.901957\n",
      "[212]\ttraining's auc: 0.979804\tvalid_1's auc: 0.902006\n",
      "[213]\ttraining's auc: 0.979843\tvalid_1's auc: 0.902049\n",
      "[214]\ttraining's auc: 0.979906\tvalid_1's auc: 0.902076\n",
      "[215]\ttraining's auc: 0.980019\tvalid_1's auc: 0.902087\n",
      "[216]\ttraining's auc: 0.980073\tvalid_1's auc: 0.902117\n",
      "[217]\ttraining's auc: 0.980179\tvalid_1's auc: 0.90211\n",
      "[218]\ttraining's auc: 0.9803\tvalid_1's auc: 0.902081\n",
      "[219]\ttraining's auc: 0.980352\tvalid_1's auc: 0.902101\n",
      "[220]\ttraining's auc: 0.9804\tvalid_1's auc: 0.902117\n",
      "[221]\ttraining's auc: 0.980537\tvalid_1's auc: 0.902227\n",
      "[222]\ttraining's auc: 0.980689\tvalid_1's auc: 0.902295\n",
      "[223]\ttraining's auc: 0.980724\tvalid_1's auc: 0.902253\n",
      "[224]\ttraining's auc: 0.980759\tvalid_1's auc: 0.902212\n",
      "[225]\ttraining's auc: 0.980818\tvalid_1's auc: 0.902234\n",
      "[226]\ttraining's auc: 0.980886\tvalid_1's auc: 0.902195\n",
      "[227]\ttraining's auc: 0.980963\tvalid_1's auc: 0.90214\n",
      "[228]\ttraining's auc: 0.981052\tvalid_1's auc: 0.902224\n",
      "[229]\ttraining's auc: 0.981157\tvalid_1's auc: 0.902233\n",
      "[230]\ttraining's auc: 0.981268\tvalid_1's auc: 0.902235\n",
      "[231]\ttraining's auc: 0.981338\tvalid_1's auc: 0.902212\n",
      "[232]\ttraining's auc: 0.981502\tvalid_1's auc: 0.90232\n",
      "[233]\ttraining's auc: 0.981544\tvalid_1's auc: 0.90239\n",
      "[234]\ttraining's auc: 0.981686\tvalid_1's auc: 0.902577\n",
      "[235]\ttraining's auc: 0.981728\tvalid_1's auc: 0.902551\n",
      "[236]\ttraining's auc: 0.981793\tvalid_1's auc: 0.902551\n",
      "[237]\ttraining's auc: 0.981852\tvalid_1's auc: 0.902524\n",
      "[238]\ttraining's auc: 0.981918\tvalid_1's auc: 0.902493\n",
      "[239]\ttraining's auc: 0.981948\tvalid_1's auc: 0.90248\n",
      "[240]\ttraining's auc: 0.982009\tvalid_1's auc: 0.902437\n",
      "[241]\ttraining's auc: 0.982156\tvalid_1's auc: 0.902585\n",
      "[242]\ttraining's auc: 0.982279\tvalid_1's auc: 0.902728\n",
      "[243]\ttraining's auc: 0.982414\tvalid_1's auc: 0.902904\n",
      "[244]\ttraining's auc: 0.982513\tvalid_1's auc: 0.902976\n",
      "[245]\ttraining's auc: 0.982619\tvalid_1's auc: 0.903015\n",
      "[246]\ttraining's auc: 0.982757\tvalid_1's auc: 0.903068\n",
      "[247]\ttraining's auc: 0.982881\tvalid_1's auc: 0.903095\n",
      "[248]\ttraining's auc: 0.982965\tvalid_1's auc: 0.903078\n",
      "[249]\ttraining's auc: 0.983088\tvalid_1's auc: 0.903074\n",
      "[250]\ttraining's auc: 0.983209\tvalid_1's auc: 0.903193\n",
      "[251]\ttraining's auc: 0.983277\tvalid_1's auc: 0.90328\n",
      "[252]\ttraining's auc: 0.983306\tvalid_1's auc: 0.903248\n",
      "[253]\ttraining's auc: 0.983406\tvalid_1's auc: 0.90322\n",
      "[254]\ttraining's auc: 0.983484\tvalid_1's auc: 0.903188\n",
      "[255]\ttraining's auc: 0.983595\tvalid_1's auc: 0.903128\n",
      "[256]\ttraining's auc: 0.983656\tvalid_1's auc: 0.903097\n",
      "[257]\ttraining's auc: 0.98369\tvalid_1's auc: 0.903084\n",
      "[258]\ttraining's auc: 0.983736\tvalid_1's auc: 0.903094\n",
      "[259]\ttraining's auc: 0.983787\tvalid_1's auc: 0.90307\n",
      "[260]\ttraining's auc: 0.983814\tvalid_1's auc: 0.903069\n",
      "[261]\ttraining's auc: 0.983856\tvalid_1's auc: 0.902998\n",
      "[262]\ttraining's auc: 0.983962\tvalid_1's auc: 0.902984\n",
      "[263]\ttraining's auc: 0.983988\tvalid_1's auc: 0.902989\n",
      "[264]\ttraining's auc: 0.984048\tvalid_1's auc: 0.903031\n",
      "[265]\ttraining's auc: 0.984087\tvalid_1's auc: 0.90305\n",
      "[266]\ttraining's auc: 0.98411\tvalid_1's auc: 0.903075\n",
      "[267]\ttraining's auc: 0.984123\tvalid_1's auc: 0.903055\n",
      "[268]\ttraining's auc: 0.984242\tvalid_1's auc: 0.903078\n",
      "[269]\ttraining's auc: 0.984336\tvalid_1's auc: 0.903052\n",
      "[270]\ttraining's auc: 0.984433\tvalid_1's auc: 0.903088\n",
      "[271]\ttraining's auc: 0.984519\tvalid_1's auc: 0.903125\n",
      "[272]\ttraining's auc: 0.984609\tvalid_1's auc: 0.903192\n",
      "[273]\ttraining's auc: 0.984644\tvalid_1's auc: 0.903174\n",
      "[274]\ttraining's auc: 0.984666\tvalid_1's auc: 0.903144\n",
      "[275]\ttraining's auc: 0.984692\tvalid_1's auc: 0.903137\n",
      "[276]\ttraining's auc: 0.984704\tvalid_1's auc: 0.903146\n",
      "[277]\ttraining's auc: 0.984827\tvalid_1's auc: 0.903215\n",
      "[278]\ttraining's auc: 0.984932\tvalid_1's auc: 0.903287\n",
      "[279]\ttraining's auc: 0.985028\tvalid_1's auc: 0.903311\n",
      "[280]\ttraining's auc: 0.985106\tvalid_1's auc: 0.903247\n",
      "[281]\ttraining's auc: 0.985124\tvalid_1's auc: 0.903234\n",
      "[282]\ttraining's auc: 0.985164\tvalid_1's auc: 0.903172\n",
      "[283]\ttraining's auc: 0.985273\tvalid_1's auc: 0.903156\n",
      "[284]\ttraining's auc: 0.985376\tvalid_1's auc: 0.90316\n",
      "[285]\ttraining's auc: 0.98551\tvalid_1's auc: 0.903107\n",
      "[286]\ttraining's auc: 0.985598\tvalid_1's auc: 0.90309\n",
      "[287]\ttraining's auc: 0.98568\tvalid_1's auc: 0.903133\n",
      "[288]\ttraining's auc: 0.985781\tvalid_1's auc: 0.903205\n",
      "[289]\ttraining's auc: 0.985844\tvalid_1's auc: 0.903172\n",
      "[290]\ttraining's auc: 0.985965\tvalid_1's auc: 0.90322\n",
      "[291]\ttraining's auc: 0.98598\tvalid_1's auc: 0.903215\n",
      "[292]\ttraining's auc: 0.986031\tvalid_1's auc: 0.903207\n",
      "[293]\ttraining's auc: 0.986087\tvalid_1's auc: 0.903186\n",
      "[294]\ttraining's auc: 0.986163\tvalid_1's auc: 0.903173\n",
      "[295]\ttraining's auc: 0.986273\tvalid_1's auc: 0.903129\n",
      "[296]\ttraining's auc: 0.986306\tvalid_1's auc: 0.903111\n",
      "[297]\ttraining's auc: 0.986359\tvalid_1's auc: 0.903086\n",
      "[298]\ttraining's auc: 0.986393\tvalid_1's auc: 0.903036\n",
      "[299]\ttraining's auc: 0.986433\tvalid_1's auc: 0.903062\n",
      "[300]\ttraining's auc: 0.986464\tvalid_1's auc: 0.903062\n",
      "[301]\ttraining's auc: 0.9865\tvalid_1's auc: 0.903061\n",
      "[302]\ttraining's auc: 0.986517\tvalid_1's auc: 0.903065\n",
      "[303]\ttraining's auc: 0.986545\tvalid_1's auc: 0.903045\n",
      "[304]\ttraining's auc: 0.986646\tvalid_1's auc: 0.902975\n",
      "[305]\ttraining's auc: 0.986737\tvalid_1's auc: 0.902957\n",
      "[306]\ttraining's auc: 0.986802\tvalid_1's auc: 0.902919\n",
      "[307]\ttraining's auc: 0.986912\tvalid_1's auc: 0.903078\n",
      "[308]\ttraining's auc: 0.986927\tvalid_1's auc: 0.903078\n",
      "[309]\ttraining's auc: 0.986952\tvalid_1's auc: 0.903051\n",
      "[310]\ttraining's auc: 0.987061\tvalid_1's auc: 0.903191\n",
      "[311]\ttraining's auc: 0.987071\tvalid_1's auc: 0.903184\n",
      "[312]\ttraining's auc: 0.987165\tvalid_1's auc: 0.903252\n",
      "[313]\ttraining's auc: 0.987261\tvalid_1's auc: 0.903272\n",
      "[314]\ttraining's auc: 0.987362\tvalid_1's auc: 0.903355\n",
      "[315]\ttraining's auc: 0.987419\tvalid_1's auc: 0.903406\n",
      "[316]\ttraining's auc: 0.987462\tvalid_1's auc: 0.903312\n",
      "[317]\ttraining's auc: 0.987503\tvalid_1's auc: 0.903212\n",
      "[318]\ttraining's auc: 0.987516\tvalid_1's auc: 0.903183\n",
      "[319]\ttraining's auc: 0.987531\tvalid_1's auc: 0.903171\n",
      "[320]\ttraining's auc: 0.987541\tvalid_1's auc: 0.903166\n",
      "[321]\ttraining's auc: 0.987589\tvalid_1's auc: 0.903126\n",
      "[322]\ttraining's auc: 0.987639\tvalid_1's auc: 0.903055\n",
      "[323]\ttraining's auc: 0.987666\tvalid_1's auc: 0.903031\n",
      "[324]\ttraining's auc: 0.987718\tvalid_1's auc: 0.903007\n",
      "[325]\ttraining's auc: 0.987791\tvalid_1's auc: 0.902947\n",
      "[326]\ttraining's auc: 0.987868\tvalid_1's auc: 0.902957\n",
      "[327]\ttraining's auc: 0.987922\tvalid_1's auc: 0.902931\n",
      "[328]\ttraining's auc: 0.98799\tvalid_1's auc: 0.90291\n",
      "[329]\ttraining's auc: 0.988031\tvalid_1's auc: 0.902855\n",
      "[330]\ttraining's auc: 0.988095\tvalid_1's auc: 0.902851\n",
      "[331]\ttraining's auc: 0.988126\tvalid_1's auc: 0.902825\n",
      "[332]\ttraining's auc: 0.98814\tvalid_1's auc: 0.902777\n",
      "[333]\ttraining's auc: 0.988165\tvalid_1's auc: 0.902715\n",
      "[334]\ttraining's auc: 0.988238\tvalid_1's auc: 0.902739\n",
      "[335]\ttraining's auc: 0.988302\tvalid_1's auc: 0.902709\n",
      "[336]\ttraining's auc: 0.988357\tvalid_1's auc: 0.902697\n",
      "[337]\ttraining's auc: 0.988421\tvalid_1's auc: 0.902727\n",
      "[338]\ttraining's auc: 0.988471\tvalid_1's auc: 0.902709\n",
      "[339]\ttraining's auc: 0.988501\tvalid_1's auc: 0.90274\n",
      "[340]\ttraining's auc: 0.988595\tvalid_1's auc: 0.902701\n",
      "[341]\ttraining's auc: 0.988654\tvalid_1's auc: 0.902656\n",
      "[342]\ttraining's auc: 0.988747\tvalid_1's auc: 0.902641\n",
      "[343]\ttraining's auc: 0.988804\tvalid_1's auc: 0.902672\n",
      "[344]\ttraining's auc: 0.98888\tvalid_1's auc: 0.902747\n",
      "[345]\ttraining's auc: 0.988919\tvalid_1's auc: 0.902799\n",
      "[346]\ttraining's auc: 0.988958\tvalid_1's auc: 0.902747\n",
      "[347]\ttraining's auc: 0.988997\tvalid_1's auc: 0.902722\n",
      "[348]\ttraining's auc: 0.989018\tvalid_1's auc: 0.902663\n",
      "[349]\ttraining's auc: 0.989064\tvalid_1's auc: 0.902593\n",
      "[350]\ttraining's auc: 0.989139\tvalid_1's auc: 0.902596\n",
      "[351]\ttraining's auc: 0.98917\tvalid_1's auc: 0.902543\n",
      "[352]\ttraining's auc: 0.989226\tvalid_1's auc: 0.902507\n",
      "[353]\ttraining's auc: 0.989245\tvalid_1's auc: 0.902448\n",
      "[354]\ttraining's auc: 0.989269\tvalid_1's auc: 0.902394\n",
      "[355]\ttraining's auc: 0.989282\tvalid_1's auc: 0.902382\n",
      "[356]\ttraining's auc: 0.989324\tvalid_1's auc: 0.90233\n",
      "[357]\ttraining's auc: 0.989345\tvalid_1's auc: 0.902332\n",
      "[358]\ttraining's auc: 0.989374\tvalid_1's auc: 0.902353\n",
      "[359]\ttraining's auc: 0.989386\tvalid_1's auc: 0.90235\n",
      "[360]\ttraining's auc: 0.989426\tvalid_1's auc: 0.902374\n",
      "[361]\ttraining's auc: 0.989476\tvalid_1's auc: 0.902322\n",
      "[362]\ttraining's auc: 0.989547\tvalid_1's auc: 0.902285\n",
      "[363]\ttraining's auc: 0.989605\tvalid_1's auc: 0.902332\n",
      "[364]\ttraining's auc: 0.989642\tvalid_1's auc: 0.90228\n",
      "[365]\ttraining's auc: 0.989667\tvalid_1's auc: 0.902235\n",
      "[366]\ttraining's auc: 0.989703\tvalid_1's auc: 0.902185\n",
      "[367]\ttraining's auc: 0.989747\tvalid_1's auc: 0.902141\n",
      "[368]\ttraining's auc: 0.98977\tvalid_1's auc: 0.902085\n",
      "[369]\ttraining's auc: 0.989824\tvalid_1's auc: 0.902074\n",
      "[370]\ttraining's auc: 0.989863\tvalid_1's auc: 0.902141\n",
      "[371]\ttraining's auc: 0.9899\tvalid_1's auc: 0.902161\n",
      "[372]\ttraining's auc: 0.989945\tvalid_1's auc: 0.902184\n",
      "[373]\ttraining's auc: 0.989976\tvalid_1's auc: 0.902197\n",
      "[374]\ttraining's auc: 0.99001\tvalid_1's auc: 0.902212\n",
      "[375]\ttraining's auc: 0.990041\tvalid_1's auc: 0.902208\n",
      "[376]\ttraining's auc: 0.990061\tvalid_1's auc: 0.902185\n",
      "[377]\ttraining's auc: 0.990087\tvalid_1's auc: 0.902168\n",
      "[378]\ttraining's auc: 0.990131\tvalid_1's auc: 0.90214\n",
      "[379]\ttraining's auc: 0.990144\tvalid_1's auc: 0.902104\n",
      "[380]\ttraining's auc: 0.990166\tvalid_1's auc: 0.90209\n",
      "[381]\ttraining's auc: 0.990177\tvalid_1's auc: 0.902089\n",
      "[382]\ttraining's auc: 0.990188\tvalid_1's auc: 0.902076\n",
      "[383]\ttraining's auc: 0.990216\tvalid_1's auc: 0.902014\n",
      "[384]\ttraining's auc: 0.990233\tvalid_1's auc: 0.902034\n",
      "[385]\ttraining's auc: 0.990326\tvalid_1's auc: 0.90204\n",
      "[386]\ttraining's auc: 0.990406\tvalid_1's auc: 0.902026\n",
      "[387]\ttraining's auc: 0.990433\tvalid_1's auc: 0.902025\n",
      "[388]\ttraining's auc: 0.990474\tvalid_1's auc: 0.902002\n",
      "[389]\ttraining's auc: 0.990534\tvalid_1's auc: 0.902014\n",
      "[390]\ttraining's auc: 0.99055\tvalid_1's auc: 0.902041\n",
      "[391]\ttraining's auc: 0.990597\tvalid_1's auc: 0.902038\n",
      "[392]\ttraining's auc: 0.99064\tvalid_1's auc: 0.901998\n",
      "[393]\ttraining's auc: 0.990649\tvalid_1's auc: 0.901979\n",
      "[394]\ttraining's auc: 0.990691\tvalid_1's auc: 0.901993\n",
      "[395]\ttraining's auc: 0.990699\tvalid_1's auc: 0.902006\n",
      "[396]\ttraining's auc: 0.990757\tvalid_1's auc: 0.901996\n",
      "[397]\ttraining's auc: 0.99079\tvalid_1's auc: 0.901925\n",
      "[398]\ttraining's auc: 0.990821\tvalid_1's auc: 0.901892\n",
      "[399]\ttraining's auc: 0.990847\tvalid_1's auc: 0.901865\n",
      "[400]\ttraining's auc: 0.990876\tvalid_1's auc: 0.901894\n",
      "[401]\ttraining's auc: 0.990931\tvalid_1's auc: 0.90191\n",
      "[402]\ttraining's auc: 0.990954\tvalid_1's auc: 0.901984\n",
      "[403]\ttraining's auc: 0.991002\tvalid_1's auc: 0.901986\n",
      "[404]\ttraining's auc: 0.99105\tvalid_1's auc: 0.902029\n",
      "[405]\ttraining's auc: 0.991088\tvalid_1's auc: 0.902044\n",
      "[406]\ttraining's auc: 0.991113\tvalid_1's auc: 0.901996\n",
      "[407]\ttraining's auc: 0.991137\tvalid_1's auc: 0.902006\n",
      "[408]\ttraining's auc: 0.99116\tvalid_1's auc: 0.901923\n",
      "[409]\ttraining's auc: 0.991177\tvalid_1's auc: 0.901857\n",
      "[410]\ttraining's auc: 0.991185\tvalid_1's auc: 0.901805\n",
      "[411]\ttraining's auc: 0.991194\tvalid_1's auc: 0.901758\n",
      "[412]\ttraining's auc: 0.99124\tvalid_1's auc: 0.901767\n",
      "[413]\ttraining's auc: 0.991251\tvalid_1's auc: 0.901774\n",
      "[414]\ttraining's auc: 0.991283\tvalid_1's auc: 0.901768\n",
      "[415]\ttraining's auc: 0.991332\tvalid_1's auc: 0.901728\n",
      "[416]\ttraining's auc: 0.991387\tvalid_1's auc: 0.901727\n",
      "[417]\ttraining's auc: 0.991415\tvalid_1's auc: 0.901755\n",
      "[418]\ttraining's auc: 0.991433\tvalid_1's auc: 0.90175\n",
      "[419]\ttraining's auc: 0.991461\tvalid_1's auc: 0.901758\n",
      "[420]\ttraining's auc: 0.991525\tvalid_1's auc: 0.901816\n",
      "[421]\ttraining's auc: 0.991591\tvalid_1's auc: 0.90178\n",
      "[422]\ttraining's auc: 0.991653\tvalid_1's auc: 0.901733\n",
      "[423]\ttraining's auc: 0.991705\tvalid_1's auc: 0.901652\n",
      "[424]\ttraining's auc: 0.991713\tvalid_1's auc: 0.901639\n",
      "[425]\ttraining's auc: 0.991718\tvalid_1's auc: 0.901597\n",
      "[426]\ttraining's auc: 0.991723\tvalid_1's auc: 0.901551\n",
      "[427]\ttraining's auc: 0.991778\tvalid_1's auc: 0.901668\n",
      "[428]\ttraining's auc: 0.991812\tvalid_1's auc: 0.901613\n",
      "[429]\ttraining's auc: 0.991868\tvalid_1's auc: 0.901596\n",
      "[430]\ttraining's auc: 0.991875\tvalid_1's auc: 0.901539\n",
      "[431]\ttraining's auc: 0.99188\tvalid_1's auc: 0.901515\n",
      "[432]\ttraining's auc: 0.991884\tvalid_1's auc: 0.901507\n",
      "[433]\ttraining's auc: 0.991926\tvalid_1's auc: 0.901484\n",
      "[434]\ttraining's auc: 0.991941\tvalid_1's auc: 0.901497\n",
      "[435]\ttraining's auc: 0.992\tvalid_1's auc: 0.901531\n",
      "[436]\ttraining's auc: 0.992045\tvalid_1's auc: 0.901509\n",
      "[437]\ttraining's auc: 0.992055\tvalid_1's auc: 0.901495\n",
      "[438]\ttraining's auc: 0.992121\tvalid_1's auc: 0.901492\n",
      "[439]\ttraining's auc: 0.992154\tvalid_1's auc: 0.901582\n",
      "[440]\ttraining's auc: 0.9922\tvalid_1's auc: 0.901593\n",
      "[441]\ttraining's auc: 0.992232\tvalid_1's auc: 0.901548\n",
      "[442]\ttraining's auc: 0.992287\tvalid_1's auc: 0.901577\n",
      "[443]\ttraining's auc: 0.992323\tvalid_1's auc: 0.901497\n",
      "[444]\ttraining's auc: 0.992363\tvalid_1's auc: 0.901501\n",
      "[445]\ttraining's auc: 0.992372\tvalid_1's auc: 0.901502\n",
      "[446]\ttraining's auc: 0.992389\tvalid_1's auc: 0.901574\n",
      "[447]\ttraining's auc: 0.99242\tvalid_1's auc: 0.901611\n",
      "[448]\ttraining's auc: 0.992433\tvalid_1's auc: 0.901598\n",
      "[449]\ttraining's auc: 0.992438\tvalid_1's auc: 0.90159\n",
      "[450]\ttraining's auc: 0.992449\tvalid_1's auc: 0.90158\n",
      "[451]\ttraining's auc: 0.992462\tvalid_1's auc: 0.901515\n",
      "[452]\ttraining's auc: 0.99252\tvalid_1's auc: 0.901569\n",
      "[453]\ttraining's auc: 0.99257\tvalid_1's auc: 0.901518\n",
      "[454]\ttraining's auc: 0.992587\tvalid_1's auc: 0.901491\n",
      "[455]\ttraining's auc: 0.992601\tvalid_1's auc: 0.901445\n",
      "[456]\ttraining's auc: 0.992614\tvalid_1's auc: 0.901419\n",
      "[457]\ttraining's auc: 0.992638\tvalid_1's auc: 0.901365\n",
      "[458]\ttraining's auc: 0.992664\tvalid_1's auc: 0.901387\n",
      "[459]\ttraining's auc: 0.992685\tvalid_1's auc: 0.901406\n",
      "[460]\ttraining's auc: 0.992695\tvalid_1's auc: 0.901417\n",
      "[461]\ttraining's auc: 0.992709\tvalid_1's auc: 0.901392\n",
      "[462]\ttraining's auc: 0.99274\tvalid_1's auc: 0.901394\n",
      "[463]\ttraining's auc: 0.992748\tvalid_1's auc: 0.901376\n",
      "[464]\ttraining's auc: 0.992756\tvalid_1's auc: 0.901368\n",
      "[465]\ttraining's auc: 0.992767\tvalid_1's auc: 0.901368\n",
      "[466]\ttraining's auc: 0.99278\tvalid_1's auc: 0.901373\n",
      "[467]\ttraining's auc: 0.99281\tvalid_1's auc: 0.901376\n",
      "[468]\ttraining's auc: 0.992834\tvalid_1's auc: 0.901323\n",
      "[469]\ttraining's auc: 0.992858\tvalid_1's auc: 0.9013\n",
      "[470]\ttraining's auc: 0.992879\tvalid_1's auc: 0.901264\n",
      "[471]\ttraining's auc: 0.992904\tvalid_1's auc: 0.901247\n",
      "[472]\ttraining's auc: 0.992941\tvalid_1's auc: 0.901348\n",
      "[473]\ttraining's auc: 0.992974\tvalid_1's auc: 0.901421\n",
      "[474]\ttraining's auc: 0.993007\tvalid_1's auc: 0.901499\n",
      "[475]\ttraining's auc: 0.993017\tvalid_1's auc: 0.901482\n",
      "[476]\ttraining's auc: 0.99303\tvalid_1's auc: 0.90145\n",
      "[477]\ttraining's auc: 0.993056\tvalid_1's auc: 0.901441\n",
      "[478]\ttraining's auc: 0.993068\tvalid_1's auc: 0.90143\n",
      "[479]\ttraining's auc: 0.99309\tvalid_1's auc: 0.901417\n",
      "[480]\ttraining's auc: 0.993121\tvalid_1's auc: 0.90143\n",
      "[481]\ttraining's auc: 0.993174\tvalid_1's auc: 0.901405\n",
      "[482]\ttraining's auc: 0.993215\tvalid_1's auc: 0.901466\n",
      "[483]\ttraining's auc: 0.993269\tvalid_1's auc: 0.901482\n",
      "[484]\ttraining's auc: 0.993283\tvalid_1's auc: 0.901451\n",
      "[485]\ttraining's auc: 0.993312\tvalid_1's auc: 0.901437\n",
      "[486]\ttraining's auc: 0.993337\tvalid_1's auc: 0.901361\n",
      "[487]\ttraining's auc: 0.993355\tvalid_1's auc: 0.901335\n",
      "[488]\ttraining's auc: 0.993363\tvalid_1's auc: 0.901329\n",
      "[489]\ttraining's auc: 0.993398\tvalid_1's auc: 0.901311\n",
      "[490]\ttraining's auc: 0.993445\tvalid_1's auc: 0.901336\n",
      "[491]\ttraining's auc: 0.993467\tvalid_1's auc: 0.901313\n",
      "[492]\ttraining's auc: 0.993473\tvalid_1's auc: 0.90127\n",
      "[493]\ttraining's auc: 0.993495\tvalid_1's auc: 0.901183\n",
      "[494]\ttraining's auc: 0.99354\tvalid_1's auc: 0.90118\n",
      "[495]\ttraining's auc: 0.993565\tvalid_1's auc: 0.901142\n",
      "[496]\ttraining's auc: 0.99362\tvalid_1's auc: 0.901104\n",
      "[497]\ttraining's auc: 0.993657\tvalid_1's auc: 0.901025\n",
      "[498]\ttraining's auc: 0.993714\tvalid_1's auc: 0.901\n",
      "[499]\ttraining's auc: 0.993733\tvalid_1's auc: 0.900967\n",
      "[500]\ttraining's auc: 0.993746\tvalid_1's auc: 0.900928\n",
      "[501]\ttraining's auc: 0.993767\tvalid_1's auc: 0.900857\n",
      "[502]\ttraining's auc: 0.993779\tvalid_1's auc: 0.900832\n",
      "[503]\ttraining's auc: 0.993808\tvalid_1's auc: 0.900806\n",
      "[504]\ttraining's auc: 0.99382\tvalid_1's auc: 0.900772\n",
      "[505]\ttraining's auc: 0.993865\tvalid_1's auc: 0.900827\n",
      "[506]\ttraining's auc: 0.993896\tvalid_1's auc: 0.900821\n",
      "[507]\ttraining's auc: 0.993917\tvalid_1's auc: 0.900859\n",
      "[508]\ttraining's auc: 0.993942\tvalid_1's auc: 0.900754\n",
      "[509]\ttraining's auc: 0.993958\tvalid_1's auc: 0.900737\n",
      "[510]\ttraining's auc: 0.993969\tvalid_1's auc: 0.900729\n",
      "[511]\ttraining's auc: 0.993972\tvalid_1's auc: 0.900686\n",
      "[512]\ttraining's auc: 0.993983\tvalid_1's auc: 0.900651\n",
      "[513]\ttraining's auc: 0.993996\tvalid_1's auc: 0.900631\n",
      "[514]\ttraining's auc: 0.99403\tvalid_1's auc: 0.900636\n",
      "[515]\ttraining's auc: 0.994055\tvalid_1's auc: 0.900581\n",
      "Early stopping, best iteration is:\n",
      "[315]\ttraining's auc: 0.987419\tvalid_1's auc: 0.903406\n",
      "Fold 3\n",
      "[1]\ttraining's auc: 0.878235\tvalid_1's auc: 0.844553\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\ttraining's auc: 0.886267\tvalid_1's auc: 0.854599\n",
      "[3]\ttraining's auc: 0.890942\tvalid_1's auc: 0.865429\n",
      "[4]\ttraining's auc: 0.893143\tvalid_1's auc: 0.87009\n",
      "[5]\ttraining's auc: 0.895363\tvalid_1's auc: 0.872478\n",
      "[6]\ttraining's auc: 0.896172\tvalid_1's auc: 0.873752\n",
      "[7]\ttraining's auc: 0.898006\tvalid_1's auc: 0.87467\n",
      "[8]\ttraining's auc: 0.898838\tvalid_1's auc: 0.875162\n",
      "[9]\ttraining's auc: 0.899925\tvalid_1's auc: 0.875462\n",
      "[10]\ttraining's auc: 0.90112\tvalid_1's auc: 0.876123\n",
      "[11]\ttraining's auc: 0.901437\tvalid_1's auc: 0.876566\n",
      "[12]\ttraining's auc: 0.901709\tvalid_1's auc: 0.876693\n",
      "[13]\ttraining's auc: 0.902594\tvalid_1's auc: 0.877823\n",
      "[14]\ttraining's auc: 0.903332\tvalid_1's auc: 0.878572\n",
      "[15]\ttraining's auc: 0.903504\tvalid_1's auc: 0.878663\n",
      "[16]\ttraining's auc: 0.903723\tvalid_1's auc: 0.878928\n",
      "[17]\ttraining's auc: 0.904143\tvalid_1's auc: 0.878726\n",
      "[18]\ttraining's auc: 0.904363\tvalid_1's auc: 0.878519\n",
      "[19]\ttraining's auc: 0.904657\tvalid_1's auc: 0.878628\n",
      "[20]\ttraining's auc: 0.904995\tvalid_1's auc: 0.878873\n",
      "[21]\ttraining's auc: 0.906153\tvalid_1's auc: 0.879814\n",
      "[22]\ttraining's auc: 0.906355\tvalid_1's auc: 0.879695\n",
      "[23]\ttraining's auc: 0.90654\tvalid_1's auc: 0.880002\n",
      "[24]\ttraining's auc: 0.906658\tvalid_1's auc: 0.880125\n",
      "[25]\ttraining's auc: 0.90705\tvalid_1's auc: 0.88005\n",
      "[26]\ttraining's auc: 0.907476\tvalid_1's auc: 0.880013\n",
      "[27]\ttraining's auc: 0.907871\tvalid_1's auc: 0.880267\n",
      "[28]\ttraining's auc: 0.909573\tvalid_1's auc: 0.880949\n",
      "[29]\ttraining's auc: 0.909824\tvalid_1's auc: 0.881084\n",
      "[30]\ttraining's auc: 0.910247\tvalid_1's auc: 0.881398\n",
      "[31]\ttraining's auc: 0.910806\tvalid_1's auc: 0.88185\n",
      "[32]\ttraining's auc: 0.911167\tvalid_1's auc: 0.88249\n",
      "[33]\ttraining's auc: 0.911507\tvalid_1's auc: 0.882613\n",
      "[34]\ttraining's auc: 0.912311\tvalid_1's auc: 0.88312\n",
      "[35]\ttraining's auc: 0.913767\tvalid_1's auc: 0.883852\n",
      "[36]\ttraining's auc: 0.914355\tvalid_1's auc: 0.884148\n",
      "[37]\ttraining's auc: 0.915435\tvalid_1's auc: 0.884985\n",
      "[38]\ttraining's auc: 0.915997\tvalid_1's auc: 0.885484\n",
      "[39]\ttraining's auc: 0.916293\tvalid_1's auc: 0.885633\n",
      "[40]\ttraining's auc: 0.916795\tvalid_1's auc: 0.885949\n",
      "[41]\ttraining's auc: 0.917447\tvalid_1's auc: 0.886124\n",
      "[42]\ttraining's auc: 0.917896\tvalid_1's auc: 0.886475\n",
      "[43]\ttraining's auc: 0.918356\tvalid_1's auc: 0.886607\n",
      "[44]\ttraining's auc: 0.918794\tvalid_1's auc: 0.886935\n",
      "[45]\ttraining's auc: 0.919239\tvalid_1's auc: 0.887155\n",
      "[46]\ttraining's auc: 0.919772\tvalid_1's auc: 0.88773\n",
      "[47]\ttraining's auc: 0.920513\tvalid_1's auc: 0.888036\n",
      "[48]\ttraining's auc: 0.92108\tvalid_1's auc: 0.888597\n",
      "[49]\ttraining's auc: 0.921612\tvalid_1's auc: 0.888721\n",
      "[50]\ttraining's auc: 0.921929\tvalid_1's auc: 0.888985\n",
      "[51]\ttraining's auc: 0.922377\tvalid_1's auc: 0.889224\n",
      "[52]\ttraining's auc: 0.922868\tvalid_1's auc: 0.889515\n",
      "[53]\ttraining's auc: 0.923477\tvalid_1's auc: 0.890211\n",
      "[54]\ttraining's auc: 0.924005\tvalid_1's auc: 0.890473\n",
      "[55]\ttraining's auc: 0.924687\tvalid_1's auc: 0.890813\n",
      "[56]\ttraining's auc: 0.925357\tvalid_1's auc: 0.891348\n",
      "[57]\ttraining's auc: 0.925808\tvalid_1's auc: 0.891756\n",
      "[58]\ttraining's auc: 0.926322\tvalid_1's auc: 0.891951\n",
      "[59]\ttraining's auc: 0.926748\tvalid_1's auc: 0.8923\n",
      "[60]\ttraining's auc: 0.927074\tvalid_1's auc: 0.89239\n",
      "[61]\ttraining's auc: 0.927528\tvalid_1's auc: 0.892791\n",
      "[62]\ttraining's auc: 0.927958\tvalid_1's auc: 0.893195\n",
      "[63]\ttraining's auc: 0.928382\tvalid_1's auc: 0.893565\n",
      "[64]\ttraining's auc: 0.929048\tvalid_1's auc: 0.894107\n",
      "[65]\ttraining's auc: 0.929658\tvalid_1's auc: 0.894514\n",
      "[66]\ttraining's auc: 0.930064\tvalid_1's auc: 0.89477\n",
      "[67]\ttraining's auc: 0.930652\tvalid_1's auc: 0.89521\n",
      "[68]\ttraining's auc: 0.931116\tvalid_1's auc: 0.895377\n",
      "[69]\ttraining's auc: 0.931751\tvalid_1's auc: 0.89576\n",
      "[70]\ttraining's auc: 0.93245\tvalid_1's auc: 0.896078\n",
      "[71]\ttraining's auc: 0.932902\tvalid_1's auc: 0.896265\n",
      "[72]\ttraining's auc: 0.933269\tvalid_1's auc: 0.896315\n",
      "[73]\ttraining's auc: 0.933727\tvalid_1's auc: 0.89642\n",
      "[74]\ttraining's auc: 0.934015\tvalid_1's auc: 0.896506\n",
      "[75]\ttraining's auc: 0.934447\tvalid_1's auc: 0.896632\n",
      "[76]\ttraining's auc: 0.934812\tvalid_1's auc: 0.896938\n",
      "[77]\ttraining's auc: 0.935383\tvalid_1's auc: 0.897351\n",
      "[78]\ttraining's auc: 0.935842\tvalid_1's auc: 0.897669\n",
      "[79]\ttraining's auc: 0.93626\tvalid_1's auc: 0.897946\n",
      "[80]\ttraining's auc: 0.936635\tvalid_1's auc: 0.898123\n",
      "[81]\ttraining's auc: 0.937041\tvalid_1's auc: 0.898461\n",
      "[82]\ttraining's auc: 0.93734\tvalid_1's auc: 0.898548\n",
      "[83]\ttraining's auc: 0.937685\tvalid_1's auc: 0.898753\n",
      "[84]\ttraining's auc: 0.938029\tvalid_1's auc: 0.899078\n",
      "[85]\ttraining's auc: 0.93828\tvalid_1's auc: 0.899315\n",
      "[86]\ttraining's auc: 0.938558\tvalid_1's auc: 0.899476\n",
      "[87]\ttraining's auc: 0.93896\tvalid_1's auc: 0.899747\n",
      "[88]\ttraining's auc: 0.939495\tvalid_1's auc: 0.900042\n",
      "[89]\ttraining's auc: 0.939807\tvalid_1's auc: 0.90043\n",
      "[90]\ttraining's auc: 0.94022\tvalid_1's auc: 0.900829\n",
      "[91]\ttraining's auc: 0.94062\tvalid_1's auc: 0.900952\n",
      "[92]\ttraining's auc: 0.941041\tvalid_1's auc: 0.901048\n",
      "[93]\ttraining's auc: 0.941427\tvalid_1's auc: 0.901147\n",
      "[94]\ttraining's auc: 0.941902\tvalid_1's auc: 0.901392\n",
      "[95]\ttraining's auc: 0.942258\tvalid_1's auc: 0.901588\n",
      "[96]\ttraining's auc: 0.942529\tvalid_1's auc: 0.901609\n",
      "[97]\ttraining's auc: 0.942962\tvalid_1's auc: 0.901893\n",
      "[98]\ttraining's auc: 0.943508\tvalid_1's auc: 0.902078\n",
      "[99]\ttraining's auc: 0.943839\tvalid_1's auc: 0.902196\n",
      "[100]\ttraining's auc: 0.944284\tvalid_1's auc: 0.902368\n",
      "[101]\ttraining's auc: 0.944557\tvalid_1's auc: 0.902728\n",
      "[102]\ttraining's auc: 0.945007\tvalid_1's auc: 0.902773\n",
      "[103]\ttraining's auc: 0.945401\tvalid_1's auc: 0.902853\n",
      "[104]\ttraining's auc: 0.94584\tvalid_1's auc: 0.903099\n",
      "[105]\ttraining's auc: 0.946282\tvalid_1's auc: 0.903433\n",
      "[106]\ttraining's auc: 0.946535\tvalid_1's auc: 0.903511\n",
      "[107]\ttraining's auc: 0.946839\tvalid_1's auc: 0.903686\n",
      "[108]\ttraining's auc: 0.947115\tvalid_1's auc: 0.903848\n",
      "[109]\ttraining's auc: 0.947522\tvalid_1's auc: 0.904254\n",
      "[110]\ttraining's auc: 0.947891\tvalid_1's auc: 0.904547\n",
      "[111]\ttraining's auc: 0.948228\tvalid_1's auc: 0.904743\n",
      "[112]\ttraining's auc: 0.948642\tvalid_1's auc: 0.90493\n",
      "[113]\ttraining's auc: 0.948964\tvalid_1's auc: 0.905162\n",
      "[114]\ttraining's auc: 0.949302\tvalid_1's auc: 0.905357\n",
      "[115]\ttraining's auc: 0.949718\tvalid_1's auc: 0.905668\n",
      "[116]\ttraining's auc: 0.949972\tvalid_1's auc: 0.905957\n",
      "[117]\ttraining's auc: 0.950205\tvalid_1's auc: 0.906098\n",
      "[118]\ttraining's auc: 0.950489\tvalid_1's auc: 0.90629\n",
      "[119]\ttraining's auc: 0.950777\tvalid_1's auc: 0.906406\n",
      "[120]\ttraining's auc: 0.951101\tvalid_1's auc: 0.906661\n",
      "[121]\ttraining's auc: 0.951559\tvalid_1's auc: 0.9069\n",
      "[122]\ttraining's auc: 0.951948\tvalid_1's auc: 0.907065\n",
      "[123]\ttraining's auc: 0.952245\tvalid_1's auc: 0.907197\n",
      "[124]\ttraining's auc: 0.952618\tvalid_1's auc: 0.907473\n",
      "[125]\ttraining's auc: 0.952963\tvalid_1's auc: 0.907681\n",
      "[126]\ttraining's auc: 0.953389\tvalid_1's auc: 0.907813\n",
      "[127]\ttraining's auc: 0.953677\tvalid_1's auc: 0.907929\n",
      "[128]\ttraining's auc: 0.953896\tvalid_1's auc: 0.908018\n",
      "[129]\ttraining's auc: 0.954191\tvalid_1's auc: 0.908137\n",
      "[130]\ttraining's auc: 0.954642\tvalid_1's auc: 0.908336\n",
      "[131]\ttraining's auc: 0.955042\tvalid_1's auc: 0.908522\n",
      "[132]\ttraining's auc: 0.955422\tvalid_1's auc: 0.908571\n",
      "[133]\ttraining's auc: 0.955809\tvalid_1's auc: 0.908782\n",
      "[134]\ttraining's auc: 0.956215\tvalid_1's auc: 0.908938\n",
      "[135]\ttraining's auc: 0.956595\tvalid_1's auc: 0.909085\n",
      "[136]\ttraining's auc: 0.957001\tvalid_1's auc: 0.909218\n",
      "[137]\ttraining's auc: 0.957353\tvalid_1's auc: 0.909522\n",
      "[138]\ttraining's auc: 0.95769\tvalid_1's auc: 0.909685\n",
      "[139]\ttraining's auc: 0.957951\tvalid_1's auc: 0.909772\n",
      "[140]\ttraining's auc: 0.958256\tvalid_1's auc: 0.909991\n",
      "[141]\ttraining's auc: 0.958496\tvalid_1's auc: 0.910117\n",
      "[142]\ttraining's auc: 0.958874\tvalid_1's auc: 0.910269\n",
      "[143]\ttraining's auc: 0.959108\tvalid_1's auc: 0.910367\n",
      "[144]\ttraining's auc: 0.959372\tvalid_1's auc: 0.910418\n",
      "[145]\ttraining's auc: 0.959694\tvalid_1's auc: 0.910653\n",
      "[146]\ttraining's auc: 0.960053\tvalid_1's auc: 0.910879\n",
      "[147]\ttraining's auc: 0.960402\tvalid_1's auc: 0.911035\n",
      "[148]\ttraining's auc: 0.960691\tvalid_1's auc: 0.911258\n",
      "[149]\ttraining's auc: 0.960933\tvalid_1's auc: 0.911342\n",
      "[150]\ttraining's auc: 0.96113\tvalid_1's auc: 0.911467\n",
      "[151]\ttraining's auc: 0.961405\tvalid_1's auc: 0.911667\n",
      "[152]\ttraining's auc: 0.961625\tvalid_1's auc: 0.911751\n",
      "[153]\ttraining's auc: 0.961854\tvalid_1's auc: 0.911987\n",
      "[154]\ttraining's auc: 0.962136\tvalid_1's auc: 0.912216\n",
      "[155]\ttraining's auc: 0.962382\tvalid_1's auc: 0.912351\n",
      "[156]\ttraining's auc: 0.96265\tvalid_1's auc: 0.912419\n",
      "[157]\ttraining's auc: 0.962876\tvalid_1's auc: 0.912607\n",
      "[158]\ttraining's auc: 0.963087\tvalid_1's auc: 0.912789\n",
      "[159]\ttraining's auc: 0.963335\tvalid_1's auc: 0.912937\n",
      "[160]\ttraining's auc: 0.96367\tvalid_1's auc: 0.913027\n",
      "[161]\ttraining's auc: 0.963975\tvalid_1's auc: 0.913107\n",
      "[162]\ttraining's auc: 0.964282\tvalid_1's auc: 0.9132\n",
      "[163]\ttraining's auc: 0.964552\tvalid_1's auc: 0.913294\n",
      "[164]\ttraining's auc: 0.964772\tvalid_1's auc: 0.913317\n",
      "[165]\ttraining's auc: 0.965015\tvalid_1's auc: 0.913348\n",
      "[166]\ttraining's auc: 0.965187\tvalid_1's auc: 0.913484\n",
      "[167]\ttraining's auc: 0.965351\tvalid_1's auc: 0.913613\n",
      "[168]\ttraining's auc: 0.965486\tvalid_1's auc: 0.913774\n",
      "[169]\ttraining's auc: 0.965646\tvalid_1's auc: 0.913861\n",
      "[170]\ttraining's auc: 0.965832\tvalid_1's auc: 0.914079\n",
      "[171]\ttraining's auc: 0.965998\tvalid_1's auc: 0.914119\n",
      "[172]\ttraining's auc: 0.966168\tvalid_1's auc: 0.914224\n",
      "[173]\ttraining's auc: 0.966331\tvalid_1's auc: 0.914312\n",
      "[174]\ttraining's auc: 0.966541\tvalid_1's auc: 0.914489\n",
      "[175]\ttraining's auc: 0.966705\tvalid_1's auc: 0.914644\n",
      "[176]\ttraining's auc: 0.966812\tvalid_1's auc: 0.914675\n",
      "[177]\ttraining's auc: 0.966947\tvalid_1's auc: 0.914814\n",
      "[178]\ttraining's auc: 0.967167\tvalid_1's auc: 0.914993\n",
      "[179]\ttraining's auc: 0.967361\tvalid_1's auc: 0.915184\n",
      "[180]\ttraining's auc: 0.967565\tvalid_1's auc: 0.915312\n",
      "[181]\ttraining's auc: 0.967788\tvalid_1's auc: 0.915419\n",
      "[182]\ttraining's auc: 0.967968\tvalid_1's auc: 0.915531\n",
      "[183]\ttraining's auc: 0.968139\tvalid_1's auc: 0.91562\n",
      "[184]\ttraining's auc: 0.968288\tvalid_1's auc: 0.915748\n",
      "[185]\ttraining's auc: 0.968439\tvalid_1's auc: 0.915903\n",
      "[186]\ttraining's auc: 0.968572\tvalid_1's auc: 0.91593\n",
      "[187]\ttraining's auc: 0.968629\tvalid_1's auc: 0.915999\n",
      "[188]\ttraining's auc: 0.968839\tvalid_1's auc: 0.916124\n",
      "[189]\ttraining's auc: 0.969026\tvalid_1's auc: 0.916253\n",
      "[190]\ttraining's auc: 0.969192\tvalid_1's auc: 0.916281\n",
      "[191]\ttraining's auc: 0.96938\tvalid_1's auc: 0.916312\n",
      "[192]\ttraining's auc: 0.9695\tvalid_1's auc: 0.916383\n",
      "[193]\ttraining's auc: 0.969675\tvalid_1's auc: 0.916447\n",
      "[194]\ttraining's auc: 0.969833\tvalid_1's auc: 0.916536\n",
      "[195]\ttraining's auc: 0.969924\tvalid_1's auc: 0.916583\n",
      "[196]\ttraining's auc: 0.970036\tvalid_1's auc: 0.916614\n",
      "[197]\ttraining's auc: 0.970156\tvalid_1's auc: 0.916715\n",
      "[198]\ttraining's auc: 0.970301\tvalid_1's auc: 0.916843\n",
      "[199]\ttraining's auc: 0.970407\tvalid_1's auc: 0.916917\n",
      "[200]\ttraining's auc: 0.970511\tvalid_1's auc: 0.916964\n",
      "[201]\ttraining's auc: 0.970579\tvalid_1's auc: 0.917021\n",
      "[202]\ttraining's auc: 0.970644\tvalid_1's auc: 0.917131\n",
      "[203]\ttraining's auc: 0.970749\tvalid_1's auc: 0.917274\n",
      "[204]\ttraining's auc: 0.970827\tvalid_1's auc: 0.917344\n",
      "[205]\ttraining's auc: 0.970889\tvalid_1's auc: 0.917413\n",
      "[206]\ttraining's auc: 0.970956\tvalid_1's auc: 0.917441\n",
      "[207]\ttraining's auc: 0.970994\tvalid_1's auc: 0.917388\n",
      "[208]\ttraining's auc: 0.971147\tvalid_1's auc: 0.917438\n",
      "[209]\ttraining's auc: 0.971322\tvalid_1's auc: 0.91753\n",
      "[210]\ttraining's auc: 0.971447\tvalid_1's auc: 0.91763\n",
      "[211]\ttraining's auc: 0.971628\tvalid_1's auc: 0.9177\n",
      "[212]\ttraining's auc: 0.971781\tvalid_1's auc: 0.91775\n",
      "[213]\ttraining's auc: 0.971923\tvalid_1's auc: 0.917717\n",
      "[214]\ttraining's auc: 0.972026\tvalid_1's auc: 0.917667\n",
      "[215]\ttraining's auc: 0.972118\tvalid_1's auc: 0.917692\n",
      "[216]\ttraining's auc: 0.972261\tvalid_1's auc: 0.917682\n",
      "[217]\ttraining's auc: 0.972405\tvalid_1's auc: 0.917722\n",
      "[218]\ttraining's auc: 0.97246\tvalid_1's auc: 0.917767\n",
      "[219]\ttraining's auc: 0.97252\tvalid_1's auc: 0.917776\n",
      "[220]\ttraining's auc: 0.972651\tvalid_1's auc: 0.917781\n",
      "[221]\ttraining's auc: 0.972791\tvalid_1's auc: 0.917809\n",
      "[222]\ttraining's auc: 0.972923\tvalid_1's auc: 0.917873\n",
      "[223]\ttraining's auc: 0.973062\tvalid_1's auc: 0.917925\n",
      "[224]\ttraining's auc: 0.973186\tvalid_1's auc: 0.917972\n",
      "[225]\ttraining's auc: 0.97332\tvalid_1's auc: 0.918041\n",
      "[226]\ttraining's auc: 0.973387\tvalid_1's auc: 0.918088\n",
      "[227]\ttraining's auc: 0.973484\tvalid_1's auc: 0.918087\n",
      "[228]\ttraining's auc: 0.973574\tvalid_1's auc: 0.918085\n",
      "[229]\ttraining's auc: 0.973674\tvalid_1's auc: 0.918158\n",
      "[230]\ttraining's auc: 0.973821\tvalid_1's auc: 0.918237\n",
      "[231]\ttraining's auc: 0.973893\tvalid_1's auc: 0.918271\n",
      "[232]\ttraining's auc: 0.973953\tvalid_1's auc: 0.918306\n",
      "[233]\ttraining's auc: 0.974015\tvalid_1's auc: 0.918346\n",
      "[234]\ttraining's auc: 0.974126\tvalid_1's auc: 0.918391\n",
      "[235]\ttraining's auc: 0.974262\tvalid_1's auc: 0.918436\n",
      "[236]\ttraining's auc: 0.974395\tvalid_1's auc: 0.918499\n",
      "[237]\ttraining's auc: 0.974552\tvalid_1's auc: 0.918605\n",
      "[238]\ttraining's auc: 0.974661\tvalid_1's auc: 0.918678\n",
      "[239]\ttraining's auc: 0.974827\tvalid_1's auc: 0.918767\n",
      "[240]\ttraining's auc: 0.974889\tvalid_1's auc: 0.91879\n",
      "[241]\ttraining's auc: 0.975016\tvalid_1's auc: 0.918812\n",
      "[242]\ttraining's auc: 0.975179\tvalid_1's auc: 0.918909\n",
      "[243]\ttraining's auc: 0.975272\tvalid_1's auc: 0.918966\n",
      "[244]\ttraining's auc: 0.975411\tvalid_1's auc: 0.919083\n",
      "[245]\ttraining's auc: 0.975578\tvalid_1's auc: 0.919181\n",
      "[246]\ttraining's auc: 0.975671\tvalid_1's auc: 0.919171\n",
      "[247]\ttraining's auc: 0.975816\tvalid_1's auc: 0.919209\n",
      "[248]\ttraining's auc: 0.975941\tvalid_1's auc: 0.919184\n",
      "[249]\ttraining's auc: 0.976032\tvalid_1's auc: 0.919185\n",
      "[250]\ttraining's auc: 0.976087\tvalid_1's auc: 0.919221\n",
      "[251]\ttraining's auc: 0.976123\tvalid_1's auc: 0.919223\n",
      "[252]\ttraining's auc: 0.976143\tvalid_1's auc: 0.919224\n",
      "[253]\ttraining's auc: 0.976194\tvalid_1's auc: 0.919218\n",
      "[254]\ttraining's auc: 0.976222\tvalid_1's auc: 0.919231\n",
      "[255]\ttraining's auc: 0.976253\tvalid_1's auc: 0.919228\n",
      "[256]\ttraining's auc: 0.976307\tvalid_1's auc: 0.919268\n",
      "[257]\ttraining's auc: 0.976375\tvalid_1's auc: 0.919387\n",
      "[258]\ttraining's auc: 0.976476\tvalid_1's auc: 0.919462\n",
      "[259]\ttraining's auc: 0.976575\tvalid_1's auc: 0.919508\n",
      "[260]\ttraining's auc: 0.97666\tvalid_1's auc: 0.919564\n",
      "[261]\ttraining's auc: 0.976726\tvalid_1's auc: 0.919571\n",
      "[262]\ttraining's auc: 0.976845\tvalid_1's auc: 0.919602\n",
      "[263]\ttraining's auc: 0.97696\tvalid_1's auc: 0.919652\n",
      "[264]\ttraining's auc: 0.977073\tvalid_1's auc: 0.919702\n",
      "[265]\ttraining's auc: 0.977192\tvalid_1's auc: 0.919731\n",
      "[266]\ttraining's auc: 0.977253\tvalid_1's auc: 0.919719\n",
      "[267]\ttraining's auc: 0.977309\tvalid_1's auc: 0.919661\n",
      "[268]\ttraining's auc: 0.977397\tvalid_1's auc: 0.919687\n",
      "[269]\ttraining's auc: 0.977448\tvalid_1's auc: 0.919694\n",
      "[270]\ttraining's auc: 0.977532\tvalid_1's auc: 0.919716\n",
      "[271]\ttraining's auc: 0.977565\tvalid_1's auc: 0.919754\n",
      "[272]\ttraining's auc: 0.977679\tvalid_1's auc: 0.919823\n",
      "[273]\ttraining's auc: 0.9777\tvalid_1's auc: 0.919779\n",
      "[274]\ttraining's auc: 0.977726\tvalid_1's auc: 0.919803\n",
      "[275]\ttraining's auc: 0.977788\tvalid_1's auc: 0.919797\n",
      "[276]\ttraining's auc: 0.9778\tvalid_1's auc: 0.919782\n",
      "[277]\ttraining's auc: 0.977837\tvalid_1's auc: 0.919774\n",
      "[278]\ttraining's auc: 0.977881\tvalid_1's auc: 0.919826\n",
      "[279]\ttraining's auc: 0.977912\tvalid_1's auc: 0.919809\n",
      "[280]\ttraining's auc: 0.977957\tvalid_1's auc: 0.919826\n",
      "[281]\ttraining's auc: 0.978016\tvalid_1's auc: 0.919832\n",
      "[282]\ttraining's auc: 0.978084\tvalid_1's auc: 0.919826\n",
      "[283]\ttraining's auc: 0.978157\tvalid_1's auc: 0.919921\n",
      "[284]\ttraining's auc: 0.978256\tvalid_1's auc: 0.92003\n",
      "[285]\ttraining's auc: 0.978339\tvalid_1's auc: 0.920107\n",
      "[286]\ttraining's auc: 0.978417\tvalid_1's auc: 0.92015\n",
      "[287]\ttraining's auc: 0.978542\tvalid_1's auc: 0.920212\n",
      "[288]\ttraining's auc: 0.97867\tvalid_1's auc: 0.920208\n",
      "[289]\ttraining's auc: 0.978798\tvalid_1's auc: 0.920292\n",
      "[290]\ttraining's auc: 0.978893\tvalid_1's auc: 0.920282\n",
      "[291]\ttraining's auc: 0.978945\tvalid_1's auc: 0.920234\n",
      "[292]\ttraining's auc: 0.97901\tvalid_1's auc: 0.920162\n",
      "[293]\ttraining's auc: 0.979082\tvalid_1's auc: 0.920193\n",
      "[294]\ttraining's auc: 0.979128\tvalid_1's auc: 0.920168\n",
      "[295]\ttraining's auc: 0.979165\tvalid_1's auc: 0.920138\n",
      "[296]\ttraining's auc: 0.979179\tvalid_1's auc: 0.920128\n",
      "[297]\ttraining's auc: 0.979195\tvalid_1's auc: 0.920104\n",
      "[298]\ttraining's auc: 0.979295\tvalid_1's auc: 0.920103\n",
      "[299]\ttraining's auc: 0.979377\tvalid_1's auc: 0.920086\n",
      "[300]\ttraining's auc: 0.979479\tvalid_1's auc: 0.92011\n",
      "[301]\ttraining's auc: 0.979618\tvalid_1's auc: 0.920152\n",
      "[302]\ttraining's auc: 0.979703\tvalid_1's auc: 0.920167\n",
      "[303]\ttraining's auc: 0.979801\tvalid_1's auc: 0.920164\n",
      "[304]\ttraining's auc: 0.979875\tvalid_1's auc: 0.920119\n",
      "[305]\ttraining's auc: 0.979933\tvalid_1's auc: 0.920103\n",
      "[306]\ttraining's auc: 0.979991\tvalid_1's auc: 0.920112\n",
      "[307]\ttraining's auc: 0.980118\tvalid_1's auc: 0.920112\n",
      "[308]\ttraining's auc: 0.980192\tvalid_1's auc: 0.92013\n",
      "[309]\ttraining's auc: 0.98024\tvalid_1's auc: 0.920162\n",
      "[310]\ttraining's auc: 0.980357\tvalid_1's auc: 0.920151\n",
      "[311]\ttraining's auc: 0.980468\tvalid_1's auc: 0.920134\n",
      "[312]\ttraining's auc: 0.980556\tvalid_1's auc: 0.920076\n",
      "[313]\ttraining's auc: 0.980573\tvalid_1's auc: 0.920058\n",
      "[314]\ttraining's auc: 0.980602\tvalid_1's auc: 0.920038\n",
      "[315]\ttraining's auc: 0.980619\tvalid_1's auc: 0.920014\n",
      "[316]\ttraining's auc: 0.980683\tvalid_1's auc: 0.919982\n",
      "[317]\ttraining's auc: 0.980707\tvalid_1's auc: 0.919962\n",
      "[318]\ttraining's auc: 0.980768\tvalid_1's auc: 0.919931\n",
      "[319]\ttraining's auc: 0.980808\tvalid_1's auc: 0.920014\n",
      "[320]\ttraining's auc: 0.980841\tvalid_1's auc: 0.920013\n",
      "[321]\ttraining's auc: 0.980896\tvalid_1's auc: 0.920026\n",
      "[322]\ttraining's auc: 0.980937\tvalid_1's auc: 0.920011\n",
      "[323]\ttraining's auc: 0.981059\tvalid_1's auc: 0.920043\n",
      "[324]\ttraining's auc: 0.981151\tvalid_1's auc: 0.920106\n",
      "[325]\ttraining's auc: 0.981226\tvalid_1's auc: 0.920096\n",
      "[326]\ttraining's auc: 0.98126\tvalid_1's auc: 0.92006\n",
      "[327]\ttraining's auc: 0.981333\tvalid_1's auc: 0.920036\n",
      "[328]\ttraining's auc: 0.9814\tvalid_1's auc: 0.920011\n",
      "[329]\ttraining's auc: 0.981482\tvalid_1's auc: 0.919989\n",
      "[330]\ttraining's auc: 0.981513\tvalid_1's auc: 0.919981\n",
      "[331]\ttraining's auc: 0.981629\tvalid_1's auc: 0.920039\n",
      "[332]\ttraining's auc: 0.981704\tvalid_1's auc: 0.920054\n",
      "[333]\ttraining's auc: 0.981762\tvalid_1's auc: 0.920017\n",
      "[334]\ttraining's auc: 0.981803\tvalid_1's auc: 0.920006\n",
      "[335]\ttraining's auc: 0.981839\tvalid_1's auc: 0.919991\n",
      "[336]\ttraining's auc: 0.98187\tvalid_1's auc: 0.920002\n",
      "[337]\ttraining's auc: 0.981967\tvalid_1's auc: 0.919993\n",
      "[338]\ttraining's auc: 0.982032\tvalid_1's auc: 0.920034\n",
      "[339]\ttraining's auc: 0.98205\tvalid_1's auc: 0.920096\n",
      "[340]\ttraining's auc: 0.98206\tvalid_1's auc: 0.920093\n",
      "[341]\ttraining's auc: 0.982111\tvalid_1's auc: 0.920103\n",
      "[342]\ttraining's auc: 0.98217\tvalid_1's auc: 0.920121\n",
      "[343]\ttraining's auc: 0.98219\tvalid_1's auc: 0.920085\n",
      "[344]\ttraining's auc: 0.9822\tvalid_1's auc: 0.920074\n",
      "[345]\ttraining's auc: 0.982211\tvalid_1's auc: 0.92006\n",
      "[346]\ttraining's auc: 0.9823\tvalid_1's auc: 0.92007\n",
      "[347]\ttraining's auc: 0.982357\tvalid_1's auc: 0.920069\n",
      "[348]\ttraining's auc: 0.98238\tvalid_1's auc: 0.920038\n",
      "[349]\ttraining's auc: 0.982415\tvalid_1's auc: 0.920003\n",
      "[350]\ttraining's auc: 0.982453\tvalid_1's auc: 0.920019\n",
      "[351]\ttraining's auc: 0.982508\tvalid_1's auc: 0.919957\n",
      "[352]\ttraining's auc: 0.982545\tvalid_1's auc: 0.920022\n",
      "[353]\ttraining's auc: 0.982564\tvalid_1's auc: 0.920015\n",
      "[354]\ttraining's auc: 0.982596\tvalid_1's auc: 0.920038\n",
      "[355]\ttraining's auc: 0.982653\tvalid_1's auc: 0.92006\n",
      "[356]\ttraining's auc: 0.982706\tvalid_1's auc: 0.919997\n",
      "[357]\ttraining's auc: 0.982735\tvalid_1's auc: 0.920001\n",
      "[358]\ttraining's auc: 0.982801\tvalid_1's auc: 0.919972\n",
      "[359]\ttraining's auc: 0.982834\tvalid_1's auc: 0.919944\n",
      "[360]\ttraining's auc: 0.982936\tvalid_1's auc: 0.919974\n",
      "[361]\ttraining's auc: 0.983021\tvalid_1's auc: 0.919925\n",
      "[362]\ttraining's auc: 0.983095\tvalid_1's auc: 0.919915\n",
      "[363]\ttraining's auc: 0.983195\tvalid_1's auc: 0.919853\n",
      "[364]\ttraining's auc: 0.983247\tvalid_1's auc: 0.919838\n",
      "[365]\ttraining's auc: 0.983309\tvalid_1's auc: 0.919852\n",
      "[366]\ttraining's auc: 0.98341\tvalid_1's auc: 0.919895\n",
      "[367]\ttraining's auc: 0.983424\tvalid_1's auc: 0.919884\n",
      "[368]\ttraining's auc: 0.983438\tvalid_1's auc: 0.919862\n",
      "[369]\ttraining's auc: 0.983462\tvalid_1's auc: 0.919873\n",
      "[370]\ttraining's auc: 0.983492\tvalid_1's auc: 0.919858\n",
      "[371]\ttraining's auc: 0.983518\tvalid_1's auc: 0.919855\n",
      "[372]\ttraining's auc: 0.983532\tvalid_1's auc: 0.919814\n",
      "[373]\ttraining's auc: 0.983574\tvalid_1's auc: 0.919829\n",
      "[374]\ttraining's auc: 0.983616\tvalid_1's auc: 0.919826\n",
      "[375]\ttraining's auc: 0.983684\tvalid_1's auc: 0.91987\n",
      "[376]\ttraining's auc: 0.983749\tvalid_1's auc: 0.919924\n",
      "[377]\ttraining's auc: 0.983826\tvalid_1's auc: 0.919919\n",
      "[378]\ttraining's auc: 0.983916\tvalid_1's auc: 0.919941\n",
      "[379]\ttraining's auc: 0.983935\tvalid_1's auc: 0.919885\n",
      "[380]\ttraining's auc: 0.98396\tvalid_1's auc: 0.919816\n",
      "[381]\ttraining's auc: 0.984037\tvalid_1's auc: 0.919786\n",
      "[382]\ttraining's auc: 0.984077\tvalid_1's auc: 0.919814\n",
      "[383]\ttraining's auc: 0.984109\tvalid_1's auc: 0.919792\n",
      "[384]\ttraining's auc: 0.984133\tvalid_1's auc: 0.919763\n",
      "[385]\ttraining's auc: 0.984171\tvalid_1's auc: 0.919801\n",
      "[386]\ttraining's auc: 0.984235\tvalid_1's auc: 0.919815\n",
      "[387]\ttraining's auc: 0.984288\tvalid_1's auc: 0.919809\n",
      "[388]\ttraining's auc: 0.984352\tvalid_1's auc: 0.91976\n",
      "[389]\ttraining's auc: 0.984419\tvalid_1's auc: 0.919709\n",
      "[390]\ttraining's auc: 0.984488\tvalid_1's auc: 0.919725\n",
      "[391]\ttraining's auc: 0.984557\tvalid_1's auc: 0.919723\n",
      "[392]\ttraining's auc: 0.984633\tvalid_1's auc: 0.919694\n",
      "[393]\ttraining's auc: 0.98469\tvalid_1's auc: 0.919646\n",
      "[394]\ttraining's auc: 0.984739\tvalid_1's auc: 0.919681\n",
      "[395]\ttraining's auc: 0.984806\tvalid_1's auc: 0.91969\n",
      "[396]\ttraining's auc: 0.984857\tvalid_1's auc: 0.919606\n",
      "[397]\ttraining's auc: 0.984936\tvalid_1's auc: 0.919596\n",
      "[398]\ttraining's auc: 0.985004\tvalid_1's auc: 0.919591\n",
      "[399]\ttraining's auc: 0.985075\tvalid_1's auc: 0.919559\n",
      "[400]\ttraining's auc: 0.985104\tvalid_1's auc: 0.919563\n",
      "[401]\ttraining's auc: 0.985121\tvalid_1's auc: 0.919544\n",
      "[402]\ttraining's auc: 0.98514\tvalid_1's auc: 0.919562\n",
      "[403]\ttraining's auc: 0.985176\tvalid_1's auc: 0.919563\n",
      "[404]\ttraining's auc: 0.985244\tvalid_1's auc: 0.919567\n",
      "[405]\ttraining's auc: 0.98526\tvalid_1's auc: 0.91955\n",
      "[406]\ttraining's auc: 0.985353\tvalid_1's auc: 0.919588\n",
      "[407]\ttraining's auc: 0.985455\tvalid_1's auc: 0.919572\n",
      "[408]\ttraining's auc: 0.985523\tvalid_1's auc: 0.919671\n",
      "[409]\ttraining's auc: 0.985542\tvalid_1's auc: 0.919656\n",
      "[410]\ttraining's auc: 0.985603\tvalid_1's auc: 0.919653\n",
      "[411]\ttraining's auc: 0.985661\tvalid_1's auc: 0.919645\n",
      "[412]\ttraining's auc: 0.985702\tvalid_1's auc: 0.919652\n",
      "[413]\ttraining's auc: 0.985718\tvalid_1's auc: 0.919656\n",
      "[414]\ttraining's auc: 0.985743\tvalid_1's auc: 0.919645\n",
      "[415]\ttraining's auc: 0.985764\tvalid_1's auc: 0.91961\n",
      "[416]\ttraining's auc: 0.985796\tvalid_1's auc: 0.919592\n",
      "[417]\ttraining's auc: 0.985859\tvalid_1's auc: 0.919553\n",
      "[418]\ttraining's auc: 0.985881\tvalid_1's auc: 0.919488\n",
      "[419]\ttraining's auc: 0.985908\tvalid_1's auc: 0.919457\n",
      "[420]\ttraining's auc: 0.985929\tvalid_1's auc: 0.919458\n",
      "[421]\ttraining's auc: 0.985967\tvalid_1's auc: 0.9194\n",
      "[422]\ttraining's auc: 0.985981\tvalid_1's auc: 0.919356\n",
      "[423]\ttraining's auc: 0.986007\tvalid_1's auc: 0.919293\n",
      "[424]\ttraining's auc: 0.986037\tvalid_1's auc: 0.919267\n",
      "[425]\ttraining's auc: 0.98607\tvalid_1's auc: 0.919266\n",
      "[426]\ttraining's auc: 0.986079\tvalid_1's auc: 0.91918\n",
      "[427]\ttraining's auc: 0.986128\tvalid_1's auc: 0.919208\n",
      "[428]\ttraining's auc: 0.986176\tvalid_1's auc: 0.919198\n",
      "[429]\ttraining's auc: 0.986188\tvalid_1's auc: 0.91914\n",
      "[430]\ttraining's auc: 0.986209\tvalid_1's auc: 0.919083\n",
      "[431]\ttraining's auc: 0.986246\tvalid_1's auc: 0.919029\n",
      "[432]\ttraining's auc: 0.986267\tvalid_1's auc: 0.919005\n",
      "[433]\ttraining's auc: 0.986321\tvalid_1's auc: 0.918988\n",
      "[434]\ttraining's auc: 0.98637\tvalid_1's auc: 0.918955\n",
      "[435]\ttraining's auc: 0.986427\tvalid_1's auc: 0.918911\n",
      "[436]\ttraining's auc: 0.986436\tvalid_1's auc: 0.918883\n",
      "[437]\ttraining's auc: 0.986449\tvalid_1's auc: 0.91884\n",
      "[438]\ttraining's auc: 0.986463\tvalid_1's auc: 0.918811\n",
      "[439]\ttraining's auc: 0.986531\tvalid_1's auc: 0.918835\n",
      "[440]\ttraining's auc: 0.986579\tvalid_1's auc: 0.918794\n",
      "[441]\ttraining's auc: 0.986623\tvalid_1's auc: 0.918792\n",
      "[442]\ttraining's auc: 0.986634\tvalid_1's auc: 0.918791\n",
      "[443]\ttraining's auc: 0.986648\tvalid_1's auc: 0.918777\n",
      "[444]\ttraining's auc: 0.98666\tvalid_1's auc: 0.918787\n",
      "[445]\ttraining's auc: 0.986709\tvalid_1's auc: 0.918793\n",
      "[446]\ttraining's auc: 0.986767\tvalid_1's auc: 0.918769\n",
      "[447]\ttraining's auc: 0.986823\tvalid_1's auc: 0.918724\n",
      "[448]\ttraining's auc: 0.986869\tvalid_1's auc: 0.918699\n",
      "[449]\ttraining's auc: 0.98694\tvalid_1's auc: 0.918684\n",
      "[450]\ttraining's auc: 0.986984\tvalid_1's auc: 0.918569\n",
      "[451]\ttraining's auc: 0.987016\tvalid_1's auc: 0.918564\n",
      "[452]\ttraining's auc: 0.987046\tvalid_1's auc: 0.918546\n",
      "[453]\ttraining's auc: 0.987072\tvalid_1's auc: 0.918555\n",
      "[454]\ttraining's auc: 0.98711\tvalid_1's auc: 0.918505\n",
      "[455]\ttraining's auc: 0.987162\tvalid_1's auc: 0.918433\n",
      "[456]\ttraining's auc: 0.987185\tvalid_1's auc: 0.918415\n",
      "[457]\ttraining's auc: 0.98723\tvalid_1's auc: 0.918394\n",
      "[458]\ttraining's auc: 0.987254\tvalid_1's auc: 0.918405\n",
      "[459]\ttraining's auc: 0.987343\tvalid_1's auc: 0.918441\n",
      "[460]\ttraining's auc: 0.987393\tvalid_1's auc: 0.918427\n",
      "[461]\ttraining's auc: 0.987405\tvalid_1's auc: 0.918438\n",
      "[462]\ttraining's auc: 0.987414\tvalid_1's auc: 0.918423\n",
      "[463]\ttraining's auc: 0.987423\tvalid_1's auc: 0.918404\n",
      "[464]\ttraining's auc: 0.987442\tvalid_1's auc: 0.918378\n",
      "[465]\ttraining's auc: 0.987479\tvalid_1's auc: 0.918394\n",
      "[466]\ttraining's auc: 0.987532\tvalid_1's auc: 0.918375\n",
      "[467]\ttraining's auc: 0.987578\tvalid_1's auc: 0.918364\n",
      "[468]\ttraining's auc: 0.98763\tvalid_1's auc: 0.918381\n",
      "[469]\ttraining's auc: 0.987665\tvalid_1's auc: 0.918363\n",
      "[470]\ttraining's auc: 0.987691\tvalid_1's auc: 0.918362\n",
      "[471]\ttraining's auc: 0.987726\tvalid_1's auc: 0.918363\n",
      "[472]\ttraining's auc: 0.987747\tvalid_1's auc: 0.91834\n",
      "[473]\ttraining's auc: 0.987795\tvalid_1's auc: 0.918294\n",
      "[474]\ttraining's auc: 0.98783\tvalid_1's auc: 0.918257\n",
      "[475]\ttraining's auc: 0.987867\tvalid_1's auc: 0.9182\n",
      "[476]\ttraining's auc: 0.9879\tvalid_1's auc: 0.918189\n",
      "[477]\ttraining's auc: 0.987913\tvalid_1's auc: 0.918155\n",
      "[478]\ttraining's auc: 0.987971\tvalid_1's auc: 0.918211\n",
      "[479]\ttraining's auc: 0.988027\tvalid_1's auc: 0.918234\n",
      "[480]\ttraining's auc: 0.988079\tvalid_1's auc: 0.918252\n",
      "[481]\ttraining's auc: 0.988119\tvalid_1's auc: 0.918234\n",
      "[482]\ttraining's auc: 0.988157\tvalid_1's auc: 0.918185\n",
      "[483]\ttraining's auc: 0.988206\tvalid_1's auc: 0.918152\n",
      "[484]\ttraining's auc: 0.988248\tvalid_1's auc: 0.918147\n",
      "[485]\ttraining's auc: 0.988276\tvalid_1's auc: 0.918196\n",
      "[486]\ttraining's auc: 0.988322\tvalid_1's auc: 0.91824\n",
      "[487]\ttraining's auc: 0.988354\tvalid_1's auc: 0.918233\n",
      "[488]\ttraining's auc: 0.988382\tvalid_1's auc: 0.918145\n",
      "[489]\ttraining's auc: 0.988405\tvalid_1's auc: 0.918086\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's auc: 0.978798\tvalid_1's auc: 0.920292\n",
      "Fold 4\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2ffc88edf58a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0min_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_of_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_of_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# log train and valid auc metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#neptune.send_metric('train_auc', train_auc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-4de515d40cc0>\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(X, y, X_test, folds, model_params, training_params)\u001b[0m\n\u001b[1;32m     15\u001b[0m                         \u001b[0mtraining_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_boosting_rounds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0mvalid_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                         early_stopping_rounds = training_params['early_stopping_rounds'])\n\u001b[0m\u001b[1;32m     18\u001b[0m                         \u001b[0;31m#,callbacks=[monitor])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0min_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1552\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m   1002\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    727\u001b[0m                                                                                              \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                                                                                              \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                                                                              self.pandas_categorical)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_label_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_has_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input data must be 2 dimensional and non empty.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mcat_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpandas_categorical\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPY2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mrename\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4023\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4024\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mapper'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4027\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mSubstitution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mrename\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m             result._data = result._data.rename_axis(f, axis=baxis, copy=copy,\n\u001b[0;32m-> 1091\u001b[0;31m                                                     level=level)\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mrename_axis\u001b[0;34m(self, mapper, axis, copy, level)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mlevel\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \"\"\"\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_transform_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         return self.apply('copy', axes=new_axes, deep=deep,\n\u001b[0;32m--> 734\u001b[0;31m                           do_integrity_check=False)\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "in_fold, out_of_fold, test_preds = fit_predict(X, y, X_test, folds, model_params, training_params)\n",
    "\n",
    "train_auc, valid_auc = roc_auc_score(y, in_fold), roc_auc_score(y, out_of_fold)\n",
    "# log train and valid auc metrics\n",
    "#neptune.send_metric('train_auc', train_auc)\n",
    "#neptune.send_metric('valid_auc', valid_auc)\n",
    "# log diagnostic charts on the validation\n",
    "#send_binary_classification_report(y, fmt_preds(out_of_fold), channel_name='valid_classification_report')\n",
    "\n",
    "train = pd.concat([train, pd.DataFrame(out_of_fold, columns=['prediction'])], axis=1)\n",
    "test = pd.concat([test, pd.DataFrame(test_preds, columns=['prediction'])], axis=1)\n",
    "sub['isFraud'] = pd.merge(sub, test, on='TransactionID')['prediction']\n",
    "train.to_csv(train_predictions_path, index=None)\n",
    "test.to_csv(test_predictions_path, index=None)\n",
    "sub.to_csv(submission_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed3927c03577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
